{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9167941,"sourceType":"datasetVersion","datasetId":5539782},{"sourceId":4771786,"sourceType":"datasetVersion","datasetId":2761867}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Init env","metadata":{}},{"cell_type":"code","source":"!conda create -n minusface python=3.8 -y","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda env list","metadata":{"execution":{"iopub.status.busy":"2024-09-29T07:36:46.201135Z","iopub.execute_input":"2024-09-29T07:36:46.202117Z","iopub.status.idle":"2024-09-29T07:36:48.027995Z","shell.execute_reply.started":"2024-09-29T07:36:46.202069Z","shell.execute_reply":"2024-09-29T07:36:48.027032Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"# conda environments:\n#\nbase                     /opt/conda\nminusface                /opt/conda/envs/minusface\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['PYTHON_BIN'] = '/opt/conda/envs/minusface/bin'","metadata":{"execution":{"iopub.status.busy":"2024-09-29T07:37:11.724271Z","iopub.execute_input":"2024-09-29T07:37:11.724658Z","iopub.status.idle":"2024-09-29T07:37:11.729412Z","shell.execute_reply.started":"2024-09-29T07:37:11.724622Z","shell.execute_reply":"2024-09-29T07:37:11.728404Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!$PYTHON_BIN/pip install dareblopy\n!$PYTHON_BIN/pip install torchjpeg\n!$PYTHON_BIN/pip install pyyaml\n!$PYTHON_BIN/pip install tensorboard\n!$PYTHON_BIN/pip install opencv-python\n!$PYTHON_BIN/pip install protobuf==3.20.*\n!$PYTHON_BIN/pip install scikit-learn\n!$PYTHON_BIN/pip install tqdm\n!$PYTHON_BIN/pip install scikit-image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!$PYTHON_BIN/pip list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setup","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/Tencent/TFace.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r '/kaggle/working/recognition'\n!cp -r '/kaggle/working/TFace/recognition' '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-09-24T17:39:46.419898Z","iopub.execute_input":"2024-09-24T17:39:46.420547Z","iopub.status.idle":"2024-09-24T17:39:48.400616Z","shell.execute_reply.started":"2024-09-24T17:39:46.420499Z","shell.execute_reply":"2024-09-24T17:39:48.399422Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%writefile '/kaggle/working/recognition/torchkit/hooks/learning_rate_hook.py'\nimport logging\nfrom bisect import bisect\nfrom .base_hook import Hook\n\n\ndef set_optimizer_lr(optimizer, lr):\n    if isinstance(optimizer, dict):\n        backbone_opt, head_opts = optimizer['backbone'], optimizer['heads']\n        if len(backbone_opt.param_groups) > 1: # is stage 1\n            rate = 0.1\n            backbone_opt.param_groups[0]['lr'] = lr * rate\n            backbone_opt.param_groups[1]['lr'] = lr\n            for _, head_opt in head_opts.items():\n                for param_group in head_opt.param_groups:\n                    param_group['lr'] = lr\n        else: # is stage 2\n            for param_group in backbone_opt.param_groups:\n                param_group['lr'] = lr\n    else:\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n\ndef warm_up_lr(step, warmup_step, init_lr, optimizer):\n    \"\"\" Warm up learning rate when batch step below warmup steps\n    \"\"\"\n\n    lr = step * init_lr / warmup_step\n    if step % 500 == 0:\n        logging.info(\"Current step {}, learning rate {}\".format(step, lr))\n\n    set_optimizer_lr(optimizer, lr)\n\n\ndef adjust_lr(epoch, learning_rates, stages, optimizer):\n    \"\"\" Decay the learning rate based on schedule\n    \"\"\"\n\n    pos = bisect(stages, epoch)\n    lr = learning_rates[pos]\n    logging.info(\"Current epoch {}, learning rate {}\".format(epoch + 1, lr))\n\n    set_optimizer_lr(optimizer, lr)\n\n\nclass LearningRateHook(Hook):\n    \"\"\" LearningRate Hook, adjust learning rate in training\n    \"\"\"\n    def __init__(self,\n                 learning_rates,\n                 stages,\n                 warmup_step):\n        \"\"\" Create a ``LearningRateHook`` object\n\n            Args:\n            learning_rates: all learning rates value\n            stages: learning rate adjust stages value\n            warmup_step: step num of warmup\n        \"\"\"\n\n        self.learning_rates = learning_rates\n        self.stages = stages\n        if len(self.learning_rates) != len(self.stages) + 1:\n            raise RuntimeError(\"Learning_rates size should be one larger than stages size\")\n        self.init_lr = self.learning_rates[0]\n        self.warmup_step = warmup_step\n\n    def before_train_iter(self, task, step, epoch):\n        global_step = epoch * task.step_per_epoch + step\n        if self.warmup_step > 0 and global_step <= self.warmup_step:\n            warm_up_lr(global_step, self.warmup_step, self.init_lr, task.opt)\n\n    def before_train_epoch(self, task, epoch):\n        adjust_lr(epoch, self.learning_rates, self.stages, task.opt)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T17:40:29.643885Z","iopub.execute_input":"2024-09-24T17:40:29.644656Z","iopub.status.idle":"2024-09-24T17:40:29.653350Z","shell.execute_reply.started":"2024-09-24T17:40:29.644615Z","shell.execute_reply":"2024-09-24T17:40:29.652421Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/recognition/torchkit/hooks/learning_rate_hook.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Minus Face","metadata":{}},{"cell_type":"markdown","source":"### Generate index file","metadata":{}},{"cell_type":"code","source":"!mkdir '/kaggle/working/index_root'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nDATA_ROOT = '/kaggle/input/vn-celeb'\n\nINDEX_ROOT = '/kaggle/working/index_root'\nif not os.path.exists(INDEX_ROOT):\n    os.mkdir(INDEX_ROOT)\n    \nindex_path = os.path.join(INDEX_ROOT, 'vn-celeb.index.txt')\nif os.path.exists(index_path):\n    os.remove(index_path)\n\nperson_id = 0\nwith open(index_path, 'w') as out_file:\n    sub_name = 'VN-celeb'\n    dataset_path = os.path.join(DATA_ROOT, sub_name)\n    for person_name in os.listdir(dataset_path):\n        person_path = os.path.join(dataset_path, person_name)\n        for img_name in os.listdir(person_path):\n            out_file.write(\"{}\\t{}\\n\".format(os.path.join(sub_name, person_name, img_name), person_id))\n        person_id += 1","metadata":{"execution":{"iopub.status.busy":"2024-09-24T18:12:20.683088Z","iopub.execute_input":"2024-09-24T18:12:20.683501Z","iopub.status.idle":"2024-09-24T18:12:35.509230Z","shell.execute_reply.started":"2024-09-24T18:12:20.683464Z","shell.execute_reply":"2024-09-24T18:12:35.508411Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"%%writefile '/kaggle/working/recognition/tasks/minusface/train.yaml'\nSEED: 1337 # random seed for reproduce results\nDATA_ROOT: '/kaggle/input/vn-celeb' # [fill in this blank] the parent directory where your train/val/test data are stored\nINDEX_ROOT: '/kaggle/working/index_root' # [fill in this blank] the parent directory for index\nDATASETS:\n  - name: 'vn-celeb.index' # [fill in this blank] the name of your dataset\n    batch_size: 16\n    weight: 1.0\n    scale: 64\n    margin: 0.5\n\nBACKBONE_RESUME: \"\"\nHEAD_RESUME: \"\"\nMETA_RESUME: \"\"\n\nINPUT_SIZE: [ 112, 112 ]\nBACKBONE_NAME: 'IR_18' # support: ['IR_18', 'IR_50']\nEMBEDDING_SIZE: 512\n\nMODEL_ROOT: '/kaggle/working/model_root' # the root to buffer your checkpoints\nLOG_ROOT: '/kaggle/working/log_root' # the root to log your train/val status\n\nDIST_FC: true\nHEAD_NAME: \"ArcFace\" # support:  ['ArcFace', 'CurricularFace', 'CosFace']\nLOSS_NAME: 'DistCrossEntropy' # support: ['DistCrossEntropy', 'Softmax']\n\nRGB_MEAN: [ 0.5, 0.5, 0.5 ] # for normalize inputs to [-1, 1]\nRGB_STD: [ 0.5, 0.5, 0.5 ]\n\nLRS: [ 0.01, 0.001, 0.0001, 0.00001 ]\nWARMUP_STEP: -1\nSTAGES: [ 10, 18, 22 ]\n\nSTART_EPOCH: 0 # start epoch\nNUM_EPOCH: 24 # total epoch number\nSAVE_EPOCHS: [ 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24 ]\n\nWEIGHT_DECAY: 0.0005 # do not apply to batch_norm parameters\nMOMENTUM: 0.9\n\nWORLD_SIZE: 1\nRANK: 0\nLOCAL_RANK: 0\nDIST_BACKEND: 'nccl'\nDIST_URL: 'env://'\n\nNUM_WORKERS: 8\n\nAMP: false # fp16 for backbone\n\n# MinusFace\nMETHOD: MinusFace\nTASK: stage1 # toy, stage1, stage2\nNUM_DUPS: 1\nNUM_AUG: 3 # multiplier for data augmentation\nTASK_BACKBONE: 'IR_18' # IR_18, IR_50\nPRETRAIN_CKPT: '' # [fill in this blank] to train the recognition model requires pretrained MinusFace checkpoint\nTASK_VER: 3","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:02:29.056469Z","iopub.execute_input":"2024-09-24T20:02:29.056885Z","iopub.status.idle":"2024-09-24T20:02:29.065296Z","shell.execute_reply.started":"2024-09-24T20:02:29.056848Z","shell.execute_reply":"2024-09-24T20:02:29.064324Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/recognition/tasks/minusface/train.yaml\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Transform input for Minus Face compatible ","metadata":{}},{"cell_type":"code","source":"%%writefile '/kaggle/working/recognition/tasks/partialface/base_task.py'\nimport os\nimport sys\nimport copy\nimport logging\nfrom collections import OrderedDict\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\n\nfrom torchkit.task.base_task import BaseTask\nfrom torchkit.backbone import get_model\nfrom torchkit.head import get_head\nfrom torchkit.util import get_class_split, separate_resnet_bn_paras\nfrom torchkit.data import MultiDataset, MultiDistributedSampler\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s: %(message)s')\n\n\nclass AugmentedMultiDataset(MultiDataset):\n    def __init__(self, data_root, index_root, names, transform, num_aug, **kwargs) -> None:\n        super().__init__(data_root, index_root, names, transform, **kwargs)\n        self.num_aug = num_aug\n\n    def _build_inputs(self, world_size=None, rank=None):\n        \"\"\" Read index file and saved in ``self.inputs``\n            If ``self.is_shard`` is True, ``total_sample_nums`` > ``sample_nums``\n        \"\"\"\n\n        for i, name in enumerate(self.names):\n            index_file = os.path.join(self.index_root, name + \".txt\")\n            self.index_parser.reset()\n            self.inputs[name] = []\n            with open(index_file, 'r') as f:\n                for line_i, line in enumerate(f):\n                    sample = self.index_parser(line)\n                    if self.is_shard is False:\n                        # ============== PartialFace / MinusFace ==============\n                        for i in range(self.num_aug):\n                            self.inputs[name].append(sample)\n                        # =====================================================\n                    else:\n                        if line_i % world_size == rank:\n                            self.inputs[name].append(sample)\n                        else:\n                            pass\n            self.class_nums[name] = self.index_parser.class_num + 1\n            self.sample_nums[name] = len(self.inputs[name])\n            if self.is_shard:\n                self.total_sample_nums[name] = self.index_parser.sample_num\n                logging.info(\"Dataset %s, class_num %d, total_sample_num %d, sample_num %d\" % (\n                    name, self.class_nums[name], self.total_sample_nums[name], self.sample_nums[name]))\n            else:\n                logging.info(\"Dataset %s, class_num %d, sample_num %d\" % (\n                    name, self.class_nums[name], self.sample_nums[name]))\n\n\nclass LocalBaseTask(BaseTask):\n    def __init__(self, cfg_file):\n        super().__init__(cfg_file=cfg_file)\n        # if self.cfg['METHOD'] == 'PartialFace':\n        #     self.num_aug = self.cfg['NUM_AUG']\n        #     self.num_chs = self.cfg['NUM_CHS']\n\n    def make_inputs(self):\n        \"\"\" make datasets\n        \"\"\"\n        rgb_mean = self.cfg['RGB_MEAN']\n        rgb_std = self.cfg['RGB_STD']\n        if self.cfg['METHOD'] == 'MinusFace':\n            transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((112, 112)),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=rgb_mean, std=rgb_std)\n            ])\n        else:\n            transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=rgb_mean, std=rgb_std)\n            ])\n\n        ds_names = list(self.branches.keys())\n        # ============== PartialFace / MinusFace ==============\n        ds = AugmentedMultiDataset(self.cfg['DATA_ROOT'], self.cfg['INDEX_ROOT'], ds_names,\n                                   transform, self.cfg['NUM_AUG'])\n        # =====================================================\n\n        ds.make_dataset(shard=False)\n        self.class_nums = ds.class_nums\n\n        sampler = MultiDistributedSampler(ds, self.batch_sizes)\n        self.train_loader = DataLoader(ds, sum(self.batch_sizes), shuffle=False,\n                                       num_workers=self.cfg[\"NUM_WORKERS\"], pin_memory=True,\n                                       sampler=sampler, drop_last=False)\n\n        self.step_per_epoch = len(self.train_loader)\n        logging.info(\"Step_per_epoch = %d\" % self.step_per_epoch)\n\n    def make_model(self):\n        \"\"\" build training backbone and heads\n        \"\"\"\n\n        # ============== PartialFace / MinusFace ==============\n        if self.cfg['METHOD'] == 'PartialFace':\n\n            backbone_name = self.cfg['BACKBONE_NAME']\n            backbone_model = get_model(backbone_name)\n            self.backbone = backbone_model(self.input_size)\n\n            self.backbone.input_layer = nn.Sequential(nn.Conv2d(self.cfg['NUM_CHS'] * 3, 64, (3, 3), 1, 1, bias=False),\n                                                      nn.BatchNorm2d(64), nn.PReLU(64))\n\n            logging.info(\"{} Backbone Generated\".format(backbone_name))\n\n        else:  # self.cfg['METHOD'] == 'MinusFace'\n            from tasks.minusface.minusface import MinusBackbone\n\n            generator, recognizer = None, None\n\n            recognizer = get_model(self.cfg['TASK_BACKBONE'])([112, 112])\n            print('Recognizer is {}'.format(self.cfg['TASK_BACKBONE']))\n\n            if self.cfg['TASK'] == 'stage2':\n                pretrain_backbone = MinusBackbone(mode='stage1',\n                                                  recognizer=get_model(self.cfg['TASK_BACKBONE'])([112, 112]))\n                pretrain_backbone.load_state_dict(torch.load(self.cfg['PRETRAIN_CKPT']))\n                pretrain_backbone.generator.mode = self.cfg['TASK']\n                generator = copy.deepcopy(pretrain_backbone.generator)\n                print('Load pretrain ckpt: ', self.cfg['PRETRAIN_CKPT'])\n\n            self.backbone = MinusBackbone(mode=self.cfg['TASK'], n_duplicate=1, generator=generator,\n                                          recognizer=recognizer)\n            logging.info(f\"Minus {self.cfg['TASK']} Backbone Generated\")\n        # =====================================================\n\n        self.backbone.cuda()\n\n        embedding_size = self.cfg['EMBEDDING_SIZE']\n        self.class_shards = []\n        metric = get_head(self.cfg['HEAD_NAME'], dist_fc=self.dist_fc)\n\n        for name, branch in self.branches.items():\n            class_num = self.class_nums[name]\n            class_shard = get_class_split(class_num, self.world_size)\n            self.class_shards.append(class_shard)\n            logging.info('Split FC: {}'.format(class_shard))\n\n            init_value = torch.FloatTensor(embedding_size, class_num)\n            init.normal_(init_value, std=0.01)\n            head = metric(in_features=embedding_size,\n                          gpu_index=self.rank,\n                          weight_init=init_value,\n                          class_split=class_shard,\n                          scale=branch.scale,\n                          margin=branch.margin)\n            del init_value\n            head = head.cuda()\n            self.heads[name] = head\n\n    def get_optimizer(self):\n        \"\"\" build optimizers\n        \"\"\"\n\n        learning_rates = self.cfg['LRS']\n        init_lr = learning_rates[0]\n        weight_decay = self.cfg['WEIGHT_DECAY']\n        momentum = self.cfg['MOMENTUM']\n\n        # ===================== MinusFace =====================\n        if self.cfg['METHOD'] == 'Minusface':\n            if self.cfg['TASK'] == 'stage2':\n                backbone_opt = optim.SGD([{'params': self.backbone.recognizer.parameters(), 'lr': init_lr}],\n                                         weight_decay=weight_decay, lr=init_lr, momentum=momentum)\n            else:\n                backbone_opt = optim.SGD([{'params': self.backbone.generator.parameters(), 'lr': init_lr / 10.},\n                                          {'params': self.backbone.recognizer.parameters(), 'lr': init_lr}],\n                                         weight_decay=weight_decay, lr=init_lr, momentum=momentum)\n        else:\n            backbone_paras_only_bn, backbone_paras_wo_bn = separate_resnet_bn_paras(self.backbone)\n            backbone_opt = optim.SGD([\n                {'params': backbone_paras_wo_bn, 'weight_decay': weight_decay},\n                {'params': backbone_paras_only_bn}], lr=init_lr, momentum=momentum)\n        # =====================================================\n\n        head_opts = OrderedDict()\n        for name, head in self.heads.items():\n            opt = optim.SGD([{'params': head.parameters()}], lr=init_lr, momentum=momentum,\n                            weight_decay=weight_decay)\n            head_opts[name] = opt\n\n        optimizer = {\n            'backbone': backbone_opt,\n            'heads': head_opts,\n        }\n        return optimizer\n\n    def loop_step(self, epoch):\n        \"\"\" Implemented by sub class, which run in every training step\n        \"\"\"\n        raise NotImplementedError()\n\n    def train(self):\n        raise NotImplementedError()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T18:21:41.031031Z","iopub.execute_input":"2024-09-24T18:21:41.031413Z","iopub.status.idle":"2024-09-24T18:21:41.043304Z","shell.execute_reply.started":"2024-09-24T18:21:41.031379Z","shell.execute_reply":"2024-09-24T18:21:41.042439Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/recognition/tasks/partialface/base_task.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train Minus Face","metadata":{}},{"cell_type":"code","source":"!mkdir '/kaggle/working/model_root'\n!mkdir '/kaggle/working/log_root'","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:03:25.973544Z","iopub.execute_input":"2024-09-24T20:03:25.974402Z","iopub.status.idle":"2024-09-24T20:03:27.953773Z","shell.execute_reply.started":"2024-09-24T20:03:25.974360Z","shell.execute_reply":"2024-09-24T20:03:27.952475Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%cd '/kaggle/working/recognition/tasks/minusface'","metadata":{"execution":{"iopub.status.busy":"2024-09-28T18:35:14.176952Z","iopub.execute_input":"2024-09-28T18:35:14.177424Z","iopub.status.idle":"2024-09-28T18:35:14.184880Z","shell.execute_reply.started":"2024-09-28T18:35:14.177363Z","shell.execute_reply":"2024-09-28T18:35:14.183971Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/recognition/tasks/minusface\n","output_type":"stream"}]},{"cell_type":"code","source":"!export CUDA_VISIBLE_DEVICES='0'\n!$PYTHON_BIN/python3 -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 train.py","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:03:43.939104Z","iopub.execute_input":"2024-09-24T20:03:43.939496Z","iopub.status.idle":"2024-09-25T03:46:44.794012Z","shell.execute_reply.started":"2024-09-24T20:03:43.939462Z","shell.execute_reply":"2024-09-25T03:46:44.791176Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  warnings.warn(\n2024-09-24 20:03:50,193: Dataset vn-celeb.index, batch_size 16, weight 1.000000, scale 64, margin 0.500000\n2024-09-24 20:03:50,213: Added key: store_based_barrier_key:1 to store for rank: 0\n2024-09-24 20:03:50,214: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n2024-09-24 20:03:50,233: world_size: 1, rank: 0, local_rank: 0\nSEED 1337\nDATA_ROOT /kaggle/input/vn-celeb\nINDEX_ROOT /kaggle/working/index_root\nDATASETS [{'name': 'vn-celeb.index', 'batch_size': 16, 'weight': 1.0, 'scale': 64, 'margin': 0.5}]\nBACKBONE_RESUME \nHEAD_RESUME \nMETA_RESUME \nINPUT_SIZE [112, 112]\nBACKBONE_NAME IR_18\nEMBEDDING_SIZE 512\nMODEL_ROOT /kaggle/working/model_root\nLOG_ROOT /kaggle/working/log_root\nDIST_FC True\nHEAD_NAME ArcFace\nLOSS_NAME DistCrossEntropy\nRGB_MEAN [0.5, 0.5, 0.5]\nRGB_STD [0.5, 0.5, 0.5]\nLRS [0.01, 0.001, 0.0001, 1e-05]\nWARMUP_STEP -1\nSTAGES [10, 18, 22]\nSTART_EPOCH 0\nNUM_EPOCH 24\nSAVE_EPOCHS [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nWEIGHT_DECAY 0.0005\nMOMENTUM 0.9\nWORLD_SIZE 1\nRANK 0\nLOCAL_RANK 0\nDIST_BACKEND nccl\nDIST_URL env://\nNUM_WORKERS 8\nAMP False\nMETHOD MinusFace\nTASK stage1\nNUM_DUPS 1\nNUM_AUG 3\nTASK_BACKBONE IR_18\nPRETRAIN_CKPT \nTASK_VER 3\n2024-09-24 20:03:50,301: Dataset vn-celeb.index, class_num 1020, sample_num 69315\n2024-09-24 20:03:50,301: Dataset vn-celeb.index, total_size 69328, mine_size 69328, batch_num 4333\n2024-09-24 20:03:50,301: MultiDistributedSampler max_batch_num 4333\n/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n2024-09-24 20:03:50,302: Step_per_epoch = 4333\nRecognizer is IR_18\n2024-09-24 20:03:51,030: Minus stage1 Backbone Generated\n2024-09-24 20:03:51,823: Split FC: [1020]\n2024-09-24 20:03:51,827: FC Start Point: [0, 1020]\n2024-09-24 20:03:52,033: Current epoch 1, learning rate 0.01\n[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n2024-09-24 20:04:07,640: Epoch 1 / 24, batch 1 / 4333, 15.6056 sec/batch\n                         loss = [43.713528] gen = [2.114464] fr = [41.599064] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-24 20:04:33,894: Epoch 1 / 24, batch 100 / 4333, 0.4186 sec/batch\n                         loss = [43.887100] gen = [1.968835] fr = [41.918266] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-24 20:05:00,586: Epoch 1 / 24, batch 200 / 4333, 0.3428 sec/batch\n                         loss = [42.858105] gen = [1.625857] fr = [41.232246] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-24 20:05:27,197: Epoch 1 / 24, batch 300 / 4333, 0.3172 sec/batch\n                         loss = [42.991318] gen = [1.271507] fr = [41.719810] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-24 20:05:53,803: Epoch 1 / 24, batch 400 / 4333, 0.3044 sec/batch\n                         loss = [40.638374] gen = [0.862028] fr = [39.776344] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-24 20:06:20,447: Epoch 1 / 24, batch 500 / 4333, 0.2968 sec/batch\n                         loss = [40.353691] gen = [1.313933] fr = [39.039757] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-24 20:06:47,098: Epoch 1 / 24, batch 600 / 4333, 0.2665 sec/batch\n                         loss = [39.867310] gen = [0.629805] fr = [39.237503] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-24 20:07:13,750: Epoch 1 / 24, batch 700 / 4333, 0.2665 sec/batch\n                         loss = [39.401146] gen = [0.571090] fr = [38.830055] spar = [0.000000] prec@1 = [6.250000] prec@5 = [18.750000] \n2024-09-24 20:07:40,401: Epoch 1 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [40.300255] gen = [0.578047] fr = [39.722206] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-24 20:08:07,037: Epoch 1 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [40.494373] gen = [0.554324] fr = [39.940048] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-24 20:08:33,668: Epoch 1 / 24, batch 1000 / 4333, 0.2664 sec/batch\n                         loss = [40.411121] gen = [0.469775] fr = [39.941345] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-24 20:09:00,297: Epoch 1 / 24, batch 1100 / 4333, 0.2663 sec/batch\n                         loss = [38.712433] gen = [0.532373] fr = [38.180061] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-24 20:09:26,938: Epoch 1 / 24, batch 1200 / 4333, 0.2664 sec/batch\n                         loss = [37.608265] gen = [0.578936] fr = [37.029327] spar = [0.000000] prec@1 = [12.500000] prec@5 = [25.000000] \n2024-09-24 20:09:53,573: Epoch 1 / 24, batch 1300 / 4333, 0.2664 sec/batch\n                         loss = [38.117054] gen = [0.413408] fr = [37.703644] spar = [0.000000] prec@1 = [6.250000] prec@5 = [18.750000] \n2024-09-24 20:10:20,209: Epoch 1 / 24, batch 1400 / 4333, 0.2664 sec/batch\n                         loss = [39.350212] gen = [0.865607] fr = [38.484604] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-24 20:10:46,850: Epoch 1 / 24, batch 1500 / 4333, 0.2664 sec/batch\n                         loss = [38.214661] gen = [0.427744] fr = [37.786915] spar = [0.000000] prec@1 = [18.750000] prec@5 = [18.750000] \n2024-09-24 20:11:13,494: Epoch 1 / 24, batch 1600 / 4333, 0.2664 sec/batch\n                         loss = [38.261059] gen = [0.413137] fr = [37.847923] spar = [0.000000] prec@1 = [12.500000] prec@5 = [25.000000] \n2024-09-24 20:11:40,150: Epoch 1 / 24, batch 1700 / 4333, 0.2665 sec/batch\n                         loss = [36.986515] gen = [0.427224] fr = [36.559292] spar = [0.000000] prec@1 = [31.250000] prec@5 = [31.250000] \n2024-09-24 20:12:06,788: Epoch 1 / 24, batch 1800 / 4333, 0.2665 sec/batch\n                         loss = [37.742130] gen = [0.481248] fr = [37.260883] spar = [0.000000] prec@1 = [18.750000] prec@5 = [31.250000] \n2024-09-24 20:12:33,425: Epoch 1 / 24, batch 1900 / 4333, 0.2664 sec/batch\n                         loss = [36.551231] gen = [0.506442] fr = [36.044788] spar = [0.000000] prec@1 = [18.750000] prec@5 = [31.250000] \n2024-09-24 20:13:00,046: Epoch 1 / 24, batch 2000 / 4333, 0.2664 sec/batch\n                         loss = [37.224689] gen = [0.369122] fr = [36.855568] spar = [0.000000] prec@1 = [12.500000] prec@5 = [37.500000] \n2024-09-24 20:13:26,676: Epoch 1 / 24, batch 2100 / 4333, 0.2663 sec/batch\n                         loss = [36.878170] gen = [0.395610] fr = [36.482559] spar = [0.000000] prec@1 = [31.250000] prec@5 = [37.500000] \n2024-09-24 20:13:53,323: Epoch 1 / 24, batch 2200 / 4333, 0.2664 sec/batch\n                         loss = [36.359314] gen = [0.423494] fr = [35.935822] spar = [0.000000] prec@1 = [18.750000] prec@5 = [37.500000] \n2024-09-24 20:14:19,989: Epoch 1 / 24, batch 2300 / 4333, 0.2665 sec/batch\n                         loss = [38.123516] gen = [0.338836] fr = [37.784679] spar = [0.000000] prec@1 = [6.250000] prec@5 = [31.250000] \n2024-09-24 20:14:46,607: Epoch 1 / 24, batch 2400 / 4333, 0.2664 sec/batch\n                         loss = [36.870930] gen = [0.386214] fr = [36.484715] spar = [0.000000] prec@1 = [25.000000] prec@5 = [25.000000] \n2024-09-24 20:15:13,225: Epoch 1 / 24, batch 2500 / 4333, 0.2664 sec/batch\n                         loss = [35.926495] gen = [0.440029] fr = [35.486465] spar = [0.000000] prec@1 = [18.750000] prec@5 = [37.500000] \n2024-09-24 20:15:39,857: Epoch 1 / 24, batch 2600 / 4333, 0.2663 sec/batch\n                         loss = [37.173233] gen = [0.386812] fr = [36.786423] spar = [0.000000] prec@1 = [18.750000] prec@5 = [25.000000] \n2024-09-24 20:16:06,478: Epoch 1 / 24, batch 2700 / 4333, 0.2663 sec/batch\n                         loss = [36.277901] gen = [0.368370] fr = [35.909531] spar = [0.000000] prec@1 = [12.500000] prec@5 = [43.750000] \n2024-09-24 20:16:33,103: Epoch 1 / 24, batch 2800 / 4333, 0.2663 sec/batch\n                         loss = [34.620300] gen = [0.401616] fr = [34.218685] spar = [0.000000] prec@1 = [31.250000] prec@5 = [56.250000] \n2024-09-24 20:16:59,744: Epoch 1 / 24, batch 2900 / 4333, 0.2663 sec/batch\n                         loss = [37.017635] gen = [0.333626] fr = [36.684010] spar = [0.000000] prec@1 = [31.250000] prec@5 = [37.500000] \n2024-09-24 20:17:26,367: Epoch 1 / 24, batch 3000 / 4333, 0.2663 sec/batch\n                         loss = [37.727951] gen = [0.340710] fr = [37.387241] spar = [0.000000] prec@1 = [18.750000] prec@5 = [31.250000] \n2024-09-24 20:17:52,992: Epoch 1 / 24, batch 3100 / 4333, 0.2663 sec/batch\n                         loss = [37.265209] gen = [0.327843] fr = [36.937366] spar = [0.000000] prec@1 = [12.500000] prec@5 = [31.250000] \n2024-09-24 20:18:19,628: Epoch 1 / 24, batch 3200 / 4333, 0.2663 sec/batch\n                         loss = [36.497498] gen = [0.348518] fr = [36.148979] spar = [0.000000] prec@1 = [31.250000] prec@5 = [37.500000] \n2024-09-24 20:18:46,261: Epoch 1 / 24, batch 3300 / 4333, 0.2663 sec/batch\n                         loss = [36.342743] gen = [0.443879] fr = [35.898865] spar = [0.000000] prec@1 = [25.000000] prec@5 = [37.500000] \n2024-09-24 20:19:12,885: Epoch 1 / 24, batch 3400 / 4333, 0.2663 sec/batch\n                         loss = [35.759079] gen = [0.403041] fr = [35.356037] spar = [0.000000] prec@1 = [18.750000] prec@5 = [37.500000] \n2024-09-24 20:19:39,502: Epoch 1 / 24, batch 3500 / 4333, 0.2663 sec/batch\n                         loss = [35.442707] gen = [0.386615] fr = [35.056091] spar = [0.000000] prec@1 = [25.000000] prec@5 = [43.750000] \n2024-09-24 20:20:06,103: Epoch 1 / 24, batch 3600 / 4333, 0.2660 sec/batch\n                         loss = [35.895576] gen = [0.355265] fr = [35.540310] spar = [0.000000] prec@1 = [31.250000] prec@5 = [62.500000] \n2024-09-24 20:20:32,720: Epoch 1 / 24, batch 3700 / 4333, 0.2661 sec/batch\n                         loss = [35.292511] gen = [0.395658] fr = [34.896851] spar = [0.000000] prec@1 = [37.500000] prec@5 = [43.750000] \n2024-09-24 20:20:59,373: Epoch 1 / 24, batch 3800 / 4333, 0.2662 sec/batch\n                         loss = [37.292042] gen = [0.351382] fr = [36.940659] spar = [0.000000] prec@1 = [25.000000] prec@5 = [37.500000] \n2024-09-24 20:21:26,059: Epoch 1 / 24, batch 3900 / 4333, 0.2664 sec/batch\n                         loss = [36.264404] gen = [0.320746] fr = [35.943657] spar = [0.000000] prec@1 = [12.500000] prec@5 = [50.000000] \n2024-09-24 20:21:52,748: Epoch 1 / 24, batch 4000 / 4333, 0.2665 sec/batch\n                         loss = [36.277157] gen = [0.324345] fr = [35.952812] spar = [0.000000] prec@1 = [31.250000] prec@5 = [37.500000] \n2024-09-24 20:22:19,426: Epoch 1 / 24, batch 4100 / 4333, 0.2668 sec/batch\n                         loss = [35.323242] gen = [0.343573] fr = [34.979668] spar = [0.000000] prec@1 = [37.500000] prec@5 = [50.000000] \n2024-09-24 20:22:46,087: Epoch 1 / 24, batch 4200 / 4333, 0.2667 sec/batch\n                         loss = [33.489559] gen = [0.285561] fr = [33.203999] spar = [0.000000] prec@1 = [37.500000] prec@5 = [62.500000] \n2024-09-24 20:23:12,740: Epoch 1 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [34.249283] gen = [0.295624] fr = [33.953659] spar = [0.000000] prec@1 = [25.000000] prec@5 = [68.750000] \n2024-09-24 20:23:22,426: Save checkpoint at epoch 1 ...\n2024-09-24 20:23:22,426: Current epoch 2, learning rate 0.01\n2024-09-24 20:23:22,896: Epoch 2 / 24, batch 1 / 4333, 0.4685 sec/batch\n                         loss = [36.289005] gen = [0.314406] fr = [35.974598] spar = [0.000000] prec@1 = [25.000000] prec@5 = [50.000000] \n2024-09-24 20:23:49,307: Epoch 2 / 24, batch 100 / 4333, 0.2688 sec/batch\n                         loss = [32.146278] gen = [0.267958] fr = [31.878319] spar = [0.000000] prec@1 = [56.250000] prec@5 = [81.250000] \n2024-09-24 20:24:15,964: Epoch 2 / 24, batch 200 / 4333, 0.2677 sec/batch\n                         loss = [33.999229] gen = [0.350904] fr = [33.648327] spar = [0.000000] prec@1 = [25.000000] prec@5 = [56.250000] \n2024-09-24 20:24:42,626: Epoch 2 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [34.985531] gen = [0.354812] fr = [34.630718] spar = [0.000000] prec@1 = [25.000000] prec@5 = [62.500000] \n2024-09-24 20:25:09,287: Epoch 2 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [33.402184] gen = [0.319342] fr = [33.082840] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:25:35,949: Epoch 2 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [34.329811] gen = [0.402240] fr = [33.927570] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:26:02,605: Epoch 2 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [32.430973] gen = [0.323565] fr = [32.107407] spar = [0.000000] prec@1 = [43.750000] prec@5 = [68.750000] \n2024-09-24 20:26:29,261: Epoch 2 / 24, batch 700 / 4333, 0.2666 sec/batch\n                         loss = [31.799391] gen = [0.348570] fr = [31.450821] spar = [0.000000] prec@1 = [56.250000] prec@5 = [68.750000] \n2024-09-24 20:26:55,922: Epoch 2 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [35.288628] gen = [0.341791] fr = [34.946838] spar = [0.000000] prec@1 = [37.500000] prec@5 = [50.000000] \n2024-09-24 20:27:22,570: Epoch 2 / 24, batch 900 / 4333, 0.2666 sec/batch\n                         loss = [33.328697] gen = [0.283233] fr = [33.045464] spar = [0.000000] prec@1 = [43.750000] prec@5 = [75.000000] \n2024-09-24 20:27:49,215: Epoch 2 / 24, batch 1000 / 4333, 0.2665 sec/batch\n                         loss = [33.486885] gen = [0.295680] fr = [33.191204] spar = [0.000000] prec@1 = [50.000000] prec@5 = [50.000000] \n2024-09-24 20:28:15,853: Epoch 2 / 24, batch 1100 / 4333, 0.2664 sec/batch\n                         loss = [33.748539] gen = [0.303292] fr = [33.445248] spar = [0.000000] prec@1 = [43.750000] prec@5 = [56.250000] \n2024-09-24 20:28:42,506: Epoch 2 / 24, batch 1200 / 4333, 0.2665 sec/batch\n                         loss = [34.886383] gen = [0.306022] fr = [34.580360] spar = [0.000000] prec@1 = [31.250000] prec@5 = [62.500000] \n2024-09-24 20:29:09,154: Epoch 2 / 24, batch 1300 / 4333, 0.2665 sec/batch\n                         loss = [35.326614] gen = [0.307779] fr = [35.018837] spar = [0.000000] prec@1 = [31.250000] prec@5 = [43.750000] \n2024-09-24 20:29:35,803: Epoch 2 / 24, batch 1400 / 4333, 0.2665 sec/batch\n                         loss = [31.920963] gen = [0.463418] fr = [31.457546] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 20:30:02,447: Epoch 2 / 24, batch 1500 / 4333, 0.2665 sec/batch\n                         loss = [33.126923] gen = [0.324352] fr = [32.802570] spar = [0.000000] prec@1 = [37.500000] prec@5 = [68.750000] \n2024-09-24 20:30:29,101: Epoch 2 / 24, batch 1600 / 4333, 0.2665 sec/batch\n                         loss = [35.312187] gen = [0.289453] fr = [35.022736] spar = [0.000000] prec@1 = [31.250000] prec@5 = [50.000000] \n2024-09-24 20:30:55,764: Epoch 2 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [31.997524] gen = [0.366847] fr = [31.630676] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 20:31:22,425: Epoch 2 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [34.842594] gen = [0.403933] fr = [34.438660] spar = [0.000000] prec@1 = [31.250000] prec@5 = [37.500000] \n2024-09-24 20:31:49,089: Epoch 2 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [31.146889] gen = [0.288968] fr = [30.857922] spar = [0.000000] prec@1 = [68.750000] prec@5 = [75.000000] \n2024-09-24 20:32:15,745: Epoch 2 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [33.555176] gen = [0.325642] fr = [33.229534] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:32:42,392: Epoch 2 / 24, batch 2100 / 4333, 0.2665 sec/batch\n                         loss = [35.295029] gen = [0.246705] fr = [35.048325] spar = [0.000000] prec@1 = [25.000000] prec@5 = [37.500000] \n2024-09-24 20:33:09,044: Epoch 2 / 24, batch 2200 / 4333, 0.2665 sec/batch\n                         loss = [36.168461] gen = [0.372362] fr = [35.796097] spar = [0.000000] prec@1 = [31.250000] prec@5 = [50.000000] \n2024-09-24 20:33:35,682: Epoch 2 / 24, batch 2300 / 4333, 0.2665 sec/batch\n                         loss = [33.918549] gen = [0.368185] fr = [33.550362] spar = [0.000000] prec@1 = [37.500000] prec@5 = [62.500000] \n2024-09-24 20:34:02,326: Epoch 2 / 24, batch 2400 / 4333, 0.2665 sec/batch\n                         loss = [31.826710] gen = [0.251270] fr = [31.575439] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 20:34:28,968: Epoch 2 / 24, batch 2500 / 4333, 0.2664 sec/batch\n                         loss = [32.258083] gen = [0.244527] fr = [32.013557] spar = [0.000000] prec@1 = [43.750000] prec@5 = [68.750000] \n2024-09-24 20:34:55,592: Epoch 2 / 24, batch 2600 / 4333, 0.2662 sec/batch\n                         loss = [31.076706] gen = [0.272101] fr = [30.804604] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:35:22,206: Epoch 2 / 24, batch 2700 / 4333, 0.2662 sec/batch\n                         loss = [31.340046] gen = [0.254737] fr = [31.085308] spar = [0.000000] prec@1 = [43.750000] prec@5 = [75.000000] \n2024-09-24 20:35:48,829: Epoch 2 / 24, batch 2800 / 4333, 0.2662 sec/batch\n                         loss = [31.968554] gen = [0.266986] fr = [31.701569] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 20:36:15,475: Epoch 2 / 24, batch 2900 / 4333, 0.2663 sec/batch\n                         loss = [30.517332] gen = [0.296672] fr = [30.220661] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 20:36:42,126: Epoch 2 / 24, batch 3000 / 4333, 0.2663 sec/batch\n                         loss = [33.401844] gen = [0.313439] fr = [33.088406] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:37:08,779: Epoch 2 / 24, batch 3100 / 4333, 0.2665 sec/batch\n                         loss = [31.668304] gen = [0.206454] fr = [31.461851] spar = [0.000000] prec@1 = [50.000000] prec@5 = [68.750000] \n2024-09-24 20:37:35,440: Epoch 2 / 24, batch 3200 / 4333, 0.2666 sec/batch\n                         loss = [32.985283] gen = [0.281931] fr = [32.703350] spar = [0.000000] prec@1 = [31.250000] prec@5 = [68.750000] \n2024-09-24 20:38:02,089: Epoch 2 / 24, batch 3300 / 4333, 0.2665 sec/batch\n                         loss = [33.790504] gen = [0.247763] fr = [33.542740] spar = [0.000000] prec@1 = [37.500000] prec@5 = [62.500000] \n2024-09-24 20:38:28,743: Epoch 2 / 24, batch 3400 / 4333, 0.2665 sec/batch\n                         loss = [30.383114] gen = [0.271347] fr = [30.111767] spar = [0.000000] prec@1 = [50.000000] prec@5 = [75.000000] \n2024-09-24 20:38:55,387: Epoch 2 / 24, batch 3500 / 4333, 0.2665 sec/batch\n                         loss = [33.086590] gen = [0.259246] fr = [32.827343] spar = [0.000000] prec@1 = [43.750000] prec@5 = [62.500000] \n2024-09-24 20:39:22,039: Epoch 2 / 24, batch 3600 / 4333, 0.2665 sec/batch\n                         loss = [31.307705] gen = [0.316513] fr = [30.991192] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 20:39:48,720: Epoch 2 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [35.373142] gen = [0.231769] fr = [35.141373] spar = [0.000000] prec@1 = [43.750000] prec@5 = [43.750000] \n2024-09-24 20:40:15,374: Epoch 2 / 24, batch 3800 / 4333, 0.2666 sec/batch\n                         loss = [34.815823] gen = [0.289890] fr = [34.525932] spar = [0.000000] prec@1 = [37.500000] prec@5 = [56.250000] \n2024-09-24 20:40:42,034: Epoch 2 / 24, batch 3900 / 4333, 0.2666 sec/batch\n                         loss = [32.553173] gen = [0.261471] fr = [32.291702] spar = [0.000000] prec@1 = [37.500000] prec@5 = [75.000000] \n2024-09-24 20:41:08,684: Epoch 2 / 24, batch 4000 / 4333, 0.2666 sec/batch\n                         loss = [32.449680] gen = [0.249992] fr = [32.199688] spar = [0.000000] prec@1 = [43.750000] prec@5 = [75.000000] \n2024-09-24 20:41:35,337: Epoch 2 / 24, batch 4100 / 4333, 0.2665 sec/batch\n                         loss = [32.404301] gen = [0.247936] fr = [32.156364] spar = [0.000000] prec@1 = [43.750000] prec@5 = [75.000000] \n2024-09-24 20:42:01,974: Epoch 2 / 24, batch 4200 / 4333, 0.2664 sec/batch\n                         loss = [29.827038] gen = [0.250416] fr = [29.576622] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 20:42:28,608: Epoch 2 / 24, batch 4300 / 4333, 0.2664 sec/batch\n                         loss = [34.300289] gen = [0.231356] fr = [34.068932] spar = [0.000000] prec@1 = [43.750000] prec@5 = [62.500000] \n2024-09-24 20:42:38,261: Save checkpoint at epoch 2 ...\n2024-09-24 20:42:38,261: Current epoch 3, learning rate 0.01\n2024-09-24 20:42:38,707: Epoch 3 / 24, batch 1 / 4333, 0.4453 sec/batch\n                         loss = [29.165087] gen = [0.285333] fr = [28.879753] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 20:43:05,082: Epoch 3 / 24, batch 100 / 4333, 0.2682 sec/batch\n                         loss = [30.508604] gen = [0.347590] fr = [30.161015] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 20:43:31,739: Epoch 3 / 24, batch 200 / 4333, 0.2674 sec/batch\n                         loss = [29.609528] gen = [0.250084] fr = [29.359444] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 20:43:58,406: Epoch 3 / 24, batch 300 / 4333, 0.2671 sec/batch\n                         loss = [27.120358] gen = [0.218872] fr = [26.901485] spar = [0.000000] prec@1 = [68.750000] prec@5 = [75.000000] \n2024-09-24 20:44:25,070: Epoch 3 / 24, batch 400 / 4333, 0.2670 sec/batch\n                         loss = [29.845915] gen = [0.258944] fr = [29.586971] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 20:44:51,730: Epoch 3 / 24, batch 500 / 4333, 0.2669 sec/batch\n                         loss = [32.296814] gen = [0.426546] fr = [31.870268] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:45:18,390: Epoch 3 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [31.586073] gen = [0.249420] fr = [31.336653] spar = [0.000000] prec@1 = [56.250000] prec@5 = [81.250000] \n2024-09-24 20:45:45,062: Epoch 3 / 24, batch 700 / 4333, 0.2667 sec/batch\n                         loss = [27.178307] gen = [0.292336] fr = [26.885971] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 20:46:11,715: Epoch 3 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [31.964029] gen = [0.215825] fr = [31.748203] spar = [0.000000] prec@1 = [62.500000] prec@5 = [68.750000] \n2024-09-24 20:46:38,379: Epoch 3 / 24, batch 900 / 4333, 0.2666 sec/batch\n                         loss = [30.103670] gen = [0.334351] fr = [29.769320] spar = [0.000000] prec@1 = [56.250000] prec@5 = [75.000000] \n2024-09-24 20:47:05,040: Epoch 3 / 24, batch 1000 / 4333, 0.2666 sec/batch\n                         loss = [30.572382] gen = [0.243718] fr = [30.328663] spar = [0.000000] prec@1 = [56.250000] prec@5 = [81.250000] \n2024-09-24 20:47:31,698: Epoch 3 / 24, batch 1100 / 4333, 0.2666 sec/batch\n                         loss = [28.887972] gen = [0.228554] fr = [28.659418] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 20:47:58,359: Epoch 3 / 24, batch 1200 / 4333, 0.2666 sec/batch\n                         loss = [29.019257] gen = [0.236297] fr = [28.782959] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 20:48:25,015: Epoch 3 / 24, batch 1300 / 4333, 0.2666 sec/batch\n                         loss = [29.800266] gen = [0.200313] fr = [29.599953] spar = [0.000000] prec@1 = [50.000000] prec@5 = [62.500000] \n2024-09-24 20:48:51,671: Epoch 3 / 24, batch 1400 / 4333, 0.2666 sec/batch\n                         loss = [29.687605] gen = [0.268995] fr = [29.418610] spar = [0.000000] prec@1 = [50.000000] prec@5 = [68.750000] \n2024-09-24 20:49:18,323: Epoch 3 / 24, batch 1500 / 4333, 0.2666 sec/batch\n                         loss = [29.058361] gen = [0.254108] fr = [28.804253] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 20:49:44,971: Epoch 3 / 24, batch 1600 / 4333, 0.2665 sec/batch\n                         loss = [28.164057] gen = [0.221833] fr = [27.942225] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 20:50:11,608: Epoch 3 / 24, batch 1700 / 4333, 0.2664 sec/batch\n                         loss = [26.172867] gen = [0.224762] fr = [25.948105] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 20:50:38,244: Epoch 3 / 24, batch 1800 / 4333, 0.2664 sec/batch\n                         loss = [27.744980] gen = [0.222209] fr = [27.522772] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 20:51:04,881: Epoch 3 / 24, batch 1900 / 4333, 0.2664 sec/batch\n                         loss = [29.955553] gen = [0.277026] fr = [29.678528] spar = [0.000000] prec@1 = [62.500000] prec@5 = [93.750000] \n2024-09-24 20:51:31,527: Epoch 3 / 24, batch 2000 / 4333, 0.2664 sec/batch\n                         loss = [29.941628] gen = [0.269515] fr = [29.672113] spar = [0.000000] prec@1 = [43.750000] prec@5 = [81.250000] \n2024-09-24 20:51:58,176: Epoch 3 / 24, batch 2100 / 4333, 0.2665 sec/batch\n                         loss = [29.824011] gen = [0.215616] fr = [29.608395] spar = [0.000000] prec@1 = [68.750000] prec@5 = [75.000000] \n2024-09-24 20:52:24,836: Epoch 3 / 24, batch 2200 / 4333, 0.2665 sec/batch\n                         loss = [32.296036] gen = [0.244915] fr = [32.051121] spar = [0.000000] prec@1 = [43.750000] prec@5 = [62.500000] \n2024-09-24 20:52:51,481: Epoch 3 / 24, batch 2300 / 4333, 0.2665 sec/batch\n                         loss = [28.463310] gen = [0.214831] fr = [28.248480] spar = [0.000000] prec@1 = [75.000000] prec@5 = [81.250000] \n2024-09-24 20:53:18,144: Epoch 3 / 24, batch 2400 / 4333, 0.2665 sec/batch\n                         loss = [31.754629] gen = [0.228522] fr = [31.526108] spar = [0.000000] prec@1 = [56.250000] prec@5 = [75.000000] \n2024-09-24 20:53:44,789: Epoch 3 / 24, batch 2500 / 4333, 0.2665 sec/batch\n                         loss = [28.366501] gen = [0.263395] fr = [28.103106] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 20:54:11,422: Epoch 3 / 24, batch 2600 / 4333, 0.2663 sec/batch\n                         loss = [30.538963] gen = [0.226936] fr = [30.312027] spar = [0.000000] prec@1 = [62.500000] prec@5 = [68.750000] \n2024-09-24 20:54:38,074: Epoch 3 / 24, batch 2700 / 4333, 0.2664 sec/batch\n                         loss = [27.369194] gen = [0.218804] fr = [27.150391] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 20:55:04,726: Epoch 3 / 24, batch 2800 / 4333, 0.2665 sec/batch\n                         loss = [30.348600] gen = [0.247278] fr = [30.101322] spar = [0.000000] prec@1 = [62.500000] prec@5 = [68.750000] \n2024-09-24 20:55:31,386: Epoch 3 / 24, batch 2900 / 4333, 0.2665 sec/batch\n                         loss = [25.375834] gen = [0.252718] fr = [25.123116] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 20:55:58,036: Epoch 3 / 24, batch 3000 / 4333, 0.2665 sec/batch\n                         loss = [31.177462] gen = [0.226717] fr = [30.950745] spar = [0.000000] prec@1 = [31.250000] prec@5 = [75.000000] \n2024-09-24 20:56:24,692: Epoch 3 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [28.724781] gen = [0.196923] fr = [28.527859] spar = [0.000000] prec@1 = [75.000000] prec@5 = [81.250000] \n2024-09-24 20:56:51,340: Epoch 3 / 24, batch 3200 / 4333, 0.2665 sec/batch\n                         loss = [29.030476] gen = [0.281501] fr = [28.748974] spar = [0.000000] prec@1 = [62.500000] prec@5 = [68.750000] \n2024-09-24 20:57:17,974: Epoch 3 / 24, batch 3300 / 4333, 0.2665 sec/batch\n                         loss = [25.557629] gen = [0.252364] fr = [25.305264] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 20:57:44,587: Epoch 3 / 24, batch 3400 / 4333, 0.2664 sec/batch\n                         loss = [30.391760] gen = [0.225435] fr = [30.166325] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 20:58:11,218: Epoch 3 / 24, batch 3500 / 4333, 0.2664 sec/batch\n                         loss = [29.766819] gen = [0.243616] fr = [29.523203] spar = [0.000000] prec@1 = [56.250000] prec@5 = [81.250000] \n2024-09-24 20:58:37,859: Epoch 3 / 24, batch 3600 / 4333, 0.2664 sec/batch\n                         loss = [29.282913] gen = [0.196816] fr = [29.086098] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 20:59:04,501: Epoch 3 / 24, batch 3700 / 4333, 0.2664 sec/batch\n                         loss = [29.962784] gen = [0.235021] fr = [29.727764] spar = [0.000000] prec@1 = [56.250000] prec@5 = [81.250000] \n2024-09-24 20:59:31,149: Epoch 3 / 24, batch 3800 / 4333, 0.2664 sec/batch\n                         loss = [26.958014] gen = [0.232966] fr = [26.725048] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 20:59:57,856: Epoch 3 / 24, batch 3900 / 4333, 0.2666 sec/batch\n                         loss = [28.574247] gen = [0.191398] fr = [28.382849] spar = [0.000000] prec@1 = [56.250000] prec@5 = [87.500000] \n2024-09-24 21:00:24,528: Epoch 3 / 24, batch 4000 / 4333, 0.2666 sec/batch\n                         loss = [27.931622] gen = [0.191829] fr = [27.739792] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 21:00:51,191: Epoch 3 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [32.681385] gen = [0.237112] fr = [32.444275] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 21:01:17,888: Epoch 3 / 24, batch 4200 / 4333, 0.2668 sec/batch\n                         loss = [33.772678] gen = [0.270321] fr = [33.502357] spar = [0.000000] prec@1 = [31.250000] prec@5 = [68.750000] \n2024-09-24 21:01:44,548: Epoch 3 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [27.145609] gen = [0.214376] fr = [26.931232] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:01:54,206: Save checkpoint at epoch 3 ...\n2024-09-24 21:01:54,206: Current epoch 4, learning rate 0.01\n2024-09-24 21:01:54,680: Epoch 4 / 24, batch 1 / 4333, 0.4732 sec/batch\n                         loss = [27.082624] gen = [0.165244] fr = [26.917381] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 21:02:21,076: Epoch 4 / 24, batch 100 / 4333, 0.2687 sec/batch\n                         loss = [24.854813] gen = [0.249195] fr = [24.605618] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:02:47,732: Epoch 4 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [26.080114] gen = [0.194703] fr = [25.885412] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 21:03:14,381: Epoch 4 / 24, batch 300 / 4333, 0.2672 sec/batch\n                         loss = [28.027227] gen = [0.277838] fr = [27.749390] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 21:03:41,022: Epoch 4 / 24, batch 400 / 4333, 0.2670 sec/batch\n                         loss = [24.438852] gen = [0.240538] fr = [24.198315] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:04:07,669: Epoch 4 / 24, batch 500 / 4333, 0.2669 sec/batch\n                         loss = [26.686060] gen = [0.257799] fr = [26.428261] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:04:34,302: Epoch 4 / 24, batch 600 / 4333, 0.2663 sec/batch\n                         loss = [24.862370] gen = [0.219773] fr = [24.642597] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:05:00,939: Epoch 4 / 24, batch 700 / 4333, 0.2664 sec/batch\n                         loss = [25.175861] gen = [0.172688] fr = [25.003174] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:05:27,567: Epoch 4 / 24, batch 800 / 4333, 0.2663 sec/batch\n                         loss = [26.221937] gen = [0.176435] fr = [26.045502] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:05:54,199: Epoch 4 / 24, batch 900 / 4333, 0.2663 sec/batch\n                         loss = [28.301498] gen = [0.227513] fr = [28.073986] spar = [0.000000] prec@1 = [75.000000] prec@5 = [75.000000] \n2024-09-24 21:06:20,844: Epoch 4 / 24, batch 1000 / 4333, 0.2664 sec/batch\n                         loss = [26.525290] gen = [0.205761] fr = [26.319529] spar = [0.000000] prec@1 = [75.000000] prec@5 = [81.250000] \n2024-09-24 21:06:47,496: Epoch 4 / 24, batch 1100 / 4333, 0.2665 sec/batch\n                         loss = [26.108624] gen = [0.193331] fr = [25.915293] spar = [0.000000] prec@1 = [81.250000] prec@5 = [81.250000] \n2024-09-24 21:07:14,146: Epoch 4 / 24, batch 1200 / 4333, 0.2665 sec/batch\n                         loss = [24.715754] gen = [0.214868] fr = [24.500887] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 21:07:40,791: Epoch 4 / 24, batch 1300 / 4333, 0.2665 sec/batch\n                         loss = [27.740133] gen = [0.221437] fr = [27.518696] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:08:07,439: Epoch 4 / 24, batch 1400 / 4333, 0.2665 sec/batch\n                         loss = [24.322838] gen = [0.212909] fr = [24.109928] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:08:34,086: Epoch 4 / 24, batch 1500 / 4333, 0.2665 sec/batch\n                         loss = [22.696299] gen = [0.183241] fr = [22.513058] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:09:00,736: Epoch 4 / 24, batch 1600 / 4333, 0.2665 sec/batch\n                         loss = [29.687305] gen = [0.229271] fr = [29.458035] spar = [0.000000] prec@1 = [62.500000] prec@5 = [93.750000] \n2024-09-24 21:09:27,382: Epoch 4 / 24, batch 1700 / 4333, 0.2665 sec/batch\n                         loss = [30.134809] gen = [0.244683] fr = [29.890125] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 21:09:54,038: Epoch 4 / 24, batch 1800 / 4333, 0.2665 sec/batch\n                         loss = [28.395994] gen = [0.226345] fr = [28.169649] spar = [0.000000] prec@1 = [62.500000] prec@5 = [87.500000] \n2024-09-24 21:10:20,703: Epoch 4 / 24, batch 1900 / 4333, 0.2665 sec/batch\n                         loss = [27.673977] gen = [0.208545] fr = [27.465431] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 21:10:47,393: Epoch 4 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [27.307571] gen = [0.168785] fr = [27.138786] spar = [0.000000] prec@1 = [81.250000] prec@5 = [81.250000] \n2024-09-24 21:11:14,114: Epoch 4 / 24, batch 2100 / 4333, 0.2672 sec/batch\n                         loss = [28.743795] gen = [0.211881] fr = [28.531914] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 21:11:40,830: Epoch 4 / 24, batch 2200 / 4333, 0.2672 sec/batch\n                         loss = [27.926785] gen = [0.211475] fr = [27.715309] spar = [0.000000] prec@1 = [62.500000] prec@5 = [87.500000] \n2024-09-24 21:12:07,540: Epoch 4 / 24, batch 2300 / 4333, 0.2672 sec/batch\n                         loss = [24.563135] gen = [0.226751] fr = [24.336384] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 21:12:34,242: Epoch 4 / 24, batch 2400 / 4333, 0.2671 sec/batch\n                         loss = [27.517565] gen = [0.205858] fr = [27.311707] spar = [0.000000] prec@1 = [56.250000] prec@5 = [75.000000] \n2024-09-24 21:13:00,938: Epoch 4 / 24, batch 2500 / 4333, 0.2671 sec/batch\n                         loss = [26.648304] gen = [0.238954] fr = [26.409349] spar = [0.000000] prec@1 = [62.500000] prec@5 = [62.500000] \n2024-09-24 21:13:27,649: Epoch 4 / 24, batch 2600 / 4333, 0.2671 sec/batch\n                         loss = [26.940176] gen = [0.225083] fr = [26.715094] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 21:13:54,363: Epoch 4 / 24, batch 2700 / 4333, 0.2671 sec/batch\n                         loss = [25.286455] gen = [0.228971] fr = [25.057484] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:14:21,068: Epoch 4 / 24, batch 2800 / 4333, 0.2671 sec/batch\n                         loss = [27.126732] gen = [0.177735] fr = [26.948997] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:14:47,782: Epoch 4 / 24, batch 2900 / 4333, 0.2671 sec/batch\n                         loss = [24.431339] gen = [0.221977] fr = [24.209362] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:15:14,480: Epoch 4 / 24, batch 3000 / 4333, 0.2671 sec/batch\n                         loss = [23.072701] gen = [0.219591] fr = [22.853109] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:15:41,196: Epoch 4 / 24, batch 3100 / 4333, 0.2672 sec/batch\n                         loss = [23.677309] gen = [0.203714] fr = [23.473595] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:16:07,902: Epoch 4 / 24, batch 3200 / 4333, 0.2671 sec/batch\n                         loss = [26.408051] gen = [0.217945] fr = [26.190105] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:16:34,604: Epoch 4 / 24, batch 3300 / 4333, 0.2671 sec/batch\n                         loss = [22.898643] gen = [0.214711] fr = [22.683933] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:17:01,311: Epoch 4 / 24, batch 3400 / 4333, 0.2671 sec/batch\n                         loss = [29.293011] gen = [0.208945] fr = [29.084066] spar = [0.000000] prec@1 = [62.500000] prec@5 = [81.250000] \n2024-09-24 21:17:27,993: Epoch 4 / 24, batch 3500 / 4333, 0.2670 sec/batch\n                         loss = [26.759289] gen = [0.186917] fr = [26.572372] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:17:54,678: Epoch 4 / 24, batch 3600 / 4333, 0.2669 sec/batch\n                         loss = [29.029692] gen = [0.254059] fr = [28.775633] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:18:21,353: Epoch 4 / 24, batch 3700 / 4333, 0.2668 sec/batch\n                         loss = [27.630289] gen = [0.267806] fr = [27.362484] spar = [0.000000] prec@1 = [75.000000] prec@5 = [81.250000] \n2024-09-24 21:18:48,034: Epoch 4 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [25.436152] gen = [0.208651] fr = [25.227501] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:19:14,699: Epoch 4 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [28.127905] gen = [0.187128] fr = [27.940777] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:19:41,353: Epoch 4 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [21.929550] gen = [0.182521] fr = [21.747028] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:20:08,007: Epoch 4 / 24, batch 4100 / 4333, 0.2665 sec/batch\n                         loss = [27.026596] gen = [0.184803] fr = [26.841793] spar = [0.000000] prec@1 = [68.750000] prec@5 = [68.750000] \n2024-09-24 21:20:34,674: Epoch 4 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [28.578220] gen = [0.248657] fr = [28.329563] spar = [0.000000] prec@1 = [62.500000] prec@5 = [68.750000] \n2024-09-24 21:21:01,351: Epoch 4 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [24.806986] gen = [0.206507] fr = [24.600479] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 21:21:11,024: Save checkpoint at epoch 4 ...\n2024-09-24 21:21:11,024: Current epoch 5, learning rate 0.01\n2024-09-24 21:21:11,474: Epoch 5 / 24, batch 1 / 4333, 0.4483 sec/batch\n                         loss = [25.202873] gen = [0.240333] fr = [24.962540] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:21:37,897: Epoch 5 / 24, batch 100 / 4333, 0.2687 sec/batch\n                         loss = [20.863726] gen = [0.211107] fr = [20.652618] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:22:04,571: Epoch 5 / 24, batch 200 / 4333, 0.2677 sec/batch\n                         loss = [29.377146] gen = [0.192470] fr = [29.184675] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:22:31,249: Epoch 5 / 24, batch 300 / 4333, 0.2674 sec/batch\n                         loss = [25.202389] gen = [0.199490] fr = [25.002899] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:22:57,925: Epoch 5 / 24, batch 400 / 4333, 0.2672 sec/batch\n                         loss = [24.634817] gen = [0.179508] fr = [24.455309] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:23:24,593: Epoch 5 / 24, batch 500 / 4333, 0.2671 sec/batch\n                         loss = [20.236393] gen = [0.205063] fr = [20.031330] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:23:51,255: Epoch 5 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [19.109486] gen = [0.240811] fr = [18.868675] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:24:17,922: Epoch 5 / 24, batch 700 / 4333, 0.2666 sec/batch\n                         loss = [25.195219] gen = [0.170744] fr = [25.024475] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:24:44,585: Epoch 5 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [25.808897] gen = [0.192843] fr = [25.616055] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:25:11,254: Epoch 5 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [25.348646] gen = [0.187991] fr = [25.160656] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:25:37,927: Epoch 5 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [24.067259] gen = [0.184256] fr = [23.883003] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:26:04,598: Epoch 5 / 24, batch 1100 / 4333, 0.2667 sec/batch\n                         loss = [24.272966] gen = [0.160418] fr = [24.112549] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:26:31,263: Epoch 5 / 24, batch 1200 / 4333, 0.2667 sec/batch\n                         loss = [26.181791] gen = [0.186486] fr = [25.995304] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:26:57,933: Epoch 5 / 24, batch 1300 / 4333, 0.2667 sec/batch\n                         loss = [26.156818] gen = [0.192859] fr = [25.963961] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 21:27:24,594: Epoch 5 / 24, batch 1400 / 4333, 0.2667 sec/batch\n                         loss = [23.088009] gen = [0.179165] fr = [22.908844] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:27:51,244: Epoch 5 / 24, batch 1500 / 4333, 0.2666 sec/batch\n                         loss = [24.865162] gen = [0.178886] fr = [24.686275] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 21:28:17,905: Epoch 5 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [24.540834] gen = [0.181248] fr = [24.359587] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:28:44,578: Epoch 5 / 24, batch 1700 / 4333, 0.2667 sec/batch\n                         loss = [27.349052] gen = [0.200691] fr = [27.148361] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:29:11,251: Epoch 5 / 24, batch 1800 / 4333, 0.2667 sec/batch\n                         loss = [27.858149] gen = [0.183142] fr = [27.675007] spar = [0.000000] prec@1 = [62.500000] prec@5 = [75.000000] \n2024-09-24 21:29:37,925: Epoch 5 / 24, batch 1900 / 4333, 0.2667 sec/batch\n                         loss = [23.597176] gen = [0.238078] fr = [23.359098] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:30:04,590: Epoch 5 / 24, batch 2000 / 4333, 0.2667 sec/batch\n                         loss = [20.663607] gen = [0.226682] fr = [20.436924] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:30:31,257: Epoch 5 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [22.128178] gen = [0.207287] fr = [21.920891] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:30:57,928: Epoch 5 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [25.589094] gen = [0.186167] fr = [25.402927] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:31:24,604: Epoch 5 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [21.972603] gen = [0.175327] fr = [21.797276] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:31:51,271: Epoch 5 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [26.918242] gen = [0.203188] fr = [26.715054] spar = [0.000000] prec@1 = [68.750000] prec@5 = [87.500000] \n2024-09-24 21:32:17,934: Epoch 5 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [24.177681] gen = [0.169582] fr = [24.008099] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:32:44,598: Epoch 5 / 24, batch 2600 / 4333, 0.2666 sec/batch\n                         loss = [27.609079] gen = [0.156184] fr = [27.452896] spar = [0.000000] prec@1 = [75.000000] prec@5 = [81.250000] \n2024-09-24 21:33:11,267: Epoch 5 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [19.735767] gen = [0.302220] fr = [19.433548] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:33:37,929: Epoch 5 / 24, batch 2800 / 4333, 0.2667 sec/batch\n                         loss = [21.086908] gen = [0.173428] fr = [20.913481] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:34:04,602: Epoch 5 / 24, batch 2900 / 4333, 0.2667 sec/batch\n                         loss = [24.265823] gen = [0.163080] fr = [24.102743] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:34:31,278: Epoch 5 / 24, batch 3000 / 4333, 0.2667 sec/batch\n                         loss = [20.892111] gen = [0.198706] fr = [20.693405] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:34:57,935: Epoch 5 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [25.473063] gen = [0.240760] fr = [25.232302] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:35:24,587: Epoch 5 / 24, batch 3200 / 4333, 0.2665 sec/batch\n                         loss = [25.835920] gen = [0.225873] fr = [25.610046] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 21:35:51,247: Epoch 5 / 24, batch 3300 / 4333, 0.2666 sec/batch\n                         loss = [24.315561] gen = [0.175946] fr = [24.139616] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:36:17,918: Epoch 5 / 24, batch 3400 / 4333, 0.2666 sec/batch\n                         loss = [20.268349] gen = [0.212650] fr = [20.055698] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:36:44,575: Epoch 5 / 24, batch 3500 / 4333, 0.2666 sec/batch\n                         loss = [19.952370] gen = [0.174481] fr = [19.777887] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:37:11,239: Epoch 5 / 24, batch 3600 / 4333, 0.2666 sec/batch\n                         loss = [24.699272] gen = [0.228452] fr = [24.470819] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:37:37,910: Epoch 5 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [25.363308] gen = [0.195500] fr = [25.167809] spar = [0.000000] prec@1 = [68.750000] prec@5 = [81.250000] \n2024-09-24 21:38:04,577: Epoch 5 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [24.736395] gen = [0.204909] fr = [24.531487] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:38:31,241: Epoch 5 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [19.934528] gen = [0.173887] fr = [19.760641] spar = [0.000000] prec@1 = [81.250000] prec@5 = [81.250000] \n2024-09-24 21:38:57,904: Epoch 5 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [25.704077] gen = [0.194544] fr = [25.509533] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:39:24,571: Epoch 5 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [22.653830] gen = [0.172508] fr = [22.481321] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:39:51,243: Epoch 5 / 24, batch 4200 / 4333, 0.2667 sec/batch\n                         loss = [21.144762] gen = [0.172163] fr = [20.972599] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:40:17,918: Epoch 5 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [21.482752] gen = [0.221196] fr = [21.261555] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:40:27,579: Save checkpoint at epoch 5 ...\n2024-09-24 21:40:27,579: Current epoch 6, learning rate 0.01\n2024-09-24 21:40:28,007: Epoch 6 / 24, batch 1 / 4333, 0.4270 sec/batch\n                         loss = [23.572426] gen = [0.192680] fr = [23.379745] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:40:54,414: Epoch 6 / 24, batch 100 / 4333, 0.2683 sec/batch\n                         loss = [20.868353] gen = [0.207902] fr = [20.660452] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:41:21,083: Epoch 6 / 24, batch 200 / 4333, 0.2675 sec/batch\n                         loss = [18.621689] gen = [0.245274] fr = [18.376415] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:41:47,724: Epoch 6 / 24, batch 300 / 4333, 0.2671 sec/batch\n                         loss = [21.201113] gen = [0.193549] fr = [21.007563] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:42:14,358: Epoch 6 / 24, batch 400 / 4333, 0.2669 sec/batch\n                         loss = [23.173098] gen = [0.176367] fr = [22.996731] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:42:41,000: Epoch 6 / 24, batch 500 / 4333, 0.2668 sec/batch\n                         loss = [22.312859] gen = [0.166736] fr = [22.146122] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:43:07,638: Epoch 6 / 24, batch 600 / 4333, 0.2664 sec/batch\n                         loss = [20.357450] gen = [0.288897] fr = [20.068554] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:43:34,282: Epoch 6 / 24, batch 700 / 4333, 0.2664 sec/batch\n                         loss = [23.875618] gen = [0.164032] fr = [23.711586] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:44:00,962: Epoch 6 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [20.106236] gen = [0.170208] fr = [19.936028] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:44:27,619: Epoch 6 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [18.829100] gen = [0.191454] fr = [18.637646] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:44:54,295: Epoch 6 / 24, batch 1000 / 4333, 0.2666 sec/batch\n                         loss = [24.772026] gen = [0.220241] fr = [24.551785] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 21:45:20,987: Epoch 6 / 24, batch 1100 / 4333, 0.2669 sec/batch\n                         loss = [21.530899] gen = [0.173124] fr = [21.357775] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:45:47,664: Epoch 6 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [24.580111] gen = [0.220289] fr = [24.359821] spar = [0.000000] prec@1 = [75.000000] prec@5 = [87.500000] \n2024-09-24 21:46:14,331: Epoch 6 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [19.783300] gen = [0.183187] fr = [19.600115] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:46:41,018: Epoch 6 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [22.358362] gen = [0.196242] fr = [22.162121] spar = [0.000000] prec@1 = [75.000000] prec@5 = [100.000000] \n2024-09-24 21:47:07,695: Epoch 6 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [20.671124] gen = [0.196210] fr = [20.474913] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:47:34,373: Epoch 6 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [20.134087] gen = [0.236654] fr = [19.897432] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:48:01,052: Epoch 6 / 24, batch 1700 / 4333, 0.2668 sec/batch\n                         loss = [24.259134] gen = [0.164441] fr = [24.094694] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 21:48:27,735: Epoch 6 / 24, batch 1800 / 4333, 0.2668 sec/batch\n                         loss = [22.908688] gen = [0.191002] fr = [22.717686] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:48:54,426: Epoch 6 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [21.130886] gen = [0.206704] fr = [20.924183] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:49:21,105: Epoch 6 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [21.287373] gen = [0.249089] fr = [21.038282] spar = [0.000000] prec@1 = [81.250000] prec@5 = [81.250000] \n2024-09-24 21:49:47,779: Epoch 6 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [21.020052] gen = [0.175999] fr = [20.844053] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:50:14,443: Epoch 6 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [22.247831] gen = [0.265292] fr = [21.982540] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:50:41,108: Epoch 6 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [20.599089] gen = [0.203684] fr = [20.395405] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:51:07,797: Epoch 6 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [20.365135] gen = [0.194782] fr = [20.170353] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:51:34,478: Epoch 6 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [20.827475] gen = [0.227739] fr = [20.599735] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:52:01,162: Epoch 6 / 24, batch 2600 / 4333, 0.2668 sec/batch\n                         loss = [21.404783] gen = [0.171856] fr = [21.232927] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 21:52:27,835: Epoch 6 / 24, batch 2700 / 4333, 0.2668 sec/batch\n                         loss = [19.637077] gen = [0.220924] fr = [19.416153] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:52:54,509: Epoch 6 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [19.990940] gen = [0.209238] fr = [19.781702] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:53:21,196: Epoch 6 / 24, batch 2900 / 4333, 0.2668 sec/batch\n                         loss = [23.146881] gen = [0.173082] fr = [22.973799] spar = [0.000000] prec@1 = [75.000000] prec@5 = [93.750000] \n2024-09-24 21:53:47,881: Epoch 6 / 24, batch 3000 / 4333, 0.2668 sec/batch\n                         loss = [20.609856] gen = [0.180680] fr = [20.429176] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:54:14,566: Epoch 6 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [18.899733] gen = [0.216223] fr = [18.683510] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:54:41,247: Epoch 6 / 24, batch 3200 / 4333, 0.2668 sec/batch\n                         loss = [22.719267] gen = [0.236826] fr = [22.482441] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:55:07,918: Epoch 6 / 24, batch 3300 / 4333, 0.2668 sec/batch\n                         loss = [21.866514] gen = [0.197054] fr = [21.669460] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:55:34,602: Epoch 6 / 24, batch 3400 / 4333, 0.2668 sec/batch\n                         loss = [23.267899] gen = [0.155301] fr = [23.112598] spar = [0.000000] prec@1 = [81.250000] prec@5 = [81.250000] \n2024-09-24 21:56:01,275: Epoch 6 / 24, batch 3500 / 4333, 0.2668 sec/batch\n                         loss = [23.325281] gen = [0.175642] fr = [23.149639] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 21:56:27,955: Epoch 6 / 24, batch 3600 / 4333, 0.2668 sec/batch\n                         loss = [20.277311] gen = [0.235705] fr = [20.041607] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 21:56:54,642: Epoch 6 / 24, batch 3700 / 4333, 0.2668 sec/batch\n                         loss = [23.354177] gen = [0.171804] fr = [23.182373] spar = [0.000000] prec@1 = [81.250000] prec@5 = [93.750000] \n2024-09-24 21:57:21,320: Epoch 6 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [21.432774] gen = [0.183735] fr = [21.249039] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 21:57:47,993: Epoch 6 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [17.993637] gen = [0.178848] fr = [17.814789] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 21:58:14,666: Epoch 6 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [20.061710] gen = [0.191226] fr = [19.870483] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:58:41,339: Epoch 6 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [19.686201] gen = [0.171537] fr = [19.514664] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 21:59:08,025: Epoch 6 / 24, batch 4200 / 4333, 0.2668 sec/batch\n                         loss = [18.619547] gen = [0.231731] fr = [18.387815] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:59:34,700: Epoch 6 / 24, batch 4300 / 4333, 0.2668 sec/batch\n                         loss = [19.298204] gen = [0.224879] fr = [19.073326] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 21:59:44,367: Save checkpoint at epoch 6 ...\n2024-09-24 21:59:44,367: Current epoch 7, learning rate 0.01\n2024-09-24 21:59:44,832: Epoch 7 / 24, batch 1 / 4333, 0.4629 sec/batch\n                         loss = [14.241456] gen = [0.213380] fr = [14.028076] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:00:11,233: Epoch 7 / 24, batch 100 / 4333, 0.2686 sec/batch\n                         loss = [16.758583] gen = [0.175548] fr = [16.583035] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:00:37,928: Epoch 7 / 24, batch 200 / 4333, 0.2678 sec/batch\n                         loss = [20.343990] gen = [0.205043] fr = [20.138948] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:01:04,621: Epoch 7 / 24, batch 300 / 4333, 0.2675 sec/batch\n                         loss = [19.691055] gen = [0.162167] fr = [19.528889] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:01:31,302: Epoch 7 / 24, batch 400 / 4333, 0.2673 sec/batch\n                         loss = [18.017389] gen = [0.220257] fr = [17.797132] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:01:57,993: Epoch 7 / 24, batch 500 / 4333, 0.2672 sec/batch\n                         loss = [20.101006] gen = [0.229346] fr = [19.871658] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:02:24,693: Epoch 7 / 24, batch 600 / 4333, 0.2670 sec/batch\n                         loss = [14.688734] gen = [0.223819] fr = [14.464915] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:02:51,374: Epoch 7 / 24, batch 700 / 4333, 0.2669 sec/batch\n                         loss = [13.983948] gen = [0.234151] fr = [13.749796] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:03:18,063: Epoch 7 / 24, batch 800 / 4333, 0.2669 sec/batch\n                         loss = [19.549582] gen = [0.159421] fr = [19.390160] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 22:03:44,742: Epoch 7 / 24, batch 900 / 4333, 0.2669 sec/batch\n                         loss = [15.482753] gen = [0.239394] fr = [15.243359] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:04:11,428: Epoch 7 / 24, batch 1000 / 4333, 0.2669 sec/batch\n                         loss = [18.345108] gen = [0.212436] fr = [18.132671] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:04:38,110: Epoch 7 / 24, batch 1100 / 4333, 0.2668 sec/batch\n                         loss = [17.861912] gen = [0.237644] fr = [17.624268] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:05:04,798: Epoch 7 / 24, batch 1200 / 4333, 0.2669 sec/batch\n                         loss = [18.458553] gen = [0.210629] fr = [18.247925] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 22:05:31,483: Epoch 7 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [22.146114] gen = [0.146422] fr = [21.999693] spar = [0.000000] prec@1 = [68.750000] prec@5 = [93.750000] \n2024-09-24 22:05:58,171: Epoch 7 / 24, batch 1400 / 4333, 0.2669 sec/batch\n                         loss = [20.428919] gen = [0.155004] fr = [20.273914] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:06:24,866: Epoch 7 / 24, batch 1500 / 4333, 0.2669 sec/batch\n                         loss = [19.216560] gen = [0.190668] fr = [19.025892] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:06:51,551: Epoch 7 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [21.658319] gen = [0.176420] fr = [21.481899] spar = [0.000000] prec@1 = [81.250000] prec@5 = [87.500000] \n2024-09-24 22:07:18,242: Epoch 7 / 24, batch 1700 / 4333, 0.2669 sec/batch\n                         loss = [16.886995] gen = [0.243026] fr = [16.643970] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:07:44,931: Epoch 7 / 24, batch 1800 / 4333, 0.2669 sec/batch\n                         loss = [15.607603] gen = [0.245628] fr = [15.361975] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:08:11,612: Epoch 7 / 24, batch 1900 / 4333, 0.2669 sec/batch\n                         loss = [16.301163] gen = [0.191013] fr = [16.110149] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:08:38,303: Epoch 7 / 24, batch 2000 / 4333, 0.2669 sec/batch\n                         loss = [18.430878] gen = [0.222866] fr = [18.208012] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:09:04,985: Epoch 7 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [13.741261] gen = [0.178315] fr = [13.562946] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:09:31,675: Epoch 7 / 24, batch 2200 / 4333, 0.2669 sec/batch\n                         loss = [15.544443] gen = [0.169416] fr = [15.375027] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:09:58,358: Epoch 7 / 24, batch 2300 / 4333, 0.2669 sec/batch\n                         loss = [18.116282] gen = [0.185216] fr = [17.931065] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 22:10:25,038: Epoch 7 / 24, batch 2400 / 4333, 0.2668 sec/batch\n                         loss = [13.964535] gen = [0.204735] fr = [13.759800] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:10:51,718: Epoch 7 / 24, batch 2500 / 4333, 0.2668 sec/batch\n                         loss = [13.935992] gen = [0.200692] fr = [13.735300] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:11:18,401: Epoch 7 / 24, batch 2600 / 4333, 0.2668 sec/batch\n                         loss = [18.365107] gen = [0.227003] fr = [18.138103] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:11:45,095: Epoch 7 / 24, batch 2700 / 4333, 0.2669 sec/batch\n                         loss = [16.384258] gen = [0.165242] fr = [16.219017] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:12:11,787: Epoch 7 / 24, batch 2800 / 4333, 0.2669 sec/batch\n                         loss = [17.547171] gen = [0.188300] fr = [17.358870] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:12:38,481: Epoch 7 / 24, batch 2900 / 4333, 0.2669 sec/batch\n                         loss = [18.262390] gen = [0.190289] fr = [18.072102] spar = [0.000000] prec@1 = [87.500000] prec@5 = [87.500000] \n2024-09-24 22:13:05,160: Epoch 7 / 24, batch 3000 / 4333, 0.2669 sec/batch\n                         loss = [14.961876] gen = [0.162192] fr = [14.799684] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:13:31,841: Epoch 7 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [17.703014] gen = [0.169651] fr = [17.533363] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:13:58,535: Epoch 7 / 24, batch 3200 / 4333, 0.2669 sec/batch\n                         loss = [17.344690] gen = [0.167362] fr = [17.177328] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:14:25,220: Epoch 7 / 24, batch 3300 / 4333, 0.2669 sec/batch\n                         loss = [19.528366] gen = [0.167199] fr = [19.361168] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:14:51,908: Epoch 7 / 24, batch 3400 / 4333, 0.2669 sec/batch\n                         loss = [18.051702] gen = [0.195016] fr = [17.856688] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:15:18,599: Epoch 7 / 24, batch 3500 / 4333, 0.2669 sec/batch\n                         loss = [15.352992] gen = [0.173815] fr = [15.179177] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:15:45,281: Epoch 7 / 24, batch 3600 / 4333, 0.2668 sec/batch\n                         loss = [19.087574] gen = [0.178404] fr = [18.909170] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:16:11,959: Epoch 7 / 24, batch 3700 / 4333, 0.2668 sec/batch\n                         loss = [17.047329] gen = [0.201756] fr = [16.845573] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:16:38,640: Epoch 7 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [18.575396] gen = [0.162647] fr = [18.412748] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:17:05,322: Epoch 7 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [17.761229] gen = [0.212058] fr = [17.549171] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:17:32,009: Epoch 7 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [16.395607] gen = [0.187138] fr = [16.208469] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:17:58,693: Epoch 7 / 24, batch 4100 / 4333, 0.2668 sec/batch\n                         loss = [18.072979] gen = [0.206389] fr = [17.866590] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:18:25,387: Epoch 7 / 24, batch 4200 / 4333, 0.2669 sec/batch\n                         loss = [15.946833] gen = [0.156284] fr = [15.790548] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:18:52,076: Epoch 7 / 24, batch 4300 / 4333, 0.2669 sec/batch\n                         loss = [16.200592] gen = [0.231132] fr = [15.969460] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:19:01,746: Save checkpoint at epoch 7 ...\n2024-09-24 22:19:01,746: Current epoch 8, learning rate 0.01\n2024-09-24 22:19:02,174: Epoch 8 / 24, batch 1 / 4333, 0.4272 sec/batch\n                         loss = [16.478945] gen = [0.183688] fr = [16.295258] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:19:28,590: Epoch 8 / 24, batch 100 / 4333, 0.2684 sec/batch\n                         loss = [17.390894] gen = [0.197795] fr = [17.193098] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:19:55,266: Epoch 8 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [13.627599] gen = [0.177438] fr = [13.450161] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:20:21,942: Epoch 8 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [15.023272] gen = [0.174421] fr = [14.848851] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:20:48,616: Epoch 8 / 24, batch 400 / 4333, 0.2672 sec/batch\n                         loss = [15.297796] gen = [0.213287] fr = [15.084510] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:21:15,304: Epoch 8 / 24, batch 500 / 4333, 0.2671 sec/batch\n                         loss = [13.230100] gen = [0.207862] fr = [13.022238] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:21:41,981: Epoch 8 / 24, batch 600 / 4333, 0.2668 sec/batch\n                         loss = [19.266558] gen = [0.170378] fr = [19.096180] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:22:08,670: Epoch 8 / 24, batch 700 / 4333, 0.2668 sec/batch\n                         loss = [15.152390] gen = [0.196665] fr = [14.955725] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:22:35,357: Epoch 8 / 24, batch 800 / 4333, 0.2668 sec/batch\n                         loss = [15.574190] gen = [0.167047] fr = [15.407143] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:23:02,037: Epoch 8 / 24, batch 900 / 4333, 0.2668 sec/batch\n                         loss = [17.565630] gen = [0.186571] fr = [17.379059] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:23:28,717: Epoch 8 / 24, batch 1000 / 4333, 0.2668 sec/batch\n                         loss = [14.540181] gen = [0.185710] fr = [14.354471] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:23:55,399: Epoch 8 / 24, batch 1100 / 4333, 0.2668 sec/batch\n                         loss = [14.027989] gen = [0.212790] fr = [13.815199] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:24:22,082: Epoch 8 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [18.192593] gen = [0.167710] fr = [18.024883] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:24:48,762: Epoch 8 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [15.533682] gen = [0.149099] fr = [15.384583] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:25:15,440: Epoch 8 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [14.732229] gen = [0.176816] fr = [14.555413] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:25:42,119: Epoch 8 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [13.332578] gen = [0.193225] fr = [13.139353] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:26:08,809: Epoch 8 / 24, batch 1600 / 4333, 0.2669 sec/batch\n                         loss = [13.302189] gen = [0.185270] fr = [13.116919] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:26:35,495: Epoch 8 / 24, batch 1700 / 4333, 0.2669 sec/batch\n                         loss = [11.740216] gen = [0.183066] fr = [11.557150] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:27:02,180: Epoch 8 / 24, batch 1800 / 4333, 0.2669 sec/batch\n                         loss = [13.981935] gen = [0.170705] fr = [13.811230] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:27:28,854: Epoch 8 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [18.472576] gen = [0.182156] fr = [18.290421] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:27:55,529: Epoch 8 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [16.893066] gen = [0.187773] fr = [16.705294] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:28:22,196: Epoch 8 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [12.354198] gen = [0.228598] fr = [12.125600] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:28:48,883: Epoch 8 / 24, batch 2200 / 4333, 0.2668 sec/batch\n                         loss = [12.693314] gen = [0.218684] fr = [12.474629] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:29:15,564: Epoch 8 / 24, batch 2300 / 4333, 0.2668 sec/batch\n                         loss = [11.549829] gen = [0.176836] fr = [11.372993] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:29:42,243: Epoch 8 / 24, batch 2400 / 4333, 0.2668 sec/batch\n                         loss = [12.628614] gen = [0.197196] fr = [12.431418] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:30:08,921: Epoch 8 / 24, batch 2500 / 4333, 0.2668 sec/batch\n                         loss = [17.483303] gen = [0.178383] fr = [17.304920] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:30:35,607: Epoch 8 / 24, batch 2600 / 4333, 0.2669 sec/batch\n                         loss = [14.209527] gen = [0.179180] fr = [14.030347] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:31:02,301: Epoch 8 / 24, batch 2700 / 4333, 0.2669 sec/batch\n                         loss = [13.347899] gen = [0.168191] fr = [13.179708] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:31:28,990: Epoch 8 / 24, batch 2800 / 4333, 0.2669 sec/batch\n                         loss = [14.132808] gen = [0.155080] fr = [13.977728] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:31:55,675: Epoch 8 / 24, batch 2900 / 4333, 0.2669 sec/batch\n                         loss = [12.991381] gen = [0.174963] fr = [12.816418] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:32:22,361: Epoch 8 / 24, batch 3000 / 4333, 0.2669 sec/batch\n                         loss = [11.696131] gen = [0.159294] fr = [11.536838] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:32:49,040: Epoch 8 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [16.470259] gen = [0.189338] fr = [16.280920] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:33:15,728: Epoch 8 / 24, batch 3200 / 4333, 0.2668 sec/batch\n                         loss = [14.661484] gen = [0.260895] fr = [14.400589] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:33:42,419: Epoch 8 / 24, batch 3300 / 4333, 0.2669 sec/batch\n                         loss = [14.697562] gen = [0.178224] fr = [14.519339] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:34:09,109: Epoch 8 / 24, batch 3400 / 4333, 0.2669 sec/batch\n                         loss = [16.473053] gen = [0.169682] fr = [16.303371] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:34:35,794: Epoch 8 / 24, batch 3500 / 4333, 0.2669 sec/batch\n                         loss = [10.959369] gen = [0.142631] fr = [10.816738] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:35:02,462: Epoch 8 / 24, batch 3600 / 4333, 0.2667 sec/batch\n                         loss = [12.548434] gen = [0.198253] fr = [12.350182] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:35:29,130: Epoch 8 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [8.361286] gen = [0.239216] fr = [8.122070] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:35:55,810: Epoch 8 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [12.066949] gen = [0.210808] fr = [11.856140] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:36:22,488: Epoch 8 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [13.067255] gen = [0.165953] fr = [12.901302] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:36:49,176: Epoch 8 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [11.635148] gen = [0.182324] fr = [11.452824] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:37:15,868: Epoch 8 / 24, batch 4100 / 4333, 0.2669 sec/batch\n                         loss = [13.249833] gen = [0.258259] fr = [12.991574] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:37:42,559: Epoch 8 / 24, batch 4200 / 4333, 0.2669 sec/batch\n                         loss = [13.315807] gen = [0.197921] fr = [13.117886] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:38:09,251: Epoch 8 / 24, batch 4300 / 4333, 0.2669 sec/batch\n                         loss = [18.326696] gen = [0.185777] fr = [18.140919] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:38:18,930: Save checkpoint at epoch 8 ...\n2024-09-24 22:38:18,930: Current epoch 9, learning rate 0.01\n2024-09-24 22:38:19,385: Epoch 9 / 24, batch 1 / 4333, 0.4540 sec/batch\n                         loss = [13.849840] gen = [0.245983] fr = [13.603857] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:38:45,816: Epoch 9 / 24, batch 100 / 4333, 0.2688 sec/batch\n                         loss = [9.471907] gen = [0.187922] fr = [9.283984] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:39:12,500: Epoch 9 / 24, batch 200 / 4333, 0.2678 sec/batch\n                         loss = [11.272829] gen = [0.172754] fr = [11.100075] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:39:39,172: Epoch 9 / 24, batch 300 / 4333, 0.2675 sec/batch\n                         loss = [12.201567] gen = [0.162220] fr = [12.039347] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:40:05,858: Epoch 9 / 24, batch 400 / 4333, 0.2673 sec/batch\n                         loss = [10.899977] gen = [0.169485] fr = [10.730492] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:40:32,546: Epoch 9 / 24, batch 500 / 4333, 0.2672 sec/batch\n                         loss = [8.721193] gen = [0.188874] fr = [8.532320] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:40:59,228: Epoch 9 / 24, batch 600 / 4333, 0.2668 sec/batch\n                         loss = [8.367299] gen = [0.147508] fr = [8.219791] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:41:25,913: Epoch 9 / 24, batch 700 / 4333, 0.2668 sec/batch\n                         loss = [8.464339] gen = [0.202714] fr = [8.261625] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:41:52,591: Epoch 9 / 24, batch 800 / 4333, 0.2668 sec/batch\n                         loss = [11.723537] gen = [0.200565] fr = [11.522972] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:42:19,265: Epoch 9 / 24, batch 900 / 4333, 0.2668 sec/batch\n                         loss = [14.624096] gen = [0.191558] fr = [14.432538] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:42:45,925: Epoch 9 / 24, batch 1000 / 4333, 0.2668 sec/batch\n                         loss = [9.518307] gen = [0.136209] fr = [9.382098] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:43:12,593: Epoch 9 / 24, batch 1100 / 4333, 0.2667 sec/batch\n                         loss = [16.849640] gen = [0.163982] fr = [16.685658] spar = [0.000000] prec@1 = [81.250000] prec@5 = [100.000000] \n2024-09-24 22:43:39,279: Epoch 9 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [9.419445] gen = [0.149778] fr = [9.269667] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:44:05,962: Epoch 9 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [16.813805] gen = [0.209528] fr = [16.604277] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:44:32,643: Epoch 9 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [15.760032] gen = [0.141658] fr = [15.618374] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:44:59,325: Epoch 9 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [11.964328] gen = [0.216811] fr = [11.747517] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:45:26,010: Epoch 9 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [8.609892] gen = [0.234944] fr = [8.374949] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:45:52,691: Epoch 9 / 24, batch 1700 / 4333, 0.2668 sec/batch\n                         loss = [15.824796] gen = [0.161802] fr = [15.662993] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:46:19,374: Epoch 9 / 24, batch 1800 / 4333, 0.2668 sec/batch\n                         loss = [11.613049] gen = [0.222114] fr = [11.390935] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:46:46,058: Epoch 9 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [14.111137] gen = [0.231811] fr = [13.879327] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:47:12,737: Epoch 9 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [9.003987] gen = [0.170817] fr = [8.833171] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:47:39,418: Epoch 9 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [9.940922] gen = [0.200732] fr = [9.740190] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:48:06,101: Epoch 9 / 24, batch 2200 / 4333, 0.2668 sec/batch\n                         loss = [13.255317] gen = [0.160119] fr = [13.095199] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:48:32,784: Epoch 9 / 24, batch 2300 / 4333, 0.2668 sec/batch\n                         loss = [14.250516] gen = [0.183732] fr = [14.066784] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:48:59,463: Epoch 9 / 24, batch 2400 / 4333, 0.2668 sec/batch\n                         loss = [11.928847] gen = [0.204553] fr = [11.724295] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 22:49:26,151: Epoch 9 / 24, batch 2500 / 4333, 0.2668 sec/batch\n                         loss = [9.236904] gen = [0.193429] fr = [9.043476] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:49:52,824: Epoch 9 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [9.320822] gen = [0.182434] fr = [9.138388] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:50:19,507: Epoch 9 / 24, batch 2700 / 4333, 0.2668 sec/batch\n                         loss = [11.507230] gen = [0.207423] fr = [11.299807] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:50:46,187: Epoch 9 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [18.701530] gen = [0.212320] fr = [18.489210] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:51:12,875: Epoch 9 / 24, batch 2900 / 4333, 0.2668 sec/batch\n                         loss = [14.468954] gen = [0.199895] fr = [14.269058] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:51:39,558: Epoch 9 / 24, batch 3000 / 4333, 0.2668 sec/batch\n                         loss = [8.091103] gen = [0.145104] fr = [7.945999] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:52:06,234: Epoch 9 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [11.648131] gen = [0.210849] fr = [11.437283] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:52:32,913: Epoch 9 / 24, batch 3200 / 4333, 0.2668 sec/batch\n                         loss = [18.446098] gen = [0.187112] fr = [18.258986] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:52:59,593: Epoch 9 / 24, batch 3300 / 4333, 0.2668 sec/batch\n                         loss = [8.509216] gen = [0.168072] fr = [8.341145] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:53:26,280: Epoch 9 / 24, batch 3400 / 4333, 0.2668 sec/batch\n                         loss = [13.182100] gen = [0.233729] fr = [12.948372] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:53:52,972: Epoch 9 / 24, batch 3500 / 4333, 0.2668 sec/batch\n                         loss = [15.053425] gen = [0.349390] fr = [14.704035] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:54:19,650: Epoch 9 / 24, batch 3600 / 4333, 0.2668 sec/batch\n                         loss = [15.460457] gen = [0.307162] fr = [15.153296] spar = [0.000000] prec@1 = [87.500000] prec@5 = [100.000000] \n2024-09-24 22:54:46,334: Epoch 9 / 24, batch 3700 / 4333, 0.2668 sec/batch\n                         loss = [7.839242] gen = [0.176554] fr = [7.662688] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:55:13,012: Epoch 9 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [15.773374] gen = [0.208764] fr = [15.564610] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:55:39,689: Epoch 9 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [11.323715] gen = [0.151299] fr = [11.172417] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:56:06,365: Epoch 9 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [14.712644] gen = [0.223946] fr = [14.488697] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 22:56:33,050: Epoch 9 / 24, batch 4100 / 4333, 0.2668 sec/batch\n                         loss = [16.420967] gen = [0.202016] fr = [16.218952] spar = [0.000000] prec@1 = [87.500000] prec@5 = [93.750000] \n2024-09-24 22:56:59,730: Epoch 9 / 24, batch 4200 / 4333, 0.2668 sec/batch\n                         loss = [8.586776] gen = [0.227488] fr = [8.359287] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:57:26,394: Epoch 9 / 24, batch 4300 / 4333, 0.2668 sec/batch\n                         loss = [9.085222] gen = [0.206263] fr = [8.878960] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:57:36,061: Save checkpoint at epoch 9 ...\n2024-09-24 22:57:36,061: Current epoch 10, learning rate 0.01\n2024-09-24 22:57:36,494: Epoch 10 / 24, batch 1 / 4333, 0.4316 sec/batch\n                         loss = [9.444868] gen = [0.150838] fr = [9.294029] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:58:02,900: Epoch 10 / 24, batch 100 / 4333, 0.2684 sec/batch\n                         loss = [9.385454] gen = [0.168686] fr = [9.216768] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:58:29,568: Epoch 10 / 24, batch 200 / 4333, 0.2675 sec/batch\n                         loss = [11.806281] gen = [0.169734] fr = [11.636547] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:58:56,271: Epoch 10 / 24, batch 300 / 4333, 0.2674 sec/batch\n                         loss = [10.336103] gen = [0.174708] fr = [10.161396] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:59:22,945: Epoch 10 / 24, batch 400 / 4333, 0.2672 sec/batch\n                         loss = [9.051667] gen = [0.216652] fr = [8.835015] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 22:59:49,622: Epoch 10 / 24, batch 500 / 4333, 0.2671 sec/batch\n                         loss = [11.863777] gen = [0.167011] fr = [11.696767] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:00:16,294: Epoch 10 / 24, batch 600 / 4333, 0.2667 sec/batch\n                         loss = [7.085716] gen = [0.209585] fr = [6.876131] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:00:43,013: Epoch 10 / 24, batch 700 / 4333, 0.2670 sec/batch\n                         loss = [9.530841] gen = [0.162838] fr = [9.368003] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:01:09,707: Epoch 10 / 24, batch 800 / 4333, 0.2669 sec/batch\n                         loss = [7.870635] gen = [0.190362] fr = [7.680272] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:01:36,409: Epoch 10 / 24, batch 900 / 4333, 0.2670 sec/batch\n                         loss = [11.027987] gen = [0.182330] fr = [10.845657] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:02:03,123: Epoch 10 / 24, batch 1000 / 4333, 0.2670 sec/batch\n                         loss = [9.225183] gen = [0.139810] fr = [9.085373] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:02:29,831: Epoch 10 / 24, batch 1100 / 4333, 0.2671 sec/batch\n                         loss = [7.324294] gen = [0.201086] fr = [7.123208] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:02:56,511: Epoch 10 / 24, batch 1200 / 4333, 0.2669 sec/batch\n                         loss = [8.125922] gen = [0.171622] fr = [7.954300] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:03:23,184: Epoch 10 / 24, batch 1300 / 4333, 0.2669 sec/batch\n                         loss = [8.849285] gen = [0.164668] fr = [8.684617] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:03:49,859: Epoch 10 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [6.482752] gen = [0.167946] fr = [6.314807] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:04:16,547: Epoch 10 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [10.420872] gen = [0.171979] fr = [10.248893] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:04:43,217: Epoch 10 / 24, batch 1600 / 4333, 0.2667 sec/batch\n                         loss = [9.170465] gen = [0.182522] fr = [8.987944] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:05:09,887: Epoch 10 / 24, batch 1700 / 4333, 0.2667 sec/batch\n                         loss = [5.482343] gen = [0.179925] fr = [5.302418] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:05:36,553: Epoch 10 / 24, batch 1800 / 4333, 0.2667 sec/batch\n                         loss = [11.277699] gen = [0.237242] fr = [11.040457] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:06:03,231: Epoch 10 / 24, batch 1900 / 4333, 0.2667 sec/batch\n                         loss = [8.229305] gen = [0.174727] fr = [8.054579] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:06:29,915: Epoch 10 / 24, batch 2000 / 4333, 0.2667 sec/batch\n                         loss = [8.084436] gen = [0.149242] fr = [7.935194] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:06:56,593: Epoch 10 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [4.545656] gen = [0.154521] fr = [4.391134] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:07:23,270: Epoch 10 / 24, batch 2200 / 4333, 0.2668 sec/batch\n                         loss = [12.619593] gen = [0.177370] fr = [12.442223] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:07:49,943: Epoch 10 / 24, batch 2300 / 4333, 0.2668 sec/batch\n                         loss = [7.666604] gen = [0.187153] fr = [7.479451] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:08:16,618: Epoch 10 / 24, batch 2400 / 4333, 0.2668 sec/batch\n                         loss = [11.545950] gen = [0.183951] fr = [11.362000] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:08:43,297: Epoch 10 / 24, batch 2500 / 4333, 0.2668 sec/batch\n                         loss = [6.259232] gen = [0.194851] fr = [6.064381] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:09:09,982: Epoch 10 / 24, batch 2600 / 4333, 0.2669 sec/batch\n                         loss = [11.157065] gen = [0.148802] fr = [11.008264] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:09:36,668: Epoch 10 / 24, batch 2700 / 4333, 0.2669 sec/batch\n                         loss = [8.180533] gen = [0.207435] fr = [7.973098] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:10:03,343: Epoch 10 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [6.008723] gen = [0.194393] fr = [5.814330] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:10:30,036: Epoch 10 / 24, batch 2900 / 4333, 0.2668 sec/batch\n                         loss = [10.040072] gen = [0.175168] fr = [9.864904] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:10:56,725: Epoch 10 / 24, batch 3000 / 4333, 0.2669 sec/batch\n                         loss = [6.508367] gen = [0.168655] fr = [6.339713] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:11:23,407: Epoch 10 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [13.356906] gen = [0.182803] fr = [13.174103] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 23:11:50,087: Epoch 10 / 24, batch 3200 / 4333, 0.2668 sec/batch\n                         loss = [10.859616] gen = [0.153650] fr = [10.705967] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:12:16,763: Epoch 10 / 24, batch 3300 / 4333, 0.2668 sec/batch\n                         loss = [10.619129] gen = [0.178684] fr = [10.440445] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:12:43,436: Epoch 10 / 24, batch 3400 / 4333, 0.2668 sec/batch\n                         loss = [9.152718] gen = [0.232904] fr = [8.919813] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:13:10,098: Epoch 10 / 24, batch 3500 / 4333, 0.2667 sec/batch\n                         loss = [12.128334] gen = [0.191721] fr = [11.936613] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:13:36,768: Epoch 10 / 24, batch 3600 / 4333, 0.2667 sec/batch\n                         loss = [7.603334] gen = [0.234236] fr = [7.369098] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:14:03,445: Epoch 10 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [10.372765] gen = [0.156227] fr = [10.216537] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:14:30,139: Epoch 10 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [6.419251] gen = [0.183501] fr = [6.235750] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:14:56,824: Epoch 10 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [9.790494] gen = [0.155102] fr = [9.635391] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 23:15:23,511: Epoch 10 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [9.623291] gen = [0.163408] fr = [9.459883] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:15:50,194: Epoch 10 / 24, batch 4100 / 4333, 0.2668 sec/batch\n                         loss = [8.987207] gen = [0.218563] fr = [8.768644] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:16:16,875: Epoch 10 / 24, batch 4200 / 4333, 0.2668 sec/batch\n                         loss = [9.769994] gen = [0.162143] fr = [9.607851] spar = [0.000000] prec@1 = [93.750000] prec@5 = [93.750000] \n2024-09-24 23:16:43,551: Epoch 10 / 24, batch 4300 / 4333, 0.2668 sec/batch\n                         loss = [7.360598] gen = [0.177769] fr = [7.182829] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:16:53,254: Save checkpoint at epoch 10 ...\n2024-09-24 23:16:53,254: Current epoch 11, learning rate 0.001\n2024-09-24 23:16:53,786: Epoch 11 / 24, batch 1 / 4333, 0.5308 sec/batch\n                         loss = [6.400362] gen = [0.237271] fr = [6.163092] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:17:20,200: Epoch 11 / 24, batch 100 / 4333, 0.2694 sec/batch\n                         loss = [4.944790] gen = [0.136288] fr = [4.808502] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:17:46,872: Epoch 11 / 24, batch 200 / 4333, 0.2681 sec/batch\n                         loss = [5.565609] gen = [0.120042] fr = [5.445567] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:18:13,547: Epoch 11 / 24, batch 300 / 4333, 0.2676 sec/batch\n                         loss = [5.783751] gen = [0.116617] fr = [5.667134] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:18:40,223: Epoch 11 / 24, batch 400 / 4333, 0.2674 sec/batch\n                         loss = [4.245667] gen = [0.117279] fr = [4.128388] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:19:06,893: Epoch 11 / 24, batch 500 / 4333, 0.2673 sec/batch\n                         loss = [4.834849] gen = [0.114966] fr = [4.719883] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:19:33,564: Epoch 11 / 24, batch 600 / 4333, 0.2667 sec/batch\n                         loss = [2.721622] gen = [0.115644] fr = [2.605979] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:20:00,227: Epoch 11 / 24, batch 700 / 4333, 0.2667 sec/batch\n                         loss = [5.478162] gen = [0.109156] fr = [5.369006] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:20:26,888: Epoch 11 / 24, batch 800 / 4333, 0.2667 sec/batch\n                         loss = [6.550231] gen = [0.104133] fr = [6.446098] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:20:53,549: Epoch 11 / 24, batch 900 / 4333, 0.2666 sec/batch\n                         loss = [5.119498] gen = [0.104245] fr = [5.015253] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:21:20,219: Epoch 11 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [5.098176] gen = [0.107649] fr = [4.990527] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:21:46,904: Epoch 11 / 24, batch 1100 / 4333, 0.2669 sec/batch\n                         loss = [5.226497] gen = [0.105260] fr = [5.121238] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:22:13,584: Epoch 11 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [7.793975] gen = [0.108968] fr = [7.685007] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:22:40,263: Epoch 11 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [3.568772] gen = [0.107243] fr = [3.461529] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:23:06,942: Epoch 11 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [5.412750] gen = [0.095548] fr = [5.317203] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:23:33,622: Epoch 11 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [5.893979] gen = [0.105636] fr = [5.788342] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:24:00,297: Epoch 11 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [4.059636] gen = [0.108935] fr = [3.950701] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:24:26,980: Epoch 11 / 24, batch 1700 / 4333, 0.2668 sec/batch\n                         loss = [3.901950] gen = [0.104915] fr = [3.797035] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:24:53,671: Epoch 11 / 24, batch 1800 / 4333, 0.2668 sec/batch\n                         loss = [4.586387] gen = [0.099639] fr = [4.486749] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:25:20,345: Epoch 11 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [5.547156] gen = [0.107404] fr = [5.439753] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:25:47,029: Epoch 11 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [4.663684] gen = [0.087411] fr = [4.576273] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:26:13,719: Epoch 11 / 24, batch 2100 / 4333, 0.2669 sec/batch\n                         loss = [4.629011] gen = [0.106637] fr = [4.522374] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:26:40,421: Epoch 11 / 24, batch 2200 / 4333, 0.2670 sec/batch\n                         loss = [6.122223] gen = [0.105716] fr = [6.016507] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:27:07,105: Epoch 11 / 24, batch 2300 / 4333, 0.2669 sec/batch\n                         loss = [6.063695] gen = [0.099192] fr = [5.964503] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:27:33,779: Epoch 11 / 24, batch 2400 / 4333, 0.2669 sec/batch\n                         loss = [2.299728] gen = [0.108104] fr = [2.191624] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:28:00,454: Epoch 11 / 24, batch 2500 / 4333, 0.2669 sec/batch\n                         loss = [3.681486] gen = [0.094894] fr = [3.586592] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:28:27,124: Epoch 11 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [4.342546] gen = [0.108412] fr = [4.234134] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:28:53,808: Epoch 11 / 24, batch 2700 / 4333, 0.2668 sec/batch\n                         loss = [3.632381] gen = [0.113411] fr = [3.518970] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:29:20,502: Epoch 11 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [3.605844] gen = [0.104692] fr = [3.501152] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:29:47,198: Epoch 11 / 24, batch 2900 / 4333, 0.2669 sec/batch\n                         loss = [8.102967] gen = [0.106068] fr = [7.996899] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:30:13,884: Epoch 11 / 24, batch 3000 / 4333, 0.2669 sec/batch\n                         loss = [4.759690] gen = [0.114111] fr = [4.645579] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:30:40,567: Epoch 11 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [5.415865] gen = [0.104518] fr = [5.311347] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:31:07,254: Epoch 11 / 24, batch 3200 / 4333, 0.2669 sec/batch\n                         loss = [5.580945] gen = [0.106033] fr = [5.474911] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:31:33,934: Epoch 11 / 24, batch 3300 / 4333, 0.2668 sec/batch\n                         loss = [3.776372] gen = [0.109271] fr = [3.667101] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:32:00,609: Epoch 11 / 24, batch 3400 / 4333, 0.2668 sec/batch\n                         loss = [2.411695] gen = [0.096704] fr = [2.314991] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:32:27,285: Epoch 11 / 24, batch 3500 / 4333, 0.2668 sec/batch\n                         loss = [5.052700] gen = [0.097933] fr = [4.954766] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:32:53,966: Epoch 11 / 24, batch 3600 / 4333, 0.2668 sec/batch\n                         loss = [4.210025] gen = [0.109141] fr = [4.100884] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:33:20,644: Epoch 11 / 24, batch 3700 / 4333, 0.2668 sec/batch\n                         loss = [6.056538] gen = [0.101889] fr = [5.954648] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:33:47,326: Epoch 11 / 24, batch 3800 / 4333, 0.2668 sec/batch\n                         loss = [1.387618] gen = [0.095986] fr = [1.291632] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:34:14,009: Epoch 11 / 24, batch 3900 / 4333, 0.2668 sec/batch\n                         loss = [3.415292] gen = [0.106076] fr = [3.309216] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:34:40,690: Epoch 11 / 24, batch 4000 / 4333, 0.2668 sec/batch\n                         loss = [6.497828] gen = [0.113746] fr = [6.384083] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:35:07,360: Epoch 11 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [2.268488] gen = [0.090010] fr = [2.178478] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:35:34,026: Epoch 11 / 24, batch 4200 / 4333, 0.2667 sec/batch\n                         loss = [3.928937] gen = [0.107383] fr = [3.821554] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:36:00,691: Epoch 11 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [3.662860] gen = [0.092088] fr = [3.570771] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:36:10,354: Save checkpoint at epoch 11 ...\n2024-09-24 23:36:10,354: Current epoch 12, learning rate 0.001\n2024-09-24 23:36:10,811: Epoch 12 / 24, batch 1 / 4333, 0.4551 sec/batch\n                         loss = [4.045555] gen = [0.093293] fr = [3.952261] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:36:37,237: Epoch 12 / 24, batch 100 / 4333, 0.2688 sec/batch\n                         loss = [3.357334] gen = [0.091880] fr = [3.265454] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:37:03,919: Epoch 12 / 24, batch 200 / 4333, 0.2678 sec/batch\n                         loss = [3.537897] gen = [0.101062] fr = [3.436835] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:37:30,591: Epoch 12 / 24, batch 300 / 4333, 0.2675 sec/batch\n                         loss = [2.095323] gen = [0.099535] fr = [1.995788] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:37:57,277: Epoch 12 / 24, batch 400 / 4333, 0.2673 sec/batch\n                         loss = [2.115633] gen = [0.096289] fr = [2.019344] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:38:23,952: Epoch 12 / 24, batch 500 / 4333, 0.2672 sec/batch\n                         loss = [4.313431] gen = [0.097456] fr = [4.215975] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:38:50,633: Epoch 12 / 24, batch 600 / 4333, 0.2668 sec/batch\n                         loss = [2.096690] gen = [0.088269] fr = [2.008421] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:39:17,312: Epoch 12 / 24, batch 700 / 4333, 0.2668 sec/batch\n                         loss = [4.314543] gen = [0.095290] fr = [4.219253] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:39:43,995: Epoch 12 / 24, batch 800 / 4333, 0.2668 sec/batch\n                         loss = [2.807272] gen = [0.100367] fr = [2.706905] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:40:10,668: Epoch 12 / 24, batch 900 / 4333, 0.2668 sec/batch\n                         loss = [3.069508] gen = [0.098926] fr = [2.970582] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:40:37,351: Epoch 12 / 24, batch 1000 / 4333, 0.2668 sec/batch\n                         loss = [5.262958] gen = [0.122386] fr = [5.140572] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:41:04,031: Epoch 12 / 24, batch 1100 / 4333, 0.2668 sec/batch\n                         loss = [4.738472] gen = [0.093281] fr = [4.645191] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:41:30,704: Epoch 12 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [6.218485] gen = [0.093459] fr = [6.125026] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:41:57,383: Epoch 12 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [2.540008] gen = [0.103411] fr = [2.436596] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:42:24,056: Epoch 12 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [3.740120] gen = [0.094885] fr = [3.645235] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:42:50,720: Epoch 12 / 24, batch 1500 / 4333, 0.2667 sec/batch\n                         loss = [2.734556] gen = [0.096842] fr = [2.637715] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:43:17,387: Epoch 12 / 24, batch 1600 / 4333, 0.2667 sec/batch\n                         loss = [2.729995] gen = [0.096789] fr = [2.633205] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:43:44,053: Epoch 12 / 24, batch 1700 / 4333, 0.2667 sec/batch\n                         loss = [4.539427] gen = [0.085978] fr = [4.453449] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:44:10,735: Epoch 12 / 24, batch 1800 / 4333, 0.2667 sec/batch\n                         loss = [1.922336] gen = [0.103442] fr = [1.818895] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:44:37,409: Epoch 12 / 24, batch 1900 / 4333, 0.2667 sec/batch\n                         loss = [2.940603] gen = [0.093367] fr = [2.847237] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:45:04,087: Epoch 12 / 24, batch 2000 / 4333, 0.2667 sec/batch\n                         loss = [2.130028] gen = [0.091313] fr = [2.038714] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:45:30,775: Epoch 12 / 24, batch 2100 / 4333, 0.2669 sec/batch\n                         loss = [3.821226] gen = [0.088665] fr = [3.732561] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:45:57,456: Epoch 12 / 24, batch 2200 / 4333, 0.2668 sec/batch\n                         loss = [5.995236] gen = [0.091483] fr = [5.903753] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:46:24,129: Epoch 12 / 24, batch 2300 / 4333, 0.2668 sec/batch\n                         loss = [3.402835] gen = [0.099956] fr = [3.302879] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:46:50,809: Epoch 12 / 24, batch 2400 / 4333, 0.2668 sec/batch\n                         loss = [4.265310] gen = [0.105037] fr = [4.160273] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:47:17,490: Epoch 12 / 24, batch 2500 / 4333, 0.2668 sec/batch\n                         loss = [3.172769] gen = [0.103010] fr = [3.069760] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:47:44,166: Epoch 12 / 24, batch 2600 / 4333, 0.2668 sec/batch\n                         loss = [4.210990] gen = [0.093089] fr = [4.117902] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:48:10,844: Epoch 12 / 24, batch 2700 / 4333, 0.2668 sec/batch\n                         loss = [3.919337] gen = [0.081417] fr = [3.837920] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:48:37,521: Epoch 12 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [2.600084] gen = [0.103968] fr = [2.496116] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:49:04,200: Epoch 12 / 24, batch 2900 / 4333, 0.2668 sec/batch\n                         loss = [4.599214] gen = [0.114016] fr = [4.485198] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:49:30,871: Epoch 12 / 24, batch 3000 / 4333, 0.2668 sec/batch\n                         loss = [3.192696] gen = [0.106485] fr = [3.086210] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:49:57,532: Epoch 12 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [3.143518] gen = [0.098952] fr = [3.044566] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:50:24,186: Epoch 12 / 24, batch 3200 / 4333, 0.2666 sec/batch\n                         loss = [6.280029] gen = [0.095835] fr = [6.184195] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:50:50,853: Epoch 12 / 24, batch 3300 / 4333, 0.2666 sec/batch\n                         loss = [2.214449] gen = [0.091139] fr = [2.123309] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:51:17,517: Epoch 12 / 24, batch 3400 / 4333, 0.2666 sec/batch\n                         loss = [3.012827] gen = [0.120600] fr = [2.892228] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:51:44,189: Epoch 12 / 24, batch 3500 / 4333, 0.2666 sec/batch\n                         loss = [2.322600] gen = [0.103438] fr = [2.219162] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:52:10,856: Epoch 12 / 24, batch 3600 / 4333, 0.2667 sec/batch\n                         loss = [3.680696] gen = [0.107946] fr = [3.572750] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:52:37,530: Epoch 12 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [0.284322] gen = [0.103171] fr = [0.181152] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:53:04,197: Epoch 12 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [1.886044] gen = [0.090351] fr = [1.795693] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:53:30,867: Epoch 12 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [6.419476] gen = [0.096190] fr = [6.323286] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:53:57,541: Epoch 12 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [1.477533] gen = [0.093873] fr = [1.383661] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:54:24,211: Epoch 12 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [2.032842] gen = [0.092171] fr = [1.940671] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:54:50,882: Epoch 12 / 24, batch 4200 / 4333, 0.2667 sec/batch\n                         loss = [3.110194] gen = [0.097333] fr = [3.012861] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:55:17,561: Epoch 12 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [1.322899] gen = [0.096479] fr = [1.226420] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:55:27,232: Save checkpoint at epoch 12 ...\n2024-09-24 23:55:27,232: Current epoch 13, learning rate 0.001\n2024-09-24 23:55:27,722: Epoch 13 / 24, batch 1 / 4333, 0.4888 sec/batch\n                         loss = [2.599532] gen = [0.095715] fr = [2.503818] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:55:54,142: Epoch 13 / 24, batch 100 / 4333, 0.2691 sec/batch\n                         loss = [2.510417] gen = [0.107329] fr = [2.403088] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:56:20,830: Epoch 13 / 24, batch 200 / 4333, 0.2680 sec/batch\n                         loss = [1.528271] gen = [0.100686] fr = [1.427585] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:56:47,508: Epoch 13 / 24, batch 300 / 4333, 0.2676 sec/batch\n                         loss = [2.386217] gen = [0.099279] fr = [2.286938] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:57:14,179: Epoch 13 / 24, batch 400 / 4333, 0.2674 sec/batch\n                         loss = [2.511131] gen = [0.103999] fr = [2.407131] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:57:40,846: Epoch 13 / 24, batch 500 / 4333, 0.2672 sec/batch\n                         loss = [1.783400] gen = [0.096799] fr = [1.686601] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:58:07,509: Epoch 13 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [2.114758] gen = [0.099877] fr = [2.014881] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:58:34,174: Epoch 13 / 24, batch 700 / 4333, 0.2666 sec/batch\n                         loss = [1.651932] gen = [0.087578] fr = [1.564354] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:59:00,839: Epoch 13 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [1.321473] gen = [0.100327] fr = [1.221147] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-24 23:59:27,515: Epoch 13 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [5.890096] gen = [0.088206] fr = [5.801889] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-24 23:59:54,181: Epoch 13 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [2.113168] gen = [0.097194] fr = [2.015973] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:00:20,851: Epoch 13 / 24, batch 1100 / 4333, 0.2667 sec/batch\n                         loss = [2.125772] gen = [0.096959] fr = [2.028813] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:00:47,530: Epoch 13 / 24, batch 1200 / 4333, 0.2667 sec/batch\n                         loss = [2.219204] gen = [0.085955] fr = [2.133250] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:01:14,205: Epoch 13 / 24, batch 1300 / 4333, 0.2667 sec/batch\n                         loss = [2.129529] gen = [0.094466] fr = [2.035063] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:01:40,877: Epoch 13 / 24, batch 1400 / 4333, 0.2667 sec/batch\n                         loss = [3.119411] gen = [0.095545] fr = [3.023866] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:02:07,546: Epoch 13 / 24, batch 1500 / 4333, 0.2667 sec/batch\n                         loss = [5.334293] gen = [0.100023] fr = [5.234270] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:02:34,223: Epoch 13 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [3.194895] gen = [0.094549] fr = [3.100346] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:03:00,894: Epoch 13 / 24, batch 1700 / 4333, 0.2667 sec/batch\n                         loss = [1.545236] gen = [0.093023] fr = [1.452213] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:03:27,564: Epoch 13 / 24, batch 1800 / 4333, 0.2667 sec/batch\n                         loss = [3.316709] gen = [0.089548] fr = [3.227161] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:03:54,237: Epoch 13 / 24, batch 1900 / 4333, 0.2667 sec/batch\n                         loss = [1.585641] gen = [0.093497] fr = [1.492144] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:04:20,910: Epoch 13 / 24, batch 2000 / 4333, 0.2667 sec/batch\n                         loss = [3.676844] gen = [0.085639] fr = [3.591204] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:04:47,585: Epoch 13 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [2.208413] gen = [0.092217] fr = [2.116196] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:05:14,245: Epoch 13 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [2.056583] gen = [0.095731] fr = [1.960853] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:05:40,905: Epoch 13 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [3.349229] gen = [0.105145] fr = [3.244083] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:06:07,567: Epoch 13 / 24, batch 2400 / 4333, 0.2666 sec/batch\n                         loss = [2.209991] gen = [0.087631] fr = [2.122360] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:06:34,239: Epoch 13 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [1.880229] gen = [0.093140] fr = [1.787089] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:07:00,909: Epoch 13 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [1.120095] gen = [0.092143] fr = [1.027952] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:07:27,588: Epoch 13 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [2.767462] gen = [0.086926] fr = [2.680535] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:07:54,263: Epoch 13 / 24, batch 2800 / 4333, 0.2667 sec/batch\n                         loss = [3.082903] gen = [0.088098] fr = [2.994805] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:08:20,937: Epoch 13 / 24, batch 2900 / 4333, 0.2667 sec/batch\n                         loss = [2.874954] gen = [0.100413] fr = [2.774542] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:08:47,618: Epoch 13 / 24, batch 3000 / 4333, 0.2668 sec/batch\n                         loss = [1.640086] gen = [0.090141] fr = [1.549946] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:09:14,291: Epoch 13 / 24, batch 3100 / 4333, 0.2667 sec/batch\n                         loss = [2.104889] gen = [0.090454] fr = [2.014435] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:09:40,967: Epoch 13 / 24, batch 3200 / 4333, 0.2667 sec/batch\n                         loss = [4.358733] gen = [0.106836] fr = [4.251897] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:10:07,639: Epoch 13 / 24, batch 3300 / 4333, 0.2667 sec/batch\n                         loss = [1.486118] gen = [0.110173] fr = [1.375946] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:10:34,321: Epoch 13 / 24, batch 3400 / 4333, 0.2668 sec/batch\n                         loss = [3.774230] gen = [0.092828] fr = [3.681402] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:11:00,991: Epoch 13 / 24, batch 3500 / 4333, 0.2667 sec/batch\n                         loss = [1.940339] gen = [0.103004] fr = [1.837335] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:11:27,669: Epoch 13 / 24, batch 3600 / 4333, 0.2668 sec/batch\n                         loss = [2.251891] gen = [0.096349] fr = [2.155541] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:11:54,331: Epoch 13 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [1.460802] gen = [0.092336] fr = [1.368466] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:12:21,001: Epoch 13 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [0.866447] gen = [0.102948] fr = [0.763499] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:12:47,661: Epoch 13 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [1.301757] gen = [0.098910] fr = [1.202847] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:13:14,322: Epoch 13 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [1.832232] gen = [0.097869] fr = [1.734363] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:13:40,986: Epoch 13 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [2.874837] gen = [0.087971] fr = [2.786865] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:14:07,667: Epoch 13 / 24, batch 4200 / 4333, 0.2667 sec/batch\n                         loss = [2.221741] gen = [0.082315] fr = [2.139426] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:14:34,335: Epoch 13 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [1.821705] gen = [0.080260] fr = [1.741444] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:14:43,998: Save checkpoint at epoch 13 ...\n2024-09-25 00:14:43,998: Current epoch 14, learning rate 0.001\n2024-09-25 00:14:44,448: Epoch 14 / 24, batch 1 / 4333, 0.4477 sec/batch\n                         loss = [2.182814] gen = [0.097034] fr = [2.085780] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:15:10,858: Epoch 14 / 24, batch 100 / 4333, 0.2686 sec/batch\n                         loss = [1.607006] gen = [0.090030] fr = [1.516976] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:15:37,530: Epoch 14 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [1.623449] gen = [0.087889] fr = [1.535560] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:16:04,207: Epoch 14 / 24, batch 300 / 4333, 0.2674 sec/batch\n                         loss = [2.799200] gen = [0.091322] fr = [2.707879] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:16:30,882: Epoch 14 / 24, batch 400 / 4333, 0.2672 sec/batch\n                         loss = [4.039871] gen = [0.100148] fr = [3.939723] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:16:57,551: Epoch 14 / 24, batch 500 / 4333, 0.2671 sec/batch\n                         loss = [3.635117] gen = [0.093520] fr = [3.541597] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:17:24,221: Epoch 14 / 24, batch 600 / 4333, 0.2667 sec/batch\n                         loss = [2.619169] gen = [0.086337] fr = [2.532833] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:17:50,890: Epoch 14 / 24, batch 700 / 4333, 0.2667 sec/batch\n                         loss = [1.419480] gen = [0.085714] fr = [1.333766] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:18:17,566: Epoch 14 / 24, batch 800 / 4333, 0.2667 sec/batch\n                         loss = [2.674209] gen = [0.097647] fr = [2.576562] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:18:44,233: Epoch 14 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [1.828699] gen = [0.090319] fr = [1.738380] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:19:10,921: Epoch 14 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [1.945990] gen = [0.089161] fr = [1.856829] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:19:37,617: Epoch 14 / 24, batch 1100 / 4333, 0.2670 sec/batch\n                         loss = [2.245671] gen = [0.085453] fr = [2.160218] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:20:04,287: Epoch 14 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [2.800031] gen = [0.089313] fr = [2.710718] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:20:30,956: Epoch 14 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [3.098358] gen = [0.088410] fr = [3.009948] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:20:57,638: Epoch 14 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [1.705016] gen = [0.092901] fr = [1.612116] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:21:24,336: Epoch 14 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [2.774059] gen = [0.078677] fr = [2.695382] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:21:51,020: Epoch 14 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [0.790380] gen = [0.088479] fr = [0.701901] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:22:17,701: Epoch 14 / 24, batch 1700 / 4333, 0.2668 sec/batch\n                         loss = [1.526958] gen = [0.093002] fr = [1.433956] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:22:44,378: Epoch 14 / 24, batch 1800 / 4333, 0.2668 sec/batch\n                         loss = [0.841844] gen = [0.090976] fr = [0.750868] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:23:11,053: Epoch 14 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [0.902427] gen = [0.093361] fr = [0.809066] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:23:37,728: Epoch 14 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [1.731904] gen = [0.094241] fr = [1.637663] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:24:04,396: Epoch 14 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [2.350671] gen = [0.086191] fr = [2.264480] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:24:31,057: Epoch 14 / 24, batch 2200 / 4333, 0.2666 sec/batch\n                         loss = [0.404192] gen = [0.087947] fr = [0.316245] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:24:57,734: Epoch 14 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [2.113612] gen = [0.086138] fr = [2.027474] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:25:24,410: Epoch 14 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [0.746462] gen = [0.078144] fr = [0.668318] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:25:51,091: Epoch 14 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [1.468575] gen = [0.082550] fr = [1.386025] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:26:17,758: Epoch 14 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [2.459692] gen = [0.084106] fr = [2.375586] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:26:44,434: Epoch 14 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [1.140761] gen = [0.083592] fr = [1.057169] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:27:11,117: Epoch 14 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [1.488464] gen = [0.085226] fr = [1.403238] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:27:37,782: Epoch 14 / 24, batch 2900 / 4333, 0.2667 sec/batch\n                         loss = [1.130607] gen = [0.093285] fr = [1.037323] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:28:04,445: Epoch 14 / 24, batch 3000 / 4333, 0.2667 sec/batch\n                         loss = [1.996775] gen = [0.084670] fr = [1.912105] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:28:31,109: Epoch 14 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [3.987061] gen = [0.083904] fr = [3.903157] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:28:57,783: Epoch 14 / 24, batch 3200 / 4333, 0.2667 sec/batch\n                         loss = [0.900088] gen = [0.090278] fr = [0.809810] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:29:24,458: Epoch 14 / 24, batch 3300 / 4333, 0.2667 sec/batch\n                         loss = [0.854554] gen = [0.085303] fr = [0.769251] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:29:51,128: Epoch 14 / 24, batch 3400 / 4333, 0.2667 sec/batch\n                         loss = [1.334587] gen = [0.082816] fr = [1.251771] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:30:17,787: Epoch 14 / 24, batch 3500 / 4333, 0.2667 sec/batch\n                         loss = [1.846446] gen = [0.084466] fr = [1.761980] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:30:44,457: Epoch 14 / 24, batch 3600 / 4333, 0.2667 sec/batch\n                         loss = [1.777558] gen = [0.090168] fr = [1.687390] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:31:11,123: Epoch 14 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [1.075630] gen = [0.081084] fr = [0.994546] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:31:37,793: Epoch 14 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [1.493109] gen = [0.094353] fr = [1.398757] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:32:04,469: Epoch 14 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [1.839236] gen = [0.087634] fr = [1.751602] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:32:31,135: Epoch 14 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [1.661785] gen = [0.094799] fr = [1.566985] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:32:57,804: Epoch 14 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [1.127266] gen = [0.092574] fr = [1.034692] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:33:24,463: Epoch 14 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [1.141616] gen = [0.078917] fr = [1.062699] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:33:51,133: Epoch 14 / 24, batch 4300 / 4333, 0.2667 sec/batch\n                         loss = [0.483475] gen = [0.108792] fr = [0.374683] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:34:00,798: Save checkpoint at epoch 14 ...\n2024-09-25 00:34:00,799: Current epoch 15, learning rate 0.001\n2024-09-25 00:34:01,258: Epoch 15 / 24, batch 1 / 4333, 0.4586 sec/batch\n                         loss = [0.361640] gen = [0.093480] fr = [0.268160] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:34:27,664: Epoch 15 / 24, batch 100 / 4333, 0.2686 sec/batch\n                         loss = [0.398565] gen = [0.091905] fr = [0.306659] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:34:54,339: Epoch 15 / 24, batch 200 / 4333, 0.2677 sec/batch\n                         loss = [1.710107] gen = [0.087356] fr = [1.622750] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:35:20,998: Epoch 15 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [0.768709] gen = [0.088045] fr = [0.680664] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:35:47,658: Epoch 15 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [1.567476] gen = [0.091659] fr = [1.475816] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:36:14,322: Epoch 15 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [3.613241] gen = [0.092294] fr = [3.520947] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:36:40,994: Epoch 15 / 24, batch 600 / 4333, 0.2667 sec/batch\n                         loss = [0.930226] gen = [0.086529] fr = [0.843696] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:37:07,673: Epoch 15 / 24, batch 700 / 4333, 0.2668 sec/batch\n                         loss = [1.415650] gen = [0.091504] fr = [1.324146] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:37:34,329: Epoch 15 / 24, batch 800 / 4333, 0.2667 sec/batch\n                         loss = [0.215000] gen = [0.085850] fr = [0.129150] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:38:01,010: Epoch 15 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [0.641135] gen = [0.082290] fr = [0.558844] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:38:27,686: Epoch 15 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [1.939119] gen = [0.078796] fr = [1.860322] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:38:54,364: Epoch 15 / 24, batch 1100 / 4333, 0.2668 sec/batch\n                         loss = [0.680078] gen = [0.077974] fr = [0.602104] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:39:21,047: Epoch 15 / 24, batch 1200 / 4333, 0.2668 sec/batch\n                         loss = [0.527184] gen = [0.085754] fr = [0.441430] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:39:47,726: Epoch 15 / 24, batch 1300 / 4333, 0.2668 sec/batch\n                         loss = [1.517513] gen = [0.086325] fr = [1.431189] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:40:14,401: Epoch 15 / 24, batch 1400 / 4333, 0.2668 sec/batch\n                         loss = [2.024167] gen = [0.081280] fr = [1.942887] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:40:41,081: Epoch 15 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [3.261464] gen = [0.096346] fr = [3.165118] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:41:07,764: Epoch 15 / 24, batch 1600 / 4333, 0.2668 sec/batch\n                         loss = [1.971748] gen = [0.083120] fr = [1.888627] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:41:34,443: Epoch 15 / 24, batch 1700 / 4333, 0.2668 sec/batch\n                         loss = [1.806636] gen = [0.084751] fr = [1.721885] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:42:01,123: Epoch 15 / 24, batch 1800 / 4333, 0.2668 sec/batch\n                         loss = [1.144851] gen = [0.085834] fr = [1.059018] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:42:27,806: Epoch 15 / 24, batch 1900 / 4333, 0.2668 sec/batch\n                         loss = [0.954663] gen = [0.083541] fr = [0.871123] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:42:54,481: Epoch 15 / 24, batch 2000 / 4333, 0.2668 sec/batch\n                         loss = [2.660515] gen = [0.081754] fr = [2.578761] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:43:21,135: Epoch 15 / 24, batch 2100 / 4333, 0.2665 sec/batch\n                         loss = [0.644802] gen = [0.085735] fr = [0.559067] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:43:47,801: Epoch 15 / 24, batch 2200 / 4333, 0.2666 sec/batch\n                         loss = [1.585230] gen = [0.082829] fr = [1.502401] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:44:14,485: Epoch 15 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [0.444451] gen = [0.080268] fr = [0.364183] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:44:41,168: Epoch 15 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [0.772375] gen = [0.086299] fr = [0.686076] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:45:07,843: Epoch 15 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [0.954860] gen = [0.087712] fr = [0.867148] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:45:34,516: Epoch 15 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [0.304455] gen = [0.094527] fr = [0.209928] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:46:01,189: Epoch 15 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [1.605305] gen = [0.089534] fr = [1.515771] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:46:27,874: Epoch 15 / 24, batch 2800 / 4333, 0.2668 sec/batch\n                         loss = [0.840252] gen = [0.085435] fr = [0.754817] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:46:54,560: Epoch 15 / 24, batch 2900 / 4333, 0.2668 sec/batch\n                         loss = [1.422001] gen = [0.075710] fr = [1.346292] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:47:21,260: Epoch 15 / 24, batch 3000 / 4333, 0.2668 sec/batch\n                         loss = [1.197323] gen = [0.088868] fr = [1.108455] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:47:47,945: Epoch 15 / 24, batch 3100 / 4333, 0.2668 sec/batch\n                         loss = [3.738688] gen = [0.097329] fr = [3.641359] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:48:14,617: Epoch 15 / 24, batch 3200 / 4333, 0.2668 sec/batch\n                         loss = [1.523869] gen = [0.083458] fr = [1.440412] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:48:41,259: Epoch 15 / 24, batch 3300 / 4333, 0.2667 sec/batch\n                         loss = [0.406851] gen = [0.084964] fr = [0.321887] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:49:07,890: Epoch 15 / 24, batch 3400 / 4333, 0.2666 sec/batch\n                         loss = [1.130613] gen = [0.077751] fr = [1.052861] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:49:34,536: Epoch 15 / 24, batch 3500 / 4333, 0.2666 sec/batch\n                         loss = [1.889762] gen = [0.093807] fr = [1.795954] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:50:01,177: Epoch 15 / 24, batch 3600 / 4333, 0.2664 sec/batch\n                         loss = [0.896815] gen = [0.095172] fr = [0.801644] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:50:27,788: Epoch 15 / 24, batch 3700 / 4333, 0.2663 sec/batch\n                         loss = [1.396695] gen = [0.089648] fr = [1.307048] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:50:54,397: Epoch 15 / 24, batch 3800 / 4333, 0.2662 sec/batch\n                         loss = [1.083854] gen = [0.095956] fr = [0.987898] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:51:21,007: Epoch 15 / 24, batch 3900 / 4333, 0.2662 sec/batch\n                         loss = [0.601016] gen = [0.081974] fr = [0.519043] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:51:47,635: Epoch 15 / 24, batch 4000 / 4333, 0.2662 sec/batch\n                         loss = [0.898339] gen = [0.084838] fr = [0.813501] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:52:14,269: Epoch 15 / 24, batch 4100 / 4333, 0.2663 sec/batch\n                         loss = [2.075282] gen = [0.085344] fr = [1.989938] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:52:40,921: Epoch 15 / 24, batch 4200 / 4333, 0.2664 sec/batch\n                         loss = [1.208638] gen = [0.082699] fr = [1.125940] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:53:07,594: Epoch 15 / 24, batch 4300 / 4333, 0.2665 sec/batch\n                         loss = [0.359940] gen = [0.087500] fr = [0.272440] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:53:17,252: Save checkpoint at epoch 15 ...\n2024-09-25 00:53:17,252: Current epoch 16, learning rate 0.001\n2024-09-25 00:53:17,730: Epoch 16 / 24, batch 1 / 4333, 0.4768 sec/batch\n                         loss = [0.375935] gen = [0.081259] fr = [0.294676] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:53:44,132: Epoch 16 / 24, batch 100 / 4333, 0.2688 sec/batch\n                         loss = [1.286546] gen = [0.079223] fr = [1.207322] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:54:10,799: Epoch 16 / 24, batch 200 / 4333, 0.2677 sec/batch\n                         loss = [1.466141] gen = [0.079179] fr = [1.386963] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:54:37,498: Epoch 16 / 24, batch 300 / 4333, 0.2675 sec/batch\n                         loss = [0.786750] gen = [0.088067] fr = [0.698683] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:55:04,154: Epoch 16 / 24, batch 400 / 4333, 0.2673 sec/batch\n                         loss = [1.532393] gen = [0.074193] fr = [1.458200] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:55:30,816: Epoch 16 / 24, batch 500 / 4333, 0.2671 sec/batch\n                         loss = [1.255329] gen = [0.084912] fr = [1.170418] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:55:57,471: Epoch 16 / 24, batch 600 / 4333, 0.2665 sec/batch\n                         loss = [0.156939] gen = [0.074457] fr = [0.082482] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:56:24,128: Epoch 16 / 24, batch 700 / 4333, 0.2666 sec/batch\n                         loss = [1.000930] gen = [0.077870] fr = [0.923060] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:56:50,784: Epoch 16 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [2.408209] gen = [0.089721] fr = [2.318488] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 00:57:17,434: Epoch 16 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [0.276989] gen = [0.086707] fr = [0.190281] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:57:44,084: Epoch 16 / 24, batch 1000 / 4333, 0.2665 sec/batch\n                         loss = [0.996443] gen = [0.085151] fr = [0.911292] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:58:10,693: Epoch 16 / 24, batch 1100 / 4333, 0.2661 sec/batch\n                         loss = [0.726377] gen = [0.085286] fr = [0.641091] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:58:37,307: Epoch 16 / 24, batch 1200 / 4333, 0.2661 sec/batch\n                         loss = [1.188716] gen = [0.076814] fr = [1.111902] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:59:03,929: Epoch 16 / 24, batch 1300 / 4333, 0.2662 sec/batch\n                         loss = [0.442108] gen = [0.089890] fr = [0.352217] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:59:30,568: Epoch 16 / 24, batch 1400 / 4333, 0.2662 sec/batch\n                         loss = [1.295151] gen = [0.080682] fr = [1.214469] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 00:59:57,230: Epoch 16 / 24, batch 1500 / 4333, 0.2663 sec/batch\n                         loss = [0.820372] gen = [0.078620] fr = [0.741751] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:00:23,869: Epoch 16 / 24, batch 1600 / 4333, 0.2664 sec/batch\n                         loss = [0.273743] gen = [0.077890] fr = [0.195853] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:00:50,520: Epoch 16 / 24, batch 1700 / 4333, 0.2664 sec/batch\n                         loss = [0.521298] gen = [0.082734] fr = [0.438564] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:01:17,193: Epoch 16 / 24, batch 1800 / 4333, 0.2665 sec/batch\n                         loss = [1.178507] gen = [0.082729] fr = [1.095779] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:01:43,856: Epoch 16 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [1.173477] gen = [0.088564] fr = [1.084913] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:02:10,518: Epoch 16 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [2.200508] gen = [0.086491] fr = [2.114017] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:02:37,191: Epoch 16 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [1.205996] gen = [0.089148] fr = [1.116848] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:03:03,859: Epoch 16 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [0.725173] gen = [0.081241] fr = [0.643932] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:03:30,524: Epoch 16 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [1.867758] gen = [0.084551] fr = [1.783206] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:03:57,198: Epoch 16 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [1.269017] gen = [0.088127] fr = [1.180889] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:04:23,872: Epoch 16 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [2.130870] gen = [0.078162] fr = [2.052708] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:04:50,544: Epoch 16 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [2.882071] gen = [0.095427] fr = [2.786643] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 01:05:17,220: Epoch 16 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [1.189091] gen = [0.082060] fr = [1.107031] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:05:43,882: Epoch 16 / 24, batch 2800 / 4333, 0.2667 sec/batch\n                         loss = [0.907611] gen = [0.093610] fr = [0.814001] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:06:10,542: Epoch 16 / 24, batch 2900 / 4333, 0.2667 sec/batch\n                         loss = [0.173627] gen = [0.075979] fr = [0.097648] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:06:37,221: Epoch 16 / 24, batch 3000 / 4333, 0.2667 sec/batch\n                         loss = [0.915855] gen = [0.080620] fr = [0.835235] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:07:03,890: Epoch 16 / 24, batch 3100 / 4333, 0.2667 sec/batch\n                         loss = [0.409954] gen = [0.088656] fr = [0.321299] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:07:30,559: Epoch 16 / 24, batch 3200 / 4333, 0.2667 sec/batch\n                         loss = [0.231258] gen = [0.088748] fr = [0.142510] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:07:57,233: Epoch 16 / 24, batch 3300 / 4333, 0.2667 sec/batch\n                         loss = [1.514292] gen = [0.080181] fr = [1.434111] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:08:23,900: Epoch 16 / 24, batch 3400 / 4333, 0.2667 sec/batch\n                         loss = [0.847634] gen = [0.076716] fr = [0.770918] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:08:50,572: Epoch 16 / 24, batch 3500 / 4333, 0.2667 sec/batch\n                         loss = [1.108742] gen = [0.079187] fr = [1.029555] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:09:17,241: Epoch 16 / 24, batch 3600 / 4333, 0.2667 sec/batch\n                         loss = [0.516231] gen = [0.088509] fr = [0.427722] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:09:43,908: Epoch 16 / 24, batch 3700 / 4333, 0.2667 sec/batch\n                         loss = [0.422150] gen = [0.081966] fr = [0.340183] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:10:10,577: Epoch 16 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [0.668634] gen = [0.075851] fr = [0.592783] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:10:37,248: Epoch 16 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [1.190327] gen = [0.081929] fr = [1.108398] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:11:03,916: Epoch 16 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [0.701031] gen = [0.080888] fr = [0.620143] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:11:30,581: Epoch 16 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [0.162849] gen = [0.084109] fr = [0.078741] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:11:57,227: Epoch 16 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [0.777655] gen = [0.082614] fr = [0.695041] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:12:23,877: Epoch 16 / 24, batch 4300 / 4333, 0.2665 sec/batch\n                         loss = [2.059418] gen = [0.080895] fr = [1.978523] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:12:33,532: Save checkpoint at epoch 16 ...\n2024-09-25 01:12:33,533: Current epoch 17, learning rate 0.001\n2024-09-25 01:12:34,002: Epoch 17 / 24, batch 1 / 4333, 0.4680 sec/batch\n                         loss = [0.447161] gen = [0.084293] fr = [0.362868] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:13:00,385: Epoch 17 / 24, batch 100 / 4333, 0.2685 sec/batch\n                         loss = [0.532762] gen = [0.076374] fr = [0.456388] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:13:27,047: Epoch 17 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [1.400393] gen = [0.074341] fr = [1.326052] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:13:53,691: Epoch 17 / 24, batch 300 / 4333, 0.2672 sec/batch\n                         loss = [0.784058] gen = [0.086834] fr = [0.697224] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:14:20,370: Epoch 17 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [0.545988] gen = [0.088538] fr = [0.457450] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:14:47,047: Epoch 17 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [1.524312] gen = [0.079578] fr = [1.444735] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:15:13,724: Epoch 17 / 24, batch 600 / 4333, 0.2668 sec/batch\n                         loss = [0.779027] gen = [0.078699] fr = [0.700328] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:15:40,386: Epoch 17 / 24, batch 700 / 4333, 0.2667 sec/batch\n                         loss = [0.481910] gen = [0.085467] fr = [0.396444] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:16:07,057: Epoch 17 / 24, batch 800 / 4333, 0.2667 sec/batch\n                         loss = [1.640657] gen = [0.082455] fr = [1.558201] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:16:33,720: Epoch 17 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [1.614842] gen = [0.081676] fr = [1.533166] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:17:00,397: Epoch 17 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [0.470663] gen = [0.073976] fr = [0.396687] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:17:27,061: Epoch 17 / 24, batch 1100 / 4333, 0.2666 sec/batch\n                         loss = [0.497733] gen = [0.083836] fr = [0.413897] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:17:53,730: Epoch 17 / 24, batch 1200 / 4333, 0.2667 sec/batch\n                         loss = [0.453260] gen = [0.073754] fr = [0.379506] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:18:20,396: Epoch 17 / 24, batch 1300 / 4333, 0.2667 sec/batch\n                         loss = [0.361650] gen = [0.075533] fr = [0.286117] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:18:47,060: Epoch 17 / 24, batch 1400 / 4333, 0.2667 sec/batch\n                         loss = [0.590728] gen = [0.073832] fr = [0.516896] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:19:13,722: Epoch 17 / 24, batch 1500 / 4333, 0.2667 sec/batch\n                         loss = [0.647451] gen = [0.082120] fr = [0.565331] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:19:40,380: Epoch 17 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [1.007549] gen = [0.079609] fr = [0.927940] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:20:07,047: Epoch 17 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.384046] gen = [0.083988] fr = [0.300058] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:20:33,695: Epoch 17 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.422410] gen = [0.076350] fr = [0.346060] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:21:00,349: Epoch 17 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [1.172102] gen = [0.079199] fr = [1.092903] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:21:26,999: Epoch 17 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [3.369048] gen = [0.078422] fr = [3.290626] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 01:21:53,673: Epoch 17 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [0.317470] gen = [0.077987] fr = [0.239483] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:22:20,339: Epoch 17 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [0.500782] gen = [0.081240] fr = [0.419543] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:22:47,012: Epoch 17 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [0.288331] gen = [0.071846] fr = [0.216485] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:23:13,675: Epoch 17 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [0.534435] gen = [0.086365] fr = [0.448070] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:23:40,343: Epoch 17 / 24, batch 2500 / 4333, 0.2667 sec/batch\n                         loss = [0.431750] gen = [0.078718] fr = [0.353031] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:24:07,010: Epoch 17 / 24, batch 2600 / 4333, 0.2667 sec/batch\n                         loss = [0.611342] gen = [0.079932] fr = [0.531410] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:24:33,669: Epoch 17 / 24, batch 2700 / 4333, 0.2666 sec/batch\n                         loss = [0.620671] gen = [0.091501] fr = [0.529170] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:25:00,326: Epoch 17 / 24, batch 2800 / 4333, 0.2666 sec/batch\n                         loss = [0.623332] gen = [0.076546] fr = [0.546785] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:25:26,993: Epoch 17 / 24, batch 2900 / 4333, 0.2666 sec/batch\n                         loss = [0.625854] gen = [0.080963] fr = [0.544891] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:25:53,655: Epoch 17 / 24, batch 3000 / 4333, 0.2666 sec/batch\n                         loss = [1.483834] gen = [0.081924] fr = [1.401910] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:26:20,319: Epoch 17 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [0.319266] gen = [0.080466] fr = [0.238800] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:26:46,986: Epoch 17 / 24, batch 3200 / 4333, 0.2667 sec/batch\n                         loss = [0.438146] gen = [0.090551] fr = [0.347595] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:27:13,651: Epoch 17 / 24, batch 3300 / 4333, 0.2667 sec/batch\n                         loss = [1.999002] gen = [0.082297] fr = [1.916706] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:27:40,307: Epoch 17 / 24, batch 3400 / 4333, 0.2666 sec/batch\n                         loss = [0.273670] gen = [0.091176] fr = [0.182494] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:28:06,945: Epoch 17 / 24, batch 3500 / 4333, 0.2666 sec/batch\n                         loss = [1.343956] gen = [0.080443] fr = [1.263513] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:28:33,585: Epoch 17 / 24, batch 3600 / 4333, 0.2664 sec/batch\n                         loss = [0.468901] gen = [0.077474] fr = [0.391427] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:29:00,225: Epoch 17 / 24, batch 3700 / 4333, 0.2664 sec/batch\n                         loss = [0.324640] gen = [0.079476] fr = [0.245164] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:29:26,883: Epoch 17 / 24, batch 3800 / 4333, 0.2665 sec/batch\n                         loss = [0.517461] gen = [0.084775] fr = [0.432686] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:29:53,534: Epoch 17 / 24, batch 3900 / 4333, 0.2665 sec/batch\n                         loss = [0.765188] gen = [0.076979] fr = [0.688209] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:30:20,179: Epoch 17 / 24, batch 4000 / 4333, 0.2665 sec/batch\n                         loss = [2.850885] gen = [0.070330] fr = [2.780555] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 01:30:46,841: Epoch 17 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [0.667015] gen = [0.081158] fr = [0.585857] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:31:13,498: Epoch 17 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [0.959266] gen = [0.094315] fr = [0.864951] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:31:40,157: Epoch 17 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [1.077777] gen = [0.088418] fr = [0.989359] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:31:49,819: Save checkpoint at epoch 17 ...\n2024-09-25 01:31:49,819: Current epoch 18, learning rate 0.001\n2024-09-25 01:31:50,273: Epoch 18 / 24, batch 1 / 4333, 0.4525 sec/batch\n                         loss = [0.961782] gen = [0.091806] fr = [0.869976] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:32:16,683: Epoch 18 / 24, batch 100 / 4333, 0.2686 sec/batch\n                         loss = [1.378188] gen = [0.080795] fr = [1.297394] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:32:43,339: Epoch 18 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [0.949055] gen = [0.078736] fr = [0.870319] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:33:10,000: Epoch 18 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [4.934973] gen = [0.073203] fr = [4.861770] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 01:33:36,663: Epoch 18 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [0.270754] gen = [0.076881] fr = [0.193874] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:34:03,329: Epoch 18 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [1.099554] gen = [0.081193] fr = [1.018361] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:34:29,983: Epoch 18 / 24, batch 600 / 4333, 0.2665 sec/batch\n                         loss = [1.010120] gen = [0.082832] fr = [0.927288] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:34:56,634: Epoch 18 / 24, batch 700 / 4333, 0.2665 sec/batch\n                         loss = [0.956995] gen = [0.080767] fr = [0.876228] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:35:23,286: Epoch 18 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [0.434825] gen = [0.082651] fr = [0.352175] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:35:49,922: Epoch 18 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [0.189452] gen = [0.075588] fr = [0.113864] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:36:16,575: Epoch 18 / 24, batch 1000 / 4333, 0.2665 sec/batch\n                         loss = [0.662355] gen = [0.072816] fr = [0.589539] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:36:43,241: Epoch 18 / 24, batch 1100 / 4333, 0.2667 sec/batch\n                         loss = [0.794029] gen = [0.074109] fr = [0.719920] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:37:09,909: Epoch 18 / 24, batch 1200 / 4333, 0.2667 sec/batch\n                         loss = [0.399483] gen = [0.071245] fr = [0.328238] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:37:36,599: Epoch 18 / 24, batch 1300 / 4333, 0.2667 sec/batch\n                         loss = [0.770259] gen = [0.071972] fr = [0.698287] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:38:03,268: Epoch 18 / 24, batch 1400 / 4333, 0.2667 sec/batch\n                         loss = [0.805932] gen = [0.070565] fr = [0.735367] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:38:29,931: Epoch 18 / 24, batch 1500 / 4333, 0.2667 sec/batch\n                         loss = [0.308874] gen = [0.074544] fr = [0.234330] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:38:56,592: Epoch 18 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [0.186392] gen = [0.072403] fr = [0.113989] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:39:23,252: Epoch 18 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.683945] gen = [0.096611] fr = [0.587334] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:39:49,913: Epoch 18 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.588701] gen = [0.077085] fr = [0.511616] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:40:16,587: Epoch 18 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.402440] gen = [0.087250] fr = [0.315190] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:40:43,248: Epoch 18 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [0.768894] gen = [0.091138] fr = [0.677755] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:41:09,902: Epoch 18 / 24, batch 2100 / 4333, 0.2665 sec/batch\n                         loss = [0.375528] gen = [0.079797] fr = [0.295732] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:41:36,569: Epoch 18 / 24, batch 2200 / 4333, 0.2666 sec/batch\n                         loss = [0.777610] gen = [0.072132] fr = [0.705478] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:42:03,233: Epoch 18 / 24, batch 2300 / 4333, 0.2666 sec/batch\n                         loss = [0.483281] gen = [0.084858] fr = [0.398423] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:42:29,898: Epoch 18 / 24, batch 2400 / 4333, 0.2666 sec/batch\n                         loss = [0.285111] gen = [0.073617] fr = [0.211494] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:42:56,554: Epoch 18 / 24, batch 2500 / 4333, 0.2666 sec/batch\n                         loss = [0.100522] gen = [0.077627] fr = [0.022895] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:43:23,202: Epoch 18 / 24, batch 2600 / 4333, 0.2665 sec/batch\n                         loss = [0.381266] gen = [0.082271] fr = [0.298995] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:43:49,853: Epoch 18 / 24, batch 2700 / 4333, 0.2665 sec/batch\n                         loss = [0.396932] gen = [0.070258] fr = [0.326674] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:44:16,513: Epoch 18 / 24, batch 2800 / 4333, 0.2665 sec/batch\n                         loss = [0.681914] gen = [0.083786] fr = [0.598128] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:44:43,171: Epoch 18 / 24, batch 2900 / 4333, 0.2665 sec/batch\n                         loss = [0.422899] gen = [0.075117] fr = [0.347783] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:45:09,835: Epoch 18 / 24, batch 3000 / 4333, 0.2666 sec/batch\n                         loss = [1.407292] gen = [0.083636] fr = [1.323656] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:45:36,500: Epoch 18 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [0.656685] gen = [0.076481] fr = [0.580203] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:46:03,162: Epoch 18 / 24, batch 3200 / 4333, 0.2666 sec/batch\n                         loss = [0.735322] gen = [0.078186] fr = [0.657137] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:46:29,826: Epoch 18 / 24, batch 3300 / 4333, 0.2666 sec/batch\n                         loss = [1.275477] gen = [0.088921] fr = [1.186556] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:46:56,481: Epoch 18 / 24, batch 3400 / 4333, 0.2666 sec/batch\n                         loss = [1.870620] gen = [0.071852] fr = [1.798768] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:47:23,146: Epoch 18 / 24, batch 3500 / 4333, 0.2666 sec/batch\n                         loss = [1.503872] gen = [0.094531] fr = [1.409341] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:47:49,808: Epoch 18 / 24, batch 3600 / 4333, 0.2666 sec/batch\n                         loss = [0.281406] gen = [0.081725] fr = [0.199682] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:48:16,474: Epoch 18 / 24, batch 3700 / 4333, 0.2666 sec/batch\n                         loss = [0.548563] gen = [0.075725] fr = [0.472838] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:48:43,143: Epoch 18 / 24, batch 3800 / 4333, 0.2667 sec/batch\n                         loss = [0.484787] gen = [0.070629] fr = [0.414157] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:49:09,809: Epoch 18 / 24, batch 3900 / 4333, 0.2667 sec/batch\n                         loss = [0.593249] gen = [0.072761] fr = [0.520488] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:49:36,478: Epoch 18 / 24, batch 4000 / 4333, 0.2667 sec/batch\n                         loss = [0.340716] gen = [0.075008] fr = [0.265708] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:50:03,149: Epoch 18 / 24, batch 4100 / 4333, 0.2667 sec/batch\n                         loss = [0.309713] gen = [0.085303] fr = [0.224410] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:50:29,805: Epoch 18 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [0.311436] gen = [0.082469] fr = [0.228967] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:50:56,454: Epoch 18 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [0.561114] gen = [0.070741] fr = [0.490373] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:51:06,113: Save checkpoint at epoch 18 ...\n2024-09-25 01:51:06,113: Current epoch 19, learning rate 0.0001\n2024-09-25 01:51:06,555: Epoch 19 / 24, batch 1 / 4333, 0.4411 sec/batch\n                         loss = [0.388975] gen = [0.074003] fr = [0.314972] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:51:32,945: Epoch 19 / 24, batch 100 / 4333, 0.2683 sec/batch\n                         loss = [0.355810] gen = [0.084016] fr = [0.271794] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:51:59,620: Epoch 19 / 24, batch 200 / 4333, 0.2675 sec/batch\n                         loss = [1.936141] gen = [0.079326] fr = [1.856815] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:52:26,284: Epoch 19 / 24, batch 300 / 4333, 0.2672 sec/batch\n                         loss = [0.731734] gen = [0.070897] fr = [0.660837] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:52:52,951: Epoch 19 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [0.176862] gen = [0.073514] fr = [0.103348] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:53:19,619: Epoch 19 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [0.666431] gen = [0.070773] fr = [0.595658] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:53:46,294: Epoch 19 / 24, batch 600 / 4333, 0.2668 sec/batch\n                         loss = [1.166845] gen = [0.082362] fr = [1.084484] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:54:12,967: Epoch 19 / 24, batch 700 / 4333, 0.2667 sec/batch\n                         loss = [0.349703] gen = [0.074980] fr = [0.274723] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:54:39,642: Epoch 19 / 24, batch 800 / 4333, 0.2667 sec/batch\n                         loss = [1.095905] gen = [0.074633] fr = [1.021272] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:55:06,302: Epoch 19 / 24, batch 900 / 4333, 0.2667 sec/batch\n                         loss = [0.165226] gen = [0.079388] fr = [0.085838] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:55:32,969: Epoch 19 / 24, batch 1000 / 4333, 0.2667 sec/batch\n                         loss = [0.173639] gen = [0.079389] fr = [0.094249] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:55:59,632: Epoch 19 / 24, batch 1100 / 4333, 0.2666 sec/batch\n                         loss = [0.720475] gen = [0.076599] fr = [0.643875] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:56:26,304: Epoch 19 / 24, batch 1200 / 4333, 0.2667 sec/batch\n                         loss = [0.590351] gen = [0.079828] fr = [0.510524] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:56:52,966: Epoch 19 / 24, batch 1300 / 4333, 0.2667 sec/batch\n                         loss = [0.832686] gen = [0.084644] fr = [0.748042] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:57:19,629: Epoch 19 / 24, batch 1400 / 4333, 0.2667 sec/batch\n                         loss = [0.350661] gen = [0.076729] fr = [0.273932] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:57:46,279: Epoch 19 / 24, batch 1500 / 4333, 0.2666 sec/batch\n                         loss = [0.105672] gen = [0.078751] fr = [0.026921] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:58:12,941: Epoch 19 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [0.207026] gen = [0.084128] fr = [0.122898] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:58:39,595: Epoch 19 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.089880] gen = [0.075990] fr = [0.013890] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:59:06,247: Epoch 19 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.494160] gen = [0.080322] fr = [0.413838] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:59:32,916: Epoch 19 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.201823] gen = [0.072587] fr = [0.129236] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 01:59:59,594: Epoch 19 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [0.710765] gen = [0.078049] fr = [0.632716] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:00:26,277: Epoch 19 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [0.420567] gen = [0.078468] fr = [0.342098] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:00:52,939: Epoch 19 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [0.883875] gen = [0.079271] fr = [0.804603] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:01:19,596: Epoch 19 / 24, batch 2300 / 4333, 0.2667 sec/batch\n                         loss = [0.722145] gen = [0.077812] fr = [0.644334] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:01:46,259: Epoch 19 / 24, batch 2400 / 4333, 0.2667 sec/batch\n                         loss = [0.567200] gen = [0.071419] fr = [0.495781] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:02:12,913: Epoch 19 / 24, batch 2500 / 4333, 0.2666 sec/batch\n                         loss = [0.244445] gen = [0.081633] fr = [0.162812] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:02:39,565: Epoch 19 / 24, batch 2600 / 4333, 0.2665 sec/batch\n                         loss = [0.861872] gen = [0.076350] fr = [0.785522] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:03:06,215: Epoch 19 / 24, batch 2700 / 4333, 0.2665 sec/batch\n                         loss = [0.398085] gen = [0.084749] fr = [0.313336] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:03:32,867: Epoch 19 / 24, batch 2800 / 4333, 0.2665 sec/batch\n                         loss = [0.423245] gen = [0.074131] fr = [0.349114] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:03:59,523: Epoch 19 / 24, batch 2900 / 4333, 0.2665 sec/batch\n                         loss = [0.382610] gen = [0.083863] fr = [0.298747] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:04:26,187: Epoch 19 / 24, batch 3000 / 4333, 0.2665 sec/batch\n                         loss = [0.497410] gen = [0.071502] fr = [0.425908] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:04:52,840: Epoch 19 / 24, batch 3100 / 4333, 0.2665 sec/batch\n                         loss = [0.435125] gen = [0.078998] fr = [0.356128] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:05:19,512: Epoch 19 / 24, batch 3200 / 4333, 0.2666 sec/batch\n                         loss = [0.322724] gen = [0.072410] fr = [0.250313] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:05:46,154: Epoch 19 / 24, batch 3300 / 4333, 0.2666 sec/batch\n                         loss = [0.360232] gen = [0.079153] fr = [0.281079] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:06:12,800: Epoch 19 / 24, batch 3400 / 4333, 0.2665 sec/batch\n                         loss = [0.602068] gen = [0.070545] fr = [0.531523] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:06:39,445: Epoch 19 / 24, batch 3500 / 4333, 0.2665 sec/batch\n                         loss = [0.451707] gen = [0.067817] fr = [0.383890] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:07:06,109: Epoch 19 / 24, batch 3600 / 4333, 0.2666 sec/batch\n                         loss = [0.392172] gen = [0.073971] fr = [0.318201] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:07:32,766: Epoch 19 / 24, batch 3700 / 4333, 0.2666 sec/batch\n                         loss = [0.382308] gen = [0.066451] fr = [0.315857] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:07:59,424: Epoch 19 / 24, batch 3800 / 4333, 0.2666 sec/batch\n                         loss = [0.843543] gen = [0.069554] fr = [0.773989] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:08:26,078: Epoch 19 / 24, batch 3900 / 4333, 0.2666 sec/batch\n                         loss = [0.528747] gen = [0.073121] fr = [0.455626] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:08:52,732: Epoch 19 / 24, batch 4000 / 4333, 0.2666 sec/batch\n                         loss = [0.306865] gen = [0.075254] fr = [0.231611] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:09:19,390: Epoch 19 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [0.508986] gen = [0.082438] fr = [0.426548] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:09:46,045: Epoch 19 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [0.486946] gen = [0.081652] fr = [0.405295] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:10:12,709: Epoch 19 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [0.513922] gen = [0.070770] fr = [0.443153] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:10:22,427: Save checkpoint at epoch 19 ...\n2024-09-25 02:10:22,427: Current epoch 20, learning rate 0.0001\n2024-09-25 02:10:23,020: Epoch 20 / 24, batch 1 / 4333, 0.5914 sec/batch\n                         loss = [0.127722] gen = [0.072435] fr = [0.055287] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:10:49,409: Epoch 20 / 24, batch 100 / 4333, 0.2698 sec/batch\n                         loss = [0.682803] gen = [0.070464] fr = [0.612339] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:11:16,065: Epoch 20 / 24, batch 200 / 4333, 0.2682 sec/batch\n                         loss = [0.664794] gen = [0.073041] fr = [0.591753] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:11:42,732: Epoch 20 / 24, batch 300 / 4333, 0.2677 sec/batch\n                         loss = [0.238417] gen = [0.078821] fr = [0.159596] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:12:09,396: Epoch 20 / 24, batch 400 / 4333, 0.2674 sec/batch\n                         loss = [0.115923] gen = [0.074536] fr = [0.041387] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:12:36,057: Epoch 20 / 24, batch 500 / 4333, 0.2673 sec/batch\n                         loss = [0.640666] gen = [0.077334] fr = [0.563332] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:13:02,703: Epoch 20 / 24, batch 600 / 4333, 0.2665 sec/batch\n                         loss = [0.401845] gen = [0.077554] fr = [0.324291] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:13:29,345: Epoch 20 / 24, batch 700 / 4333, 0.2664 sec/batch\n                         loss = [0.563645] gen = [0.071378] fr = [0.492267] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:13:55,990: Epoch 20 / 24, batch 800 / 4333, 0.2664 sec/batch\n                         loss = [0.641360] gen = [0.067590] fr = [0.573770] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:14:22,641: Epoch 20 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [3.411914] gen = [0.069536] fr = [3.342377] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:14:49,298: Epoch 20 / 24, batch 1000 / 4333, 0.2665 sec/batch\n                         loss = [0.233674] gen = [0.072982] fr = [0.160693] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:15:15,959: Epoch 20 / 24, batch 1100 / 4333, 0.2666 sec/batch\n                         loss = [0.173023] gen = [0.078568] fr = [0.094455] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:15:42,613: Epoch 20 / 24, batch 1200 / 4333, 0.2666 sec/batch\n                         loss = [1.720576] gen = [0.078183] fr = [1.642393] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:16:09,269: Epoch 20 / 24, batch 1300 / 4333, 0.2666 sec/batch\n                         loss = [0.100093] gen = [0.079926] fr = [0.020167] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:16:35,928: Epoch 20 / 24, batch 1400 / 4333, 0.2666 sec/batch\n                         loss = [0.594276] gen = [0.075779] fr = [0.518497] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:17:02,586: Epoch 20 / 24, batch 1500 / 4333, 0.2666 sec/batch\n                         loss = [0.591587] gen = [0.067665] fr = [0.523922] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:17:29,247: Epoch 20 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [0.851080] gen = [0.075403] fr = [0.775677] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:17:55,905: Epoch 20 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.475959] gen = [0.071465] fr = [0.404494] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:18:22,567: Epoch 20 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.356061] gen = [0.077149] fr = [0.278912] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:18:49,227: Epoch 20 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.665421] gen = [0.072873] fr = [0.592548] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:19:15,886: Epoch 20 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [2.528149] gen = [0.077198] fr = [2.450951] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:19:42,542: Epoch 20 / 24, batch 2100 / 4333, 0.2666 sec/batch\n                         loss = [0.748812] gen = [0.072881] fr = [0.675931] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:20:09,208: Epoch 20 / 24, batch 2200 / 4333, 0.2666 sec/batch\n                         loss = [0.616752] gen = [0.067652] fr = [0.549099] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:20:35,862: Epoch 20 / 24, batch 2300 / 4333, 0.2666 sec/batch\n                         loss = [0.257005] gen = [0.071189] fr = [0.185816] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:21:02,499: Epoch 20 / 24, batch 2400 / 4333, 0.2665 sec/batch\n                         loss = [1.028945] gen = [0.070131] fr = [0.958813] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:21:29,135: Epoch 20 / 24, batch 2500 / 4333, 0.2665 sec/batch\n                         loss = [0.609036] gen = [0.074387] fr = [0.534649] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:21:55,790: Epoch 20 / 24, batch 2600 / 4333, 0.2665 sec/batch\n                         loss = [0.469684] gen = [0.068119] fr = [0.401564] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:22:22,442: Epoch 20 / 24, batch 2700 / 4333, 0.2665 sec/batch\n                         loss = [0.674702] gen = [0.074647] fr = [0.600055] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:22:49,096: Epoch 20 / 24, batch 2800 / 4333, 0.2665 sec/batch\n                         loss = [3.791393] gen = [0.078814] fr = [3.712579] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:23:15,749: Epoch 20 / 24, batch 2900 / 4333, 0.2665 sec/batch\n                         loss = [3.097348] gen = [0.065661] fr = [3.031687] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:23:42,411: Epoch 20 / 24, batch 3000 / 4333, 0.2666 sec/batch\n                         loss = [0.665855] gen = [0.075060] fr = [0.590795] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:24:09,066: Epoch 20 / 24, batch 3100 / 4333, 0.2666 sec/batch\n                         loss = [0.550825] gen = [0.083908] fr = [0.466918] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:24:35,715: Epoch 20 / 24, batch 3200 / 4333, 0.2665 sec/batch\n                         loss = [0.530952] gen = [0.077924] fr = [0.453028] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:25:02,368: Epoch 20 / 24, batch 3300 / 4333, 0.2665 sec/batch\n                         loss = [0.404406] gen = [0.082479] fr = [0.321927] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:25:29,006: Epoch 20 / 24, batch 3400 / 4333, 0.2665 sec/batch\n                         loss = [0.512145] gen = [0.087616] fr = [0.424529] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:25:55,662: Epoch 20 / 24, batch 3500 / 4333, 0.2665 sec/batch\n                         loss = [0.585012] gen = [0.075912] fr = [0.509100] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:26:22,315: Epoch 20 / 24, batch 3600 / 4333, 0.2665 sec/batch\n                         loss = [0.801785] gen = [0.074524] fr = [0.727261] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:26:48,977: Epoch 20 / 24, batch 3700 / 4333, 0.2666 sec/batch\n                         loss = [0.269969] gen = [0.071264] fr = [0.198705] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:27:15,636: Epoch 20 / 24, batch 3800 / 4333, 0.2666 sec/batch\n                         loss = [0.447006] gen = [0.070134] fr = [0.376872] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:27:42,294: Epoch 20 / 24, batch 3900 / 4333, 0.2666 sec/batch\n                         loss = [0.690776] gen = [0.077773] fr = [0.613003] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:28:08,936: Epoch 20 / 24, batch 4000 / 4333, 0.2665 sec/batch\n                         loss = [1.177337] gen = [0.076311] fr = [1.101026] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:28:35,573: Epoch 20 / 24, batch 4100 / 4333, 0.2664 sec/batch\n                         loss = [0.309942] gen = [0.065540] fr = [0.244402] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:29:02,216: Epoch 20 / 24, batch 4200 / 4333, 0.2664 sec/batch\n                         loss = [0.333644] gen = [0.082632] fr = [0.251013] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:29:28,869: Epoch 20 / 24, batch 4300 / 4333, 0.2664 sec/batch\n                         loss = [0.330079] gen = [0.076881] fr = [0.253198] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:29:38,538: Save checkpoint at epoch 20 ...\n2024-09-25 02:29:38,538: Current epoch 21, learning rate 0.0001\n2024-09-25 02:29:38,982: Epoch 21 / 24, batch 1 / 4333, 0.4422 sec/batch\n                         loss = [0.582217] gen = [0.075833] fr = [0.506384] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:30:05,361: Epoch 21 / 24, batch 100 / 4333, 0.2682 sec/batch\n                         loss = [0.602544] gen = [0.074757] fr = [0.527787] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:30:32,024: Epoch 21 / 24, batch 200 / 4333, 0.2674 sec/batch\n                         loss = [0.277932] gen = [0.081100] fr = [0.196832] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:30:58,689: Epoch 21 / 24, batch 300 / 4333, 0.2672 sec/batch\n                         loss = [2.076127] gen = [0.078455] fr = [1.997673] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:31:25,355: Epoch 21 / 24, batch 400 / 4333, 0.2670 sec/batch\n                         loss = [0.541117] gen = [0.063361] fr = [0.477756] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:31:52,012: Epoch 21 / 24, batch 500 / 4333, 0.2669 sec/batch\n                         loss = [0.205622] gen = [0.078735] fr = [0.126887] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:32:18,673: Epoch 21 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [0.755643] gen = [0.068412] fr = [0.687231] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:32:45,335: Epoch 21 / 24, batch 700 / 4333, 0.2666 sec/batch\n                         loss = [0.598945] gen = [0.071443] fr = [0.527502] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:33:11,996: Epoch 21 / 24, batch 800 / 4333, 0.2666 sec/batch\n                         loss = [1.145904] gen = [0.074767] fr = [1.071136] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:33:38,662: Epoch 21 / 24, batch 900 / 4333, 0.2666 sec/batch\n                         loss = [1.147244] gen = [0.080764] fr = [1.066480] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:34:05,322: Epoch 21 / 24, batch 1000 / 4333, 0.2666 sec/batch\n                         loss = [0.434795] gen = [0.077581] fr = [0.357214] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:34:31,989: Epoch 21 / 24, batch 1100 / 4333, 0.2667 sec/batch\n                         loss = [0.289089] gen = [0.072047] fr = [0.217042] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:34:58,645: Epoch 21 / 24, batch 1200 / 4333, 0.2666 sec/batch\n                         loss = [0.880528] gen = [0.071244] fr = [0.809283] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:35:25,296: Epoch 21 / 24, batch 1300 / 4333, 0.2666 sec/batch\n                         loss = [3.780073] gen = [0.080639] fr = [3.699434] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:35:51,937: Epoch 21 / 24, batch 1400 / 4333, 0.2665 sec/batch\n                         loss = [0.101871] gen = [0.073681] fr = [0.028190] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:36:18,571: Epoch 21 / 24, batch 1500 / 4333, 0.2665 sec/batch\n                         loss = [0.368307] gen = [0.080359] fr = [0.287948] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:36:45,226: Epoch 21 / 24, batch 1600 / 4333, 0.2665 sec/batch\n                         loss = [0.297297] gen = [0.061425] fr = [0.235872] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:37:11,886: Epoch 21 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.180223] gen = [0.075048] fr = [0.105175] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:37:38,559: Epoch 21 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.921510] gen = [0.066162] fr = [0.855348] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:38:05,219: Epoch 21 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.349949] gen = [0.081337] fr = [0.268612] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:38:31,879: Epoch 21 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [0.217331] gen = [0.077774] fr = [0.139557] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:38:58,546: Epoch 21 / 24, batch 2100 / 4333, 0.2667 sec/batch\n                         loss = [1.670102] gen = [0.076449] fr = [1.593653] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:39:25,212: Epoch 21 / 24, batch 2200 / 4333, 0.2667 sec/batch\n                         loss = [0.308680] gen = [0.067748] fr = [0.240932] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:39:51,873: Epoch 21 / 24, batch 2300 / 4333, 0.2666 sec/batch\n                         loss = [1.186321] gen = [0.073042] fr = [1.113279] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:40:18,533: Epoch 21 / 24, batch 2400 / 4333, 0.2666 sec/batch\n                         loss = [0.532138] gen = [0.066494] fr = [0.465643] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:40:45,187: Epoch 21 / 24, batch 2500 / 4333, 0.2666 sec/batch\n                         loss = [0.901750] gen = [0.069151] fr = [0.832599] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:41:11,845: Epoch 21 / 24, batch 2600 / 4333, 0.2666 sec/batch\n                         loss = [0.306063] gen = [0.071190] fr = [0.234873] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:41:38,499: Epoch 21 / 24, batch 2700 / 4333, 0.2666 sec/batch\n                         loss = [2.996002] gen = [0.073943] fr = [2.922059] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:42:05,156: Epoch 21 / 24, batch 2800 / 4333, 0.2666 sec/batch\n                         loss = [0.828629] gen = [0.075389] fr = [0.753240] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:42:31,818: Epoch 21 / 24, batch 2900 / 4333, 0.2666 sec/batch\n                         loss = [0.710770] gen = [0.074152] fr = [0.636618] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:42:58,466: Epoch 21 / 24, batch 3000 / 4333, 0.2666 sec/batch\n                         loss = [0.352222] gen = [0.065673] fr = [0.286549] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:43:25,101: Epoch 21 / 24, batch 3100 / 4333, 0.2664 sec/batch\n                         loss = [0.270795] gen = [0.079637] fr = [0.191158] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:43:51,739: Epoch 21 / 24, batch 3200 / 4333, 0.2664 sec/batch\n                         loss = [0.443208] gen = [0.080805] fr = [0.362403] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:44:18,392: Epoch 21 / 24, batch 3300 / 4333, 0.2664 sec/batch\n                         loss = [3.762856] gen = [0.077707] fr = [3.685149] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 02:44:45,053: Epoch 21 / 24, batch 3400 / 4333, 0.2665 sec/batch\n                         loss = [0.362324] gen = [0.081288] fr = [0.281036] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:45:11,704: Epoch 21 / 24, batch 3500 / 4333, 0.2665 sec/batch\n                         loss = [0.753601] gen = [0.066033] fr = [0.687568] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:45:38,355: Epoch 21 / 24, batch 3600 / 4333, 0.2665 sec/batch\n                         loss = [0.488560] gen = [0.072039] fr = [0.416521] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:46:05,018: Epoch 21 / 24, batch 3700 / 4333, 0.2666 sec/batch\n                         loss = [0.150565] gen = [0.066966] fr = [0.083599] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:46:31,687: Epoch 21 / 24, batch 3800 / 4333, 0.2666 sec/batch\n                         loss = [0.914836] gen = [0.083388] fr = [0.831448] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:46:58,328: Epoch 21 / 24, batch 3900 / 4333, 0.2666 sec/batch\n                         loss = [0.425931] gen = [0.073775] fr = [0.352156] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:47:24,990: Epoch 21 / 24, batch 4000 / 4333, 0.2666 sec/batch\n                         loss = [0.178312] gen = [0.075889] fr = [0.102423] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:47:51,642: Epoch 21 / 24, batch 4100 / 4333, 0.2665 sec/batch\n                         loss = [0.953460] gen = [0.080472] fr = [0.872988] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:48:18,302: Epoch 21 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [1.008313] gen = [0.076058] fr = [0.932255] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:48:44,966: Epoch 21 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [0.202587] gen = [0.066742] fr = [0.135846] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:48:54,621: Save checkpoint at epoch 21 ...\n2024-09-25 02:48:54,621: Current epoch 22, learning rate 0.0001\n2024-09-25 02:48:55,097: Epoch 22 / 24, batch 1 / 4333, 0.4743 sec/batch\n                         loss = [0.638868] gen = [0.080637] fr = [0.558231] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:49:21,489: Epoch 22 / 24, batch 100 / 4333, 0.2687 sec/batch\n                         loss = [0.520887] gen = [0.086290] fr = [0.434597] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:49:48,152: Epoch 22 / 24, batch 200 / 4333, 0.2676 sec/batch\n                         loss = [0.615289] gen = [0.082626] fr = [0.532663] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:50:14,822: Epoch 22 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [0.469104] gen = [0.076127] fr = [0.392977] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:50:41,470: Epoch 22 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [0.623506] gen = [0.067550] fr = [0.555956] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:51:08,099: Epoch 22 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [0.503811] gen = [0.082403] fr = [0.421409] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:51:34,737: Epoch 22 / 24, batch 600 / 4333, 0.2664 sec/batch\n                         loss = [0.654917] gen = [0.070255] fr = [0.584662] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:52:01,402: Epoch 22 / 24, batch 700 / 4333, 0.2665 sec/batch\n                         loss = [0.495014] gen = [0.072060] fr = [0.422954] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:52:28,056: Epoch 22 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [1.353935] gen = [0.089691] fr = [1.264245] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:52:54,716: Epoch 22 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [0.337838] gen = [0.085483] fr = [0.252355] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:53:21,379: Epoch 22 / 24, batch 1000 / 4333, 0.2666 sec/batch\n                         loss = [0.326951] gen = [0.069471] fr = [0.257481] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:53:48,039: Epoch 22 / 24, batch 1100 / 4333, 0.2666 sec/batch\n                         loss = [0.228241] gen = [0.069136] fr = [0.159104] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:54:14,694: Epoch 22 / 24, batch 1200 / 4333, 0.2666 sec/batch\n                         loss = [0.281847] gen = [0.088553] fr = [0.193294] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:54:41,354: Epoch 22 / 24, batch 1300 / 4333, 0.2666 sec/batch\n                         loss = [0.249429] gen = [0.072327] fr = [0.177102] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:55:08,019: Epoch 22 / 24, batch 1400 / 4333, 0.2666 sec/batch\n                         loss = [0.097617] gen = [0.073703] fr = [0.023915] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:55:34,682: Epoch 22 / 24, batch 1500 / 4333, 0.2666 sec/batch\n                         loss = [0.287419] gen = [0.077089] fr = [0.210330] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:56:01,340: Epoch 22 / 24, batch 1600 / 4333, 0.2666 sec/batch\n                         loss = [0.569749] gen = [0.077676] fr = [0.492073] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:56:28,008: Epoch 22 / 24, batch 1700 / 4333, 0.2666 sec/batch\n                         loss = [0.663295] gen = [0.071970] fr = [0.591325] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:56:54,672: Epoch 22 / 24, batch 1800 / 4333, 0.2666 sec/batch\n                         loss = [0.647674] gen = [0.074738] fr = [0.572936] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:57:21,331: Epoch 22 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.814779] gen = [0.075166] fr = [0.739613] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:57:47,985: Epoch 22 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [0.158492] gen = [0.084537] fr = [0.073955] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:58:14,617: Epoch 22 / 24, batch 2100 / 4333, 0.2663 sec/batch\n                         loss = [0.824116] gen = [0.081164] fr = [0.742953] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:58:41,255: Epoch 22 / 24, batch 2200 / 4333, 0.2664 sec/batch\n                         loss = [2.320232] gen = [0.072051] fr = [2.248181] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:59:07,864: Epoch 22 / 24, batch 2300 / 4333, 0.2663 sec/batch\n                         loss = [0.200756] gen = [0.072115] fr = [0.128641] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 02:59:34,490: Epoch 22 / 24, batch 2400 / 4333, 0.2663 sec/batch\n                         loss = [0.637401] gen = [0.076284] fr = [0.561117] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:00:01,114: Epoch 22 / 24, batch 2500 / 4333, 0.2663 sec/batch\n                         loss = [0.293166] gen = [0.079205] fr = [0.213961] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:00:27,795: Epoch 22 / 24, batch 2600 / 4333, 0.2668 sec/batch\n                         loss = [0.446711] gen = [0.076907] fr = [0.369803] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:00:54,450: Epoch 22 / 24, batch 2700 / 4333, 0.2667 sec/batch\n                         loss = [0.191583] gen = [0.075734] fr = [0.115849] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:01:21,093: Epoch 22 / 24, batch 2800 / 4333, 0.2666 sec/batch\n                         loss = [0.296996] gen = [0.072979] fr = [0.224017] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:01:47,757: Epoch 22 / 24, batch 2900 / 4333, 0.2666 sec/batch\n                         loss = [0.207530] gen = [0.076270] fr = [0.131260] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:02:14,401: Epoch 22 / 24, batch 3000 / 4333, 0.2666 sec/batch\n                         loss = [0.670662] gen = [0.073200] fr = [0.597462] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:02:41,023: Epoch 22 / 24, batch 3100 / 4333, 0.2662 sec/batch\n                         loss = [1.560670] gen = [0.081101] fr = [1.479568] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:03:07,642: Epoch 22 / 24, batch 3200 / 4333, 0.2662 sec/batch\n                         loss = [0.281411] gen = [0.075294] fr = [0.206117] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:03:34,266: Epoch 22 / 24, batch 3300 / 4333, 0.2662 sec/batch\n                         loss = [0.356289] gen = [0.071370] fr = [0.284919] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:04:00,890: Epoch 22 / 24, batch 3400 / 4333, 0.2662 sec/batch\n                         loss = [0.407278] gen = [0.076272] fr = [0.331006] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:04:27,518: Epoch 22 / 24, batch 3500 / 4333, 0.2662 sec/batch\n                         loss = [0.341173] gen = [0.073541] fr = [0.267632] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:04:54,144: Epoch 22 / 24, batch 3600 / 4333, 0.2663 sec/batch\n                         loss = [1.334831] gen = [0.081460] fr = [1.253372] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:05:20,770: Epoch 22 / 24, batch 3700 / 4333, 0.2663 sec/batch\n                         loss = [0.412193] gen = [0.083541] fr = [0.328652] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:05:47,369: Epoch 22 / 24, batch 3800 / 4333, 0.2662 sec/batch\n                         loss = [0.153616] gen = [0.071711] fr = [0.081905] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:06:13,988: Epoch 22 / 24, batch 3900 / 4333, 0.2662 sec/batch\n                         loss = [0.611859] gen = [0.074900] fr = [0.536959] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:06:40,618: Epoch 22 / 24, batch 4000 / 4333, 0.2662 sec/batch\n                         loss = [1.053609] gen = [0.066943] fr = [0.986666] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:07:07,274: Epoch 22 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [0.126097] gen = [0.072832] fr = [0.053265] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:07:33,926: Epoch 22 / 24, batch 4200 / 4333, 0.2665 sec/batch\n                         loss = [0.638139] gen = [0.073919] fr = [0.564221] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:08:00,579: Epoch 22 / 24, batch 4300 / 4333, 0.2665 sec/batch\n                         loss = [0.713941] gen = [0.074102] fr = [0.639839] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:08:10,258: Save checkpoint at epoch 22 ...\n2024-09-25 03:08:10,258: Current epoch 23, learning rate 1e-05\n2024-09-25 03:08:10,739: Epoch 23 / 24, batch 1 / 4333, 0.4799 sec/batch\n                         loss = [0.362209] gen = [0.070867] fr = [0.291342] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:08:37,142: Epoch 23 / 24, batch 100 / 4333, 0.2688 sec/batch\n                         loss = [0.421731] gen = [0.073083] fr = [0.348648] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:09:03,796: Epoch 23 / 24, batch 200 / 4333, 0.2677 sec/batch\n                         loss = [0.224723] gen = [0.071406] fr = [0.153316] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:09:30,444: Epoch 23 / 24, batch 300 / 4333, 0.2673 sec/batch\n                         loss = [0.102686] gen = [0.069605] fr = [0.033081] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:09:57,096: Epoch 23 / 24, batch 400 / 4333, 0.2671 sec/batch\n                         loss = [0.773808] gen = [0.072786] fr = [0.701022] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:10:23,748: Epoch 23 / 24, batch 500 / 4333, 0.2670 sec/batch\n                         loss = [0.431733] gen = [0.083691] fr = [0.348042] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:10:50,408: Epoch 23 / 24, batch 600 / 4333, 0.2666 sec/batch\n                         loss = [0.416193] gen = [0.077292] fr = [0.338902] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:11:17,055: Epoch 23 / 24, batch 700 / 4333, 0.2665 sec/batch\n                         loss = [2.332467] gen = [0.072859] fr = [2.259608] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 03:11:43,710: Epoch 23 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [0.259204] gen = [0.085130] fr = [0.174074] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:12:10,356: Epoch 23 / 24, batch 900 / 4333, 0.2665 sec/batch\n                         loss = [0.419878] gen = [0.073722] fr = [0.346156] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:12:37,013: Epoch 23 / 24, batch 1000 / 4333, 0.2665 sec/batch\n                         loss = [0.541119] gen = [0.068347] fr = [0.472772] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:13:03,643: Epoch 23 / 24, batch 1100 / 4333, 0.2663 sec/batch\n                         loss = [0.420788] gen = [0.082592] fr = [0.338196] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:13:30,272: Epoch 23 / 24, batch 1200 / 4333, 0.2663 sec/batch\n                         loss = [1.172014] gen = [0.072729] fr = [1.099284] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:13:56,895: Epoch 23 / 24, batch 1300 / 4333, 0.2663 sec/batch\n                         loss = [0.416767] gen = [0.080381] fr = [0.336385] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:14:23,529: Epoch 23 / 24, batch 1400 / 4333, 0.2663 sec/batch\n                         loss = [0.358738] gen = [0.069215] fr = [0.289523] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:14:50,165: Epoch 23 / 24, batch 1500 / 4333, 0.2663 sec/batch\n                         loss = [0.424762] gen = [0.079172] fr = [0.345590] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:15:16,800: Epoch 23 / 24, batch 1600 / 4333, 0.2663 sec/batch\n                         loss = [1.189010] gen = [0.076497] fr = [1.112513] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:15:43,450: Epoch 23 / 24, batch 1700 / 4333, 0.2664 sec/batch\n                         loss = [3.507331] gen = [0.079742] fr = [3.427589] spar = [0.000000] prec@1 = [93.750000] prec@5 = [100.000000] \n2024-09-25 03:16:10,085: Epoch 23 / 24, batch 1800 / 4333, 0.2664 sec/batch\n                         loss = [0.887214] gen = [0.077019] fr = [0.810195] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:16:36,724: Epoch 23 / 24, batch 1900 / 4333, 0.2664 sec/batch\n                         loss = [0.146566] gen = [0.074872] fr = [0.071694] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:17:03,367: Epoch 23 / 24, batch 2000 / 4333, 0.2664 sec/batch\n                         loss = [0.500753] gen = [0.077352] fr = [0.423400] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:17:30,014: Epoch 23 / 24, batch 2100 / 4333, 0.2665 sec/batch\n                         loss = [0.387497] gen = [0.072209] fr = [0.315288] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:17:56,665: Epoch 23 / 24, batch 2200 / 4333, 0.2665 sec/batch\n                         loss = [0.235993] gen = [0.077260] fr = [0.158732] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:18:23,293: Epoch 23 / 24, batch 2300 / 4333, 0.2664 sec/batch\n                         loss = [0.303201] gen = [0.068774] fr = [0.234427] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:18:49,922: Epoch 23 / 24, batch 2400 / 4333, 0.2664 sec/batch\n                         loss = [0.492338] gen = [0.076080] fr = [0.416258] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:19:16,554: Epoch 23 / 24, batch 2500 / 4333, 0.2664 sec/batch\n                         loss = [0.957494] gen = [0.069126] fr = [0.888368] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:19:43,193: Epoch 23 / 24, batch 2600 / 4333, 0.2664 sec/batch\n                         loss = [0.251289] gen = [0.071002] fr = [0.180287] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:20:09,835: Epoch 23 / 24, batch 2700 / 4333, 0.2664 sec/batch\n                         loss = [0.254294] gen = [0.071616] fr = [0.182678] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:20:36,473: Epoch 23 / 24, batch 2800 / 4333, 0.2664 sec/batch\n                         loss = [0.691905] gen = [0.073623] fr = [0.618282] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:21:03,087: Epoch 23 / 24, batch 2900 / 4333, 0.2663 sec/batch\n                         loss = [0.426314] gen = [0.069401] fr = [0.356913] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:21:29,709: Epoch 23 / 24, batch 3000 / 4333, 0.2663 sec/batch\n                         loss = [0.831933] gen = [0.070273] fr = [0.761660] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:21:56,333: Epoch 23 / 24, batch 3100 / 4333, 0.2662 sec/batch\n                         loss = [0.520853] gen = [0.073081] fr = [0.447772] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:22:22,971: Epoch 23 / 24, batch 3200 / 4333, 0.2663 sec/batch\n                         loss = [0.612332] gen = [0.073087] fr = [0.539245] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:22:49,619: Epoch 23 / 24, batch 3300 / 4333, 0.2664 sec/batch\n                         loss = [0.249370] gen = [0.069004] fr = [0.180366] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:23:16,254: Epoch 23 / 24, batch 3400 / 4333, 0.2664 sec/batch\n                         loss = [0.763616] gen = [0.076006] fr = [0.687610] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:23:42,882: Epoch 23 / 24, batch 3500 / 4333, 0.2663 sec/batch\n                         loss = [0.294973] gen = [0.069017] fr = [0.225957] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:24:09,502: Epoch 23 / 24, batch 3600 / 4333, 0.2662 sec/batch\n                         loss = [2.650550] gen = [0.081835] fr = [2.568716] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:24:36,134: Epoch 23 / 24, batch 3700 / 4333, 0.2663 sec/batch\n                         loss = [0.110131] gen = [0.076646] fr = [0.033486] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:25:02,766: Epoch 23 / 24, batch 3800 / 4333, 0.2663 sec/batch\n                         loss = [0.554240] gen = [0.071387] fr = [0.482853] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:25:29,392: Epoch 23 / 24, batch 3900 / 4333, 0.2663 sec/batch\n                         loss = [0.403775] gen = [0.066001] fr = [0.337774] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:25:56,018: Epoch 23 / 24, batch 4000 / 4333, 0.2663 sec/batch\n                         loss = [0.192570] gen = [0.068590] fr = [0.123980] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:26:22,675: Epoch 23 / 24, batch 4100 / 4333, 0.2666 sec/batch\n                         loss = [0.109583] gen = [0.071570] fr = [0.038013] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:26:49,322: Epoch 23 / 24, batch 4200 / 4333, 0.2665 sec/batch\n                         loss = [0.784401] gen = [0.075070] fr = [0.709330] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:27:15,947: Epoch 23 / 24, batch 4300 / 4333, 0.2664 sec/batch\n                         loss = [0.535342] gen = [0.074590] fr = [0.460751] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:27:25,587: Save checkpoint at epoch 23 ...\n2024-09-25 03:27:25,588: Current epoch 24, learning rate 1e-05\n2024-09-25 03:27:26,066: Epoch 24 / 24, batch 1 / 4333, 0.4772 sec/batch\n                         loss = [0.147544] gen = [0.081651] fr = [0.065892] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:27:52,430: Epoch 24 / 24, batch 100 / 4333, 0.2684 sec/batch\n                         loss = [0.424454] gen = [0.077749] fr = [0.346705] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:28:19,054: Epoch 24 / 24, batch 200 / 4333, 0.2673 sec/batch\n                         loss = [0.326593] gen = [0.069330] fr = [0.257263] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:28:45,666: Epoch 24 / 24, batch 300 / 4333, 0.2669 sec/batch\n                         loss = [0.312276] gen = [0.066243] fr = [0.246033] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:29:12,279: Epoch 24 / 24, batch 400 / 4333, 0.2667 sec/batch\n                         loss = [0.797381] gen = [0.069474] fr = [0.727907] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:29:38,920: Epoch 24 / 24, batch 500 / 4333, 0.2667 sec/batch\n                         loss = [0.360169] gen = [0.076322] fr = [0.283846] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:30:05,555: Epoch 24 / 24, batch 600 / 4333, 0.2663 sec/batch\n                         loss = [0.663765] gen = [0.089049] fr = [0.574716] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:30:32,189: Epoch 24 / 24, batch 700 / 4333, 0.2663 sec/batch\n                         loss = [0.271200] gen = [0.068349] fr = [0.202851] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:30:58,874: Epoch 24 / 24, batch 800 / 4333, 0.2665 sec/batch\n                         loss = [0.426804] gen = [0.077094] fr = [0.349709] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:31:25,549: Epoch 24 / 24, batch 900 / 4333, 0.2666 sec/batch\n                         loss = [0.209693] gen = [0.072521] fr = [0.137172] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:31:52,241: Epoch 24 / 24, batch 1000 / 4333, 0.2666 sec/batch\n                         loss = [0.201806] gen = [0.072259] fr = [0.129547] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:32:18,941: Epoch 24 / 24, batch 1100 / 4333, 0.2670 sec/batch\n                         loss = [0.274906] gen = [0.064423] fr = [0.210483] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:32:45,637: Epoch 24 / 24, batch 1200 / 4333, 0.2670 sec/batch\n                         loss = [0.121574] gen = [0.088052] fr = [0.033522] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:33:12,327: Epoch 24 / 24, batch 1300 / 4333, 0.2670 sec/batch\n                         loss = [1.542871] gen = [0.082213] fr = [1.460658] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:33:39,009: Epoch 24 / 24, batch 1400 / 4333, 0.2669 sec/batch\n                         loss = [0.165410] gen = [0.075847] fr = [0.089563] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:34:05,657: Epoch 24 / 24, batch 1500 / 4333, 0.2668 sec/batch\n                         loss = [0.359972] gen = [0.069135] fr = [0.290837] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:34:32,306: Epoch 24 / 24, batch 1600 / 4333, 0.2665 sec/batch\n                         loss = [0.194319] gen = [0.070583] fr = [0.123737] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:34:58,958: Epoch 24 / 24, batch 1700 / 4333, 0.2665 sec/batch\n                         loss = [0.549121] gen = [0.062941] fr = [0.486180] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:35:25,615: Epoch 24 / 24, batch 1800 / 4333, 0.2665 sec/batch\n                         loss = [0.330614] gen = [0.082217] fr = [0.248397] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:35:52,278: Epoch 24 / 24, batch 1900 / 4333, 0.2666 sec/batch\n                         loss = [0.592412] gen = [0.067843] fr = [0.524570] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:36:18,955: Epoch 24 / 24, batch 2000 / 4333, 0.2666 sec/batch\n                         loss = [0.288588] gen = [0.071152] fr = [0.217436] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:36:45,635: Epoch 24 / 24, batch 2100 / 4333, 0.2668 sec/batch\n                         loss = [0.550287] gen = [0.081447] fr = [0.468839] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:37:12,334: Epoch 24 / 24, batch 2200 / 4333, 0.2669 sec/batch\n                         loss = [0.383019] gen = [0.073626] fr = [0.309392] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:37:39,028: Epoch 24 / 24, batch 2300 / 4333, 0.2669 sec/batch\n                         loss = [0.882675] gen = [0.080749] fr = [0.801925] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:38:05,741: Epoch 24 / 24, batch 2400 / 4333, 0.2670 sec/batch\n                         loss = [0.287176] gen = [0.082269] fr = [0.204906] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:38:32,420: Epoch 24 / 24, batch 2500 / 4333, 0.2669 sec/batch\n                         loss = [0.711482] gen = [0.075245] fr = [0.636237] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:38:59,071: Epoch 24 / 24, batch 2600 / 4333, 0.2665 sec/batch\n                         loss = [0.915655] gen = [0.077171] fr = [0.838483] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:39:25,719: Epoch 24 / 24, batch 2700 / 4333, 0.2665 sec/batch\n                         loss = [0.313651] gen = [0.067750] fr = [0.245901] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:39:52,357: Epoch 24 / 24, batch 2800 / 4333, 0.2665 sec/batch\n                         loss = [0.479724] gen = [0.091163] fr = [0.388561] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:40:19,000: Epoch 24 / 24, batch 2900 / 4333, 0.2664 sec/batch\n                         loss = [1.399742] gen = [0.076102] fr = [1.323640] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:40:45,641: Epoch 24 / 24, batch 3000 / 4333, 0.2664 sec/batch\n                         loss = [0.552474] gen = [0.076126] fr = [0.476348] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:41:12,276: Epoch 24 / 24, batch 3100 / 4333, 0.2664 sec/batch\n                         loss = [0.154473] gen = [0.075771] fr = [0.078702] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:41:38,912: Epoch 24 / 24, batch 3200 / 4333, 0.2664 sec/batch\n                         loss = [0.094693] gen = [0.066893] fr = [0.027800] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:42:05,548: Epoch 24 / 24, batch 3300 / 4333, 0.2664 sec/batch\n                         loss = [0.300406] gen = [0.073255] fr = [0.227150] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:42:32,176: Epoch 24 / 24, batch 3400 / 4333, 0.2663 sec/batch\n                         loss = [0.265327] gen = [0.065052] fr = [0.200276] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:42:58,816: Epoch 24 / 24, batch 3500 / 4333, 0.2664 sec/batch\n                         loss = [0.327236] gen = [0.077531] fr = [0.249705] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:43:25,447: Epoch 24 / 24, batch 3600 / 4333, 0.2663 sec/batch\n                         loss = [0.227431] gen = [0.074587] fr = [0.152844] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:43:52,074: Epoch 24 / 24, batch 3700 / 4333, 0.2663 sec/batch\n                         loss = [0.099173] gen = [0.074346] fr = [0.024827] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:44:18,717: Epoch 24 / 24, batch 3800 / 4333, 0.2663 sec/batch\n                         loss = [0.657516] gen = [0.082750] fr = [0.574766] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:44:45,378: Epoch 24 / 24, batch 3900 / 4333, 0.2664 sec/batch\n                         loss = [2.237825] gen = [0.077235] fr = [2.160590] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:45:12,027: Epoch 24 / 24, batch 4000 / 4333, 0.2664 sec/batch\n                         loss = [0.171115] gen = [0.077294] fr = [0.093820] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:45:38,676: Epoch 24 / 24, batch 4100 / 4333, 0.2665 sec/batch\n                         loss = [0.915986] gen = [0.069417] fr = [0.846568] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:46:05,351: Epoch 24 / 24, batch 4200 / 4333, 0.2666 sec/batch\n                         loss = [0.724799] gen = [0.076741] fr = [0.648058] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:46:32,013: Epoch 24 / 24, batch 4300 / 4333, 0.2666 sec/batch\n                         loss = [0.424728] gen = [0.068903] fr = [0.355826] spar = [0.000000] prec@1 = [100.000000] prec@5 = [100.000000] \n2024-09-25 03:46:41,695: Save checkpoint at epoch 24 ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Face Matching","metadata":{}},{"cell_type":"markdown","source":"### Generate index file","metadata":{}},{"cell_type":"code","source":"import os\n\nDATA_ROOT = '/kaggle/input/vietnamese-celebrity-faces'\n\nINDEX_ROOT = '/kaggle/working/index_root'\nif not os.path.exists(INDEX_ROOT):\n    os.mkdir(INDEX_ROOT)\n    \nindex_path = os.path.join(INDEX_ROOT, 'vietnamese-celebrity-faces.index.txt')\nif os.path.exists(index_path):\n    os.remove(index_path)\n\nperson_id = 0\nwith open(index_path, 'w') as out_file:\n    for sub_name in os.listdir(DATA_ROOT):\n        dataset_path = os.path.join(DATA_ROOT, sub_name)\n        for person_name in os.listdir(dataset_path):\n            person_path = os.path.join(dataset_path, person_name)\n            for img_name in os.listdir(person_path):\n                out_file.write(\"{}\\t{}\\n\".format(os.path.join(sub_name, person_name, img_name), person_id))\n            person_id += 1","metadata":{"execution":{"iopub.status.busy":"2024-09-25T19:37:54.206433Z","iopub.execute_input":"2024-09-25T19:37:54.207270Z","iopub.status.idle":"2024-09-25T19:37:55.609611Z","shell.execute_reply.started":"2024-09-25T19:37:54.207227Z","shell.execute_reply":"2024-09-25T19:37:55.608646Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"%%writefile '/kaggle/working/recognition/tasks/minusface/train.yaml'\nSEED: 1337 # random seed for reproduce results\nDATA_ROOT: '/kaggle/input/vietnamese-celebrity-faces' # [fill in this blank] the parent directory where your train/val/test data are stored\nINDEX_ROOT: '/kaggle/working/index_root' # [fill in this blank] the parent directory for index\nDATASETS:\n  - name: 'vietnamese-celebrity-faces.index' # [fill in this blank] the name of your dataset\n    batch_size: 16\n    weight: 1.0\n    scale: 64\n    margin: 0.5\n\nBACKBONE_RESUME: \"\"\nHEAD_RESUME: \"\"\nMETA_RESUME: \"\"\n\nINPUT_SIZE: [ 112, 112 ]\nBACKBONE_NAME: 'IR_18' # support: ['IR_18', 'IR_50']\nEMBEDDING_SIZE: 512\n\nMODEL_ROOT: '/kaggle/working/model_root_s2' # the root to buffer your checkpoints\nLOG_ROOT: '/kaggle/working/log_root_s2' # the root to log your train/val status\n\nDIST_FC: true\nHEAD_NAME: \"ArcFace\" # support:  ['ArcFace', 'CurricularFace', 'CosFace']\nLOSS_NAME: 'DistCrossEntropy' # support: ['DistCrossEntropy', 'Softmax']\n\nRGB_MEAN: [ 0.5, 0.5, 0.5 ] # for normalize inputs to [-1, 1]\nRGB_STD: [ 0.5, 0.5, 0.5 ]\n\nLRS: [ 0.01, 0.001, 0.0001, 0.00001 ]\nWARMUP_STEP: -1\nSTAGES: [ 10, 18, 22 ]\n\nSTART_EPOCH: 0 # start epoch\nNUM_EPOCH: 24 # total epoch number\nSAVE_EPOCHS: [ 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24 ]\n\nWEIGHT_DECAY: 0.0005 # do not apply to batch_norm parameters\nMOMENTUM: 0.9\n\nWORLD_SIZE: 1\nRANK: 0\nLOCAL_RANK: 0\nDIST_BACKEND: 'nccl'\nDIST_URL: 'env://'\n\nNUM_WORKERS: 8\n\nAMP: false # fp16 for backbone\n\n# MinusFace\nMETHOD: MinusFace\nTASK: stage2 # toy, stage1, stage2\nNUM_DUPS: 3\nNUM_AUG: 3 # multiplier for data augmentation\nTASK_BACKBONE: 'IR_18' # IR_18, IR_50\nPRETRAIN_CKPT: '/kaggle/working/model_root/Backbone_Epoch_24_checkpoint.pth' # [fill in this blank] to train the recognition model requires pretrained MinusFace checkpoint\nTASK_VER: 3\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T18:34:42.745011Z","iopub.execute_input":"2024-09-26T18:34:42.745417Z","iopub.status.idle":"2024-09-26T18:34:42.753502Z","shell.execute_reply.started":"2024-09-26T18:34:42.745377Z","shell.execute_reply":"2024-09-26T18:34:42.752516Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/recognition/tasks/minusface/train.yaml\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train FR","metadata":{}},{"cell_type":"code","source":"!mkdir '/kaggle/working/model_root_s2'\n!mkdir '/kaggle/working/log_root_s2'","metadata":{"execution":{"iopub.status.busy":"2024-09-26T18:34:35.022533Z","iopub.execute_input":"2024-09-26T18:34:35.023008Z","iopub.status.idle":"2024-09-26T18:34:37.267382Z","shell.execute_reply.started":"2024-09-26T18:34:35.022964Z","shell.execute_reply":"2024-09-26T18:34:37.266123Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%cd '/kaggle/working/recognition/tasks/minusface'","metadata":{"execution":{"iopub.status.busy":"2024-09-27T19:29:09.372023Z","iopub.execute_input":"2024-09-27T19:29:09.372425Z","iopub.status.idle":"2024-09-27T19:29:09.380030Z","shell.execute_reply.started":"2024-09-27T19:29:09.372390Z","shell.execute_reply":"2024-09-27T19:29:09.379043Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/kaggle/working/recognition/tasks/minusface\n","output_type":"stream"}]},{"cell_type":"code","source":"!export CUDA_VISIBLE_DEVICES='0'\n!$PYTHON_BIN/python3 -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 train.py","metadata":{"execution":{"iopub.status.busy":"2024-09-26T18:34:58.868946Z","iopub.execute_input":"2024-09-26T18:34:58.869365Z","iopub.status.idle":"2024-09-26T20:41:01.759472Z","shell.execute_reply.started":"2024-09-26T18:34:58.869324Z","shell.execute_reply":"2024-09-26T20:41:01.758257Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  warnings.warn(\n2024-09-26 18:35:06,645: Dataset vietnamese-celebrity-faces.index, batch_size 16, weight 1.000000, scale 64, margin 0.500000\n2024-09-26 18:35:06,670: Added key: store_based_barrier_key:1 to store for rank: 0\n2024-09-26 18:35:06,670: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n2024-09-26 18:35:06,693: world_size: 1, rank: 0, local_rank: 0\nSEED 1337\nDATA_ROOT /kaggle/input/vietnamese-celebrity-faces\nINDEX_ROOT /kaggle/working/index_root\nDATASETS [{'name': 'vietnamese-celebrity-faces.index', 'batch_size': 16, 'weight': 1.0, 'scale': 64, 'margin': 0.5}]\nBACKBONE_RESUME \nHEAD_RESUME \nMETA_RESUME \nINPUT_SIZE [112, 112]\nBACKBONE_NAME IR_18\nEMBEDDING_SIZE 512\nMODEL_ROOT /kaggle/working/model_root_s2\nLOG_ROOT /kaggle/working/log_root_s2\nDIST_FC True\nHEAD_NAME ArcFace\nLOSS_NAME DistCrossEntropy\nRGB_MEAN [0.5, 0.5, 0.5]\nRGB_STD [0.5, 0.5, 0.5]\nLRS [0.01, 0.001, 0.0001, 1e-05]\nWARMUP_STEP -1\nSTAGES [10, 18, 22]\nSTART_EPOCH 0\nNUM_EPOCH 24\nSAVE_EPOCHS [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\nWEIGHT_DECAY 0.0005\nMOMENTUM 0.9\nWORLD_SIZE 1\nRANK 0\nLOCAL_RANK 0\nDIST_BACKEND nccl\nDIST_URL env://\nNUM_WORKERS 8\nAMP False\nMETHOD MinusFace\nTASK stage2\nNUM_DUPS 3\nNUM_AUG 3\nTASK_BACKBONE IR_18\nPRETRAIN_CKPT /kaggle/working/model_root/Backbone_Epoch_24_checkpoint.pth\nTASK_VER 3\n2024-09-26 18:35:06,729: Dataset vietnamese-celebrity-faces.index, class_num 224, sample_num 25671\n2024-09-26 18:35:06,729: Dataset vietnamese-celebrity-faces.index, total_size 25680, mine_size 25680, batch_num 1605\n2024-09-26 18:35:06,729: MultiDistributedSampler max_batch_num 1605\n/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n2024-09-26 18:35:06,730: Step_per_epoch = 1605\nRecognizer is IR_18\nLoad pretrain ckpt:  /kaggle/working/model_root/Backbone_Epoch_24_checkpoint.pth\n2024-09-26 18:35:09,573: Minus stage2 Backbone Generated\n2024-09-26 18:35:09,662: Split FC: [224]\n2024-09-26 18:35:09,663: FC Start Point: [0, 224]\n2024-09-26 18:35:09,914: Current epoch 1, learning rate 0.01\n2024-09-26 18:35:19,130: Epoch 1 / 24, batch 1 / 1605, 9.2141 sec/batch\n                         loss = [38.548775] gen = [0.000000] fr = [38.548775] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:35:38,533: Epoch 1 / 24, batch 100 / 1605, 0.2862 sec/batch\n                         loss = [41.245853] gen = [0.000000] fr = [41.245853] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:35:58,073: Epoch 1 / 24, batch 200 / 1605, 0.2408 sec/batch\n                         loss = [40.159565] gen = [0.000000] fr = [40.159565] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:36:17,600: Epoch 1 / 24, batch 300 / 1605, 0.2256 sec/batch\n                         loss = [38.742985] gen = [0.000000] fr = [38.742985] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:36:37,114: Epoch 1 / 24, batch 400 / 1605, 0.2180 sec/batch\n                         loss = [39.393227] gen = [0.000000] fr = [39.393227] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:36:56,638: Epoch 1 / 24, batch 500 / 1605, 0.2134 sec/batch\n                         loss = [38.784180] gen = [0.000000] fr = [38.784180] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:37:16,171: Epoch 1 / 24, batch 600 / 1605, 0.1953 sec/batch\n                         loss = [39.898163] gen = [0.000000] fr = [39.898163] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:37:35,767: Epoch 1 / 24, batch 700 / 1605, 0.1956 sec/batch\n                         loss = [38.671127] gen = [0.000000] fr = [38.671127] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:37:55,352: Epoch 1 / 24, batch 800 / 1605, 0.1957 sec/batch\n                         loss = [38.969646] gen = [0.000000] fr = [38.969646] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:38:14,881: Epoch 1 / 24, batch 900 / 1605, 0.1956 sec/batch\n                         loss = [38.524082] gen = [0.000000] fr = [38.524082] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:38:34,434: Epoch 1 / 24, batch 1000 / 1605, 0.1956 sec/batch\n                         loss = [38.520943] gen = [0.000000] fr = [38.520943] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:38:54,013: Epoch 1 / 24, batch 1100 / 1605, 0.1958 sec/batch\n                         loss = [37.336990] gen = [0.000000] fr = [37.336990] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:39:13,585: Epoch 1 / 24, batch 1200 / 1605, 0.1958 sec/batch\n                         loss = [37.982597] gen = [0.000000] fr = [37.982597] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:39:33,191: Epoch 1 / 24, batch 1300 / 1605, 0.1959 sec/batch\n                         loss = [36.664162] gen = [0.000000] fr = [36.664162] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:39:52,771: Epoch 1 / 24, batch 1400 / 1605, 0.1958 sec/batch\n                         loss = [37.349377] gen = [0.000000] fr = [37.349377] spar = [0.000000] prec@1 = [6.250000] prec@5 = [18.750000] \n2024-09-26 18:40:12,468: Epoch 1 / 24, batch 1500 / 1605, 0.1961 sec/batch\n                         loss = [37.741371] gen = [0.000000] fr = [37.741371] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 18:40:32,044: Epoch 1 / 24, batch 1600 / 1605, 0.1958 sec/batch\n                         loss = [37.144966] gen = [0.000000] fr = [37.144966] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:40:33,722: Save checkpoint at epoch 1 ...\n2024-09-26 18:40:33,722: Current epoch 2, learning rate 0.01\n2024-09-26 18:40:34,269: Epoch 2 / 24, batch 1 / 1605, 0.5448 sec/batch\n                         loss = [37.396835] gen = [0.000000] fr = [37.396835] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:40:53,688: Epoch 2 / 24, batch 100 / 1605, 0.1996 sec/batch\n                         loss = [37.743820] gen = [0.000000] fr = [37.743820] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:41:13,279: Epoch 2 / 24, batch 200 / 1605, 0.1978 sec/batch\n                         loss = [37.315224] gen = [0.000000] fr = [37.315224] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:41:32,823: Epoch 2 / 24, batch 300 / 1605, 0.1970 sec/batch\n                         loss = [37.207100] gen = [0.000000] fr = [37.207100] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:41:52,387: Epoch 2 / 24, batch 400 / 1605, 0.1967 sec/batch\n                         loss = [36.773788] gen = [0.000000] fr = [36.773788] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:42:11,972: Epoch 2 / 24, batch 500 / 1605, 0.1965 sec/batch\n                         loss = [36.094444] gen = [0.000000] fr = [36.094444] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:42:31,559: Epoch 2 / 24, batch 600 / 1605, 0.1959 sec/batch\n                         loss = [35.530426] gen = [0.000000] fr = [35.530426] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:42:51,183: Epoch 2 / 24, batch 700 / 1605, 0.1961 sec/batch\n                         loss = [34.899818] gen = [0.000000] fr = [34.899818] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:43:10,784: Epoch 2 / 24, batch 800 / 1605, 0.1960 sec/batch\n                         loss = [33.632145] gen = [0.000000] fr = [33.632145] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 18:43:30,366: Epoch 2 / 24, batch 900 / 1605, 0.1960 sec/batch\n                         loss = [31.787315] gen = [0.000000] fr = [31.787315] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:43:50,013: Epoch 2 / 24, batch 1000 / 1605, 0.1961 sec/batch\n                         loss = [30.041092] gen = [0.000000] fr = [30.041092] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:44:09,617: Epoch 2 / 24, batch 1100 / 1605, 0.1960 sec/batch\n                         loss = [26.957481] gen = [0.000000] fr = [26.957481] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:44:29,259: Epoch 2 / 24, batch 1200 / 1605, 0.1962 sec/batch\n                         loss = [21.841534] gen = [0.000000] fr = [21.841534] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:44:48,842: Epoch 2 / 24, batch 1300 / 1605, 0.1961 sec/batch\n                         loss = [18.227806] gen = [0.000000] fr = [18.227806] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:45:08,367: Epoch 2 / 24, batch 1400 / 1605, 0.1959 sec/batch\n                         loss = [20.798790] gen = [0.000000] fr = [20.798790] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:45:27,876: Epoch 2 / 24, batch 1500 / 1605, 0.1957 sec/batch\n                         loss = [21.024006] gen = [0.000000] fr = [21.024006] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:45:47,320: Epoch 2 / 24, batch 1600 / 1605, 0.1944 sec/batch\n                         loss = [21.874687] gen = [0.000000] fr = [21.874687] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:45:49,051: Save checkpoint at epoch 2 ...\n2024-09-26 18:45:49,051: Current epoch 3, learning rate 0.01\n2024-09-26 18:45:49,544: Epoch 3 / 24, batch 1 / 1605, 0.4903 sec/batch\n                         loss = [21.311167] gen = [0.000000] fr = [21.311167] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:46:08,856: Epoch 3 / 24, batch 100 / 1605, 0.1980 sec/batch\n                         loss = [20.968887] gen = [0.000000] fr = [20.968887] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:46:28,372: Epoch 3 / 24, batch 200 / 1605, 0.1966 sec/batch\n                         loss = [21.573967] gen = [0.000000] fr = [21.573967] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:46:47,862: Epoch 3 / 24, batch 300 / 1605, 0.1960 sec/batch\n                         loss = [20.761335] gen = [0.000000] fr = [20.761335] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:47:07,400: Epoch 3 / 24, batch 400 / 1605, 0.1959 sec/batch\n                         loss = [21.783424] gen = [0.000000] fr = [21.783424] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:47:26,924: Epoch 3 / 24, batch 500 / 1605, 0.1957 sec/batch\n                         loss = [20.786098] gen = [0.000000] fr = [20.786098] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:47:46,466: Epoch 3 / 24, batch 600 / 1605, 0.1954 sec/batch\n                         loss = [22.076633] gen = [0.000000] fr = [22.076633] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 18:48:05,970: Epoch 3 / 24, batch 700 / 1605, 0.1952 sec/batch\n                         loss = [22.140766] gen = [0.000000] fr = [22.140766] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:48:25,462: Epoch 3 / 24, batch 800 / 1605, 0.1951 sec/batch\n                         loss = [21.163429] gen = [0.000000] fr = [21.163429] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 18:48:44,948: Epoch 3 / 24, batch 900 / 1605, 0.1951 sec/batch\n                         loss = [22.567579] gen = [0.000000] fr = [22.567579] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:49:04,428: Epoch 3 / 24, batch 1000 / 1605, 0.1950 sec/batch\n                         loss = [20.377169] gen = [0.000000] fr = [20.377169] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:49:23,890: Epoch 3 / 24, batch 1100 / 1605, 0.1946 sec/batch\n                         loss = [21.673523] gen = [0.000000] fr = [21.673523] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:49:43,377: Epoch 3 / 24, batch 1200 / 1605, 0.1947 sec/batch\n                         loss = [20.079678] gen = [0.000000] fr = [20.079678] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:50:02,884: Epoch 3 / 24, batch 1300 / 1605, 0.1949 sec/batch\n                         loss = [21.474129] gen = [0.000000] fr = [21.474129] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:50:22,360: Epoch 3 / 24, batch 1400 / 1605, 0.1948 sec/batch\n                         loss = [20.634665] gen = [0.000000] fr = [20.634665] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:50:41,856: Epoch 3 / 24, batch 1500 / 1605, 0.1949 sec/batch\n                         loss = [20.452221] gen = [0.000000] fr = [20.452221] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:51:01,326: Epoch 3 / 24, batch 1600 / 1605, 0.1947 sec/batch\n                         loss = [20.415094] gen = [0.000000] fr = [20.415094] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:51:02,999: Save checkpoint at epoch 3 ...\n2024-09-26 18:51:02,999: Current epoch 4, learning rate 0.01\n2024-09-26 18:51:03,563: Epoch 4 / 24, batch 1 / 1605, 0.5623 sec/batch\n                         loss = [21.551449] gen = [0.000000] fr = [21.551449] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:51:22,843: Epoch 4 / 24, batch 100 / 1605, 0.1984 sec/batch\n                         loss = [20.582649] gen = [0.000000] fr = [20.582649] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:51:42,370: Epoch 4 / 24, batch 200 / 1605, 0.1968 sec/batch\n                         loss = [21.410240] gen = [0.000000] fr = [21.410240] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:52:01,874: Epoch 4 / 24, batch 300 / 1605, 0.1962 sec/batch\n                         loss = [20.378757] gen = [0.000000] fr = [20.378757] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:52:21,445: Epoch 4 / 24, batch 400 / 1605, 0.1961 sec/batch\n                         loss = [20.318525] gen = [0.000000] fr = [20.318525] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:52:41,019: Epoch 4 / 24, batch 500 / 1605, 0.1960 sec/batch\n                         loss = [20.516409] gen = [0.000000] fr = [20.516409] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:53:00,623: Epoch 4 / 24, batch 600 / 1605, 0.1960 sec/batch\n                         loss = [20.441967] gen = [0.000000] fr = [20.441967] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:53:20,210: Epoch 4 / 24, batch 700 / 1605, 0.1960 sec/batch\n                         loss = [20.209433] gen = [0.000000] fr = [20.209433] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:53:39,758: Epoch 4 / 24, batch 800 / 1605, 0.1958 sec/batch\n                         loss = [22.640930] gen = [0.000000] fr = [22.640930] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 18:53:59,289: Epoch 4 / 24, batch 900 / 1605, 0.1957 sec/batch\n                         loss = [20.711081] gen = [0.000000] fr = [20.711081] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:54:18,827: Epoch 4 / 24, batch 1000 / 1605, 0.1956 sec/batch\n                         loss = [20.356930] gen = [0.000000] fr = [20.356930] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:54:38,361: Epoch 4 / 24, batch 1100 / 1605, 0.1953 sec/batch\n                         loss = [20.202641] gen = [0.000000] fr = [20.202641] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 18:54:57,927: Epoch 4 / 24, batch 1200 / 1605, 0.1955 sec/batch\n                         loss = [20.537277] gen = [0.000000] fr = [20.537277] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:55:17,454: Epoch 4 / 24, batch 1300 / 1605, 0.1954 sec/batch\n                         loss = [20.503300] gen = [0.000000] fr = [20.503300] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 18:55:36,996: Epoch 4 / 24, batch 1400 / 1605, 0.1954 sec/batch\n                         loss = [20.813927] gen = [0.000000] fr = [20.813927] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:55:56,573: Epoch 4 / 24, batch 1500 / 1605, 0.1955 sec/batch\n                         loss = [20.411129] gen = [0.000000] fr = [20.411129] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:56:16,138: Epoch 4 / 24, batch 1600 / 1605, 0.1957 sec/batch\n                         loss = [21.328869] gen = [0.000000] fr = [21.328869] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 18:56:17,833: Save checkpoint at epoch 4 ...\n2024-09-26 18:56:17,833: Current epoch 5, learning rate 0.01\n2024-09-26 18:56:18,391: Epoch 5 / 24, batch 1 / 1605, 0.5557 sec/batch\n                         loss = [20.252554] gen = [0.000000] fr = [20.252554] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:56:37,822: Epoch 5 / 24, batch 100 / 1605, 0.1999 sec/batch\n                         loss = [20.443022] gen = [0.000000] fr = [20.443022] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:56:57,404: Epoch 5 / 24, batch 200 / 1605, 0.1978 sec/batch\n                         loss = [20.470686] gen = [0.000000] fr = [20.470686] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:57:17,001: Epoch 5 / 24, batch 300 / 1605, 0.1972 sec/batch\n                         loss = [20.439079] gen = [0.000000] fr = [20.439079] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:57:36,579: Epoch 5 / 24, batch 400 / 1605, 0.1969 sec/batch\n                         loss = [20.779985] gen = [0.000000] fr = [20.779985] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:57:56,126: Epoch 5 / 24, batch 500 / 1605, 0.1966 sec/batch\n                         loss = [20.320332] gen = [0.000000] fr = [20.320332] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:58:15,712: Epoch 5 / 24, batch 600 / 1605, 0.1959 sec/batch\n                         loss = [20.198397] gen = [0.000000] fr = [20.198397] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:58:35,269: Epoch 5 / 24, batch 700 / 1605, 0.1957 sec/batch\n                         loss = [20.293608] gen = [0.000000] fr = [20.293608] spar = [0.000000] prec@1 = [6.250000] prec@5 = [12.500000] \n2024-09-26 18:58:54,787: Epoch 5 / 24, batch 800 / 1605, 0.1955 sec/batch\n                         loss = [21.648487] gen = [0.000000] fr = [21.648487] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:59:14,343: Epoch 5 / 24, batch 900 / 1605, 0.1955 sec/batch\n                         loss = [20.163046] gen = [0.000000] fr = [20.163046] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:59:33,930: Epoch 5 / 24, batch 1000 / 1605, 0.1956 sec/batch\n                         loss = [20.444393] gen = [0.000000] fr = [20.444393] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 18:59:53,507: Epoch 5 / 24, batch 1100 / 1605, 0.1958 sec/batch\n                         loss = [20.237999] gen = [0.000000] fr = [20.237999] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:00:13,064: Epoch 5 / 24, batch 1200 / 1605, 0.1957 sec/batch\n                         loss = [21.011429] gen = [0.000000] fr = [21.011429] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:00:32,632: Epoch 5 / 24, batch 1300 / 1605, 0.1957 sec/batch\n                         loss = [21.381983] gen = [0.000000] fr = [21.381983] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:00:52,242: Epoch 5 / 24, batch 1400 / 1605, 0.1958 sec/batch\n                         loss = [20.523905] gen = [0.000000] fr = [20.523905] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:01:11,839: Epoch 5 / 24, batch 1500 / 1605, 0.1958 sec/batch\n                         loss = [20.783072] gen = [0.000000] fr = [20.783072] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:01:31,472: Epoch 5 / 24, batch 1600 / 1605, 0.1963 sec/batch\n                         loss = [20.377968] gen = [0.000000] fr = [20.377968] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:01:33,166: Save checkpoint at epoch 5 ...\n2024-09-26 19:01:33,166: Current epoch 6, learning rate 0.01\n2024-09-26 19:01:33,715: Epoch 6 / 24, batch 1 / 1605, 0.5470 sec/batch\n                         loss = [22.632353] gen = [0.000000] fr = [22.632353] spar = [0.000000] prec@1 = [6.250000] prec@5 = [18.750000] \n2024-09-26 19:01:53,175: Epoch 6 / 24, batch 100 / 1605, 0.2001 sec/batch\n                         loss = [21.595072] gen = [0.000000] fr = [21.595072] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:02:12,817: Epoch 6 / 24, batch 200 / 1605, 0.1982 sec/batch\n                         loss = [20.748257] gen = [0.000000] fr = [20.748257] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:02:32,458: Epoch 6 / 24, batch 300 / 1605, 0.1976 sec/batch\n                         loss = [20.402363] gen = [0.000000] fr = [20.402363] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:02:52,093: Epoch 6 / 24, batch 400 / 1605, 0.1973 sec/batch\n                         loss = [20.854141] gen = [0.000000] fr = [20.854141] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:03:11,708: Epoch 6 / 24, batch 500 / 1605, 0.1971 sec/batch\n                         loss = [20.562223] gen = [0.000000] fr = [20.562223] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:03:31,355: Epoch 6 / 24, batch 600 / 1605, 0.1965 sec/batch\n                         loss = [20.164415] gen = [0.000000] fr = [20.164415] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:03:50,982: Epoch 6 / 24, batch 700 / 1605, 0.1964 sec/batch\n                         loss = [20.218092] gen = [0.000000] fr = [20.218092] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:04:10,618: Epoch 6 / 24, batch 800 / 1605, 0.1964 sec/batch\n                         loss = [20.760403] gen = [0.000000] fr = [20.760403] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:04:30,258: Epoch 6 / 24, batch 900 / 1605, 0.1964 sec/batch\n                         loss = [20.250267] gen = [0.000000] fr = [20.250267] spar = [0.000000] prec@1 = [6.250000] prec@5 = [12.500000] \n2024-09-26 19:04:49,894: Epoch 6 / 24, batch 1000 / 1605, 0.1964 sec/batch\n                         loss = [20.215813] gen = [0.000000] fr = [20.215813] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:05:09,507: Epoch 6 / 24, batch 1100 / 1605, 0.1961 sec/batch\n                         loss = [20.258640] gen = [0.000000] fr = [20.258640] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:05:29,171: Epoch 6 / 24, batch 1200 / 1605, 0.1964 sec/batch\n                         loss = [21.242985] gen = [0.000000] fr = [21.242985] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:05:48,803: Epoch 6 / 24, batch 1300 / 1605, 0.1964 sec/batch\n                         loss = [21.012905] gen = [0.000000] fr = [21.012905] spar = [0.000000] prec@1 = [12.500000] prec@5 = [12.500000] \n2024-09-26 19:06:08,446: Epoch 6 / 24, batch 1400 / 1605, 0.1964 sec/batch\n                         loss = [21.299721] gen = [0.000000] fr = [21.299721] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:06:28,060: Epoch 6 / 24, batch 1500 / 1605, 0.1963 sec/batch\n                         loss = [20.111290] gen = [0.000000] fr = [20.111290] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:06:47,697: Epoch 6 / 24, batch 1600 / 1605, 0.1964 sec/batch\n                         loss = [20.777740] gen = [0.000000] fr = [20.777740] spar = [0.000000] prec@1 = [0.000000] prec@5 = [18.750000] \n2024-09-26 19:06:49,399: Save checkpoint at epoch 6 ...\n2024-09-26 19:06:49,400: Current epoch 7, learning rate 0.01\n2024-09-26 19:06:49,952: Epoch 7 / 24, batch 1 / 1605, 0.5508 sec/batch\n                         loss = [21.159676] gen = [0.000000] fr = [21.159676] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:07:09,394: Epoch 7 / 24, batch 100 / 1605, 0.1999 sec/batch\n                         loss = [21.862934] gen = [0.000000] fr = [21.862934] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:07:29,014: Epoch 7 / 24, batch 200 / 1605, 0.1981 sec/batch\n                         loss = [20.551252] gen = [0.000000] fr = [20.551252] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:07:48,628: Epoch 7 / 24, batch 300 / 1605, 0.1974 sec/batch\n                         loss = [20.418648] gen = [0.000000] fr = [20.418648] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:08:08,244: Epoch 7 / 24, batch 400 / 1605, 0.1971 sec/batch\n                         loss = [20.034931] gen = [0.000000] fr = [20.034931] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:08:27,806: Epoch 7 / 24, batch 500 / 1605, 0.1968 sec/batch\n                         loss = [20.212065] gen = [0.000000] fr = [20.212065] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:08:47,390: Epoch 7 / 24, batch 600 / 1605, 0.1958 sec/batch\n                         loss = [20.305180] gen = [0.000000] fr = [20.305180] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:09:06,947: Epoch 7 / 24, batch 700 / 1605, 0.1957 sec/batch\n                         loss = [20.294043] gen = [0.000000] fr = [20.294043] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:09:26,529: Epoch 7 / 24, batch 800 / 1605, 0.1957 sec/batch\n                         loss = [20.390327] gen = [0.000000] fr = [20.390327] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:09:46,144: Epoch 7 / 24, batch 900 / 1605, 0.1958 sec/batch\n                         loss = [20.355026] gen = [0.000000] fr = [20.355026] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:10:05,724: Epoch 7 / 24, batch 1000 / 1605, 0.1958 sec/batch\n                         loss = [20.115145] gen = [0.000000] fr = [20.115145] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:10:25,302: Epoch 7 / 24, batch 1100 / 1605, 0.1958 sec/batch\n                         loss = [20.202261] gen = [0.000000] fr = [20.202261] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:10:44,878: Epoch 7 / 24, batch 1200 / 1605, 0.1958 sec/batch\n                         loss = [20.154070] gen = [0.000000] fr = [20.154070] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:11:04,460: Epoch 7 / 24, batch 1300 / 1605, 0.1958 sec/batch\n                         loss = [20.527473] gen = [0.000000] fr = [20.527473] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:11:24,040: Epoch 7 / 24, batch 1400 / 1605, 0.1958 sec/batch\n                         loss = [20.054090] gen = [0.000000] fr = [20.054090] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:11:43,649: Epoch 7 / 24, batch 1500 / 1605, 0.1959 sec/batch\n                         loss = [20.293736] gen = [0.000000] fr = [20.293736] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:12:03,263: Epoch 7 / 24, batch 1600 / 1605, 0.1961 sec/batch\n                         loss = [20.409836] gen = [0.000000] fr = [20.409836] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:12:04,966: Save checkpoint at epoch 7 ...\n2024-09-26 19:12:04,966: Current epoch 8, learning rate 0.01\n2024-09-26 19:12:05,478: Epoch 8 / 24, batch 1 / 1605, 0.5098 sec/batch\n                         loss = [22.385681] gen = [0.000000] fr = [22.385681] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:12:24,936: Epoch 8 / 24, batch 100 / 1605, 0.1997 sec/batch\n                         loss = [20.340374] gen = [0.000000] fr = [20.340374] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:12:44,552: Epoch 8 / 24, batch 200 / 1605, 0.1979 sec/batch\n                         loss = [20.301676] gen = [0.000000] fr = [20.301676] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:13:04,167: Epoch 8 / 24, batch 300 / 1605, 0.1973 sec/batch\n                         loss = [20.199308] gen = [0.000000] fr = [20.199308] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:13:23,748: Epoch 8 / 24, batch 400 / 1605, 0.1969 sec/batch\n                         loss = [20.625854] gen = [0.000000] fr = [20.625854] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 19:13:43,340: Epoch 8 / 24, batch 500 / 1605, 0.1967 sec/batch\n                         loss = [21.035530] gen = [0.000000] fr = [21.035530] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:14:02,929: Epoch 8 / 24, batch 600 / 1605, 0.1959 sec/batch\n                         loss = [20.479733] gen = [0.000000] fr = [20.479733] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:14:22,544: Epoch 8 / 24, batch 700 / 1605, 0.1960 sec/batch\n                         loss = [20.449495] gen = [0.000000] fr = [20.449495] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:14:42,159: Epoch 8 / 24, batch 800 / 1605, 0.1961 sec/batch\n                         loss = [20.467302] gen = [0.000000] fr = [20.467302] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:15:01,791: Epoch 8 / 24, batch 900 / 1605, 0.1961 sec/batch\n                         loss = [20.750313] gen = [0.000000] fr = [20.750313] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:15:21,428: Epoch 8 / 24, batch 1000 / 1605, 0.1962 sec/batch\n                         loss = [20.084114] gen = [0.000000] fr = [20.084114] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:15:41,027: Epoch 8 / 24, batch 1100 / 1605, 0.1960 sec/batch\n                         loss = [20.175716] gen = [0.000000] fr = [20.175716] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:16:00,622: Epoch 8 / 24, batch 1200 / 1605, 0.1960 sec/batch\n                         loss = [20.231754] gen = [0.000000] fr = [20.231754] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:16:20,229: Epoch 8 / 24, batch 1300 / 1605, 0.1960 sec/batch\n                         loss = [20.184950] gen = [0.000000] fr = [20.184950] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:16:39,840: Epoch 8 / 24, batch 1400 / 1605, 0.1960 sec/batch\n                         loss = [20.718216] gen = [0.000000] fr = [20.718216] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:16:59,428: Epoch 8 / 24, batch 1500 / 1605, 0.1960 sec/batch\n                         loss = [20.505980] gen = [0.000000] fr = [20.505980] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:17:19,025: Epoch 8 / 24, batch 1600 / 1605, 0.1960 sec/batch\n                         loss = [19.131050] gen = [0.000000] fr = [19.131050] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:17:20,722: Save checkpoint at epoch 8 ...\n2024-09-26 19:17:20,722: Current epoch 9, learning rate 0.01\n2024-09-26 19:17:21,296: Epoch 9 / 24, batch 1 / 1605, 0.5717 sec/batch\n                         loss = [20.525726] gen = [0.000000] fr = [20.525726] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:17:40,715: Epoch 9 / 24, batch 100 / 1605, 0.1999 sec/batch\n                         loss = [19.987095] gen = [0.000000] fr = [19.987095] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:18:00,325: Epoch 9 / 24, batch 200 / 1605, 0.1980 sec/batch\n                         loss = [23.068684] gen = [0.000000] fr = [23.068684] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:18:19,955: Epoch 9 / 24, batch 300 / 1605, 0.1974 sec/batch\n                         loss = [21.235191] gen = [0.000000] fr = [21.235191] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:18:39,536: Epoch 9 / 24, batch 400 / 1605, 0.1970 sec/batch\n                         loss = [19.568485] gen = [0.000000] fr = [19.568485] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:18:59,144: Epoch 9 / 24, batch 500 / 1605, 0.1968 sec/batch\n                         loss = [19.872540] gen = [0.000000] fr = [19.872540] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:19:18,740: Epoch 9 / 24, batch 600 / 1605, 0.1960 sec/batch\n                         loss = [21.340523] gen = [0.000000] fr = [21.340523] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:19:38,323: Epoch 9 / 24, batch 700 / 1605, 0.1959 sec/batch\n                         loss = [20.643299] gen = [0.000000] fr = [20.643299] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:19:57,943: Epoch 9 / 24, batch 800 / 1605, 0.1960 sec/batch\n                         loss = [19.946733] gen = [0.000000] fr = [19.946733] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:20:17,512: Epoch 9 / 24, batch 900 / 1605, 0.1959 sec/batch\n                         loss = [20.115414] gen = [0.000000] fr = [20.115414] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:20:37,120: Epoch 9 / 24, batch 1000 / 1605, 0.1960 sec/batch\n                         loss = [20.703728] gen = [0.000000] fr = [20.703728] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:20:56,726: Epoch 9 / 24, batch 1100 / 1605, 0.1961 sec/batch\n                         loss = [19.889721] gen = [0.000000] fr = [19.889721] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:21:16,318: Epoch 9 / 24, batch 1200 / 1605, 0.1960 sec/batch\n                         loss = [20.120342] gen = [0.000000] fr = [20.120342] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:21:35,917: Epoch 9 / 24, batch 1300 / 1605, 0.1960 sec/batch\n                         loss = [20.418364] gen = [0.000000] fr = [20.418364] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:21:55,534: Epoch 9 / 24, batch 1400 / 1605, 0.1960 sec/batch\n                         loss = [20.073343] gen = [0.000000] fr = [20.073343] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:22:15,154: Epoch 9 / 24, batch 1500 / 1605, 0.1961 sec/batch\n                         loss = [20.228235] gen = [0.000000] fr = [20.228235] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:22:34,756: Epoch 9 / 24, batch 1600 / 1605, 0.1960 sec/batch\n                         loss = [20.858639] gen = [0.000000] fr = [20.858639] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:22:36,459: Save checkpoint at epoch 9 ...\n2024-09-26 19:22:36,460: Current epoch 10, learning rate 0.01\n2024-09-26 19:22:37,051: Epoch 10 / 24, batch 1 / 1605, 0.5894 sec/batch\n                         loss = [20.295094] gen = [0.000000] fr = [20.295094] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:22:56,512: Epoch 10 / 24, batch 100 / 1605, 0.2005 sec/batch\n                         loss = [20.060648] gen = [0.000000] fr = [20.060648] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:23:16,142: Epoch 10 / 24, batch 200 / 1605, 0.1984 sec/batch\n                         loss = [20.728292] gen = [0.000000] fr = [20.728292] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:23:35,759: Epoch 10 / 24, batch 300 / 1605, 0.1977 sec/batch\n                         loss = [20.203283] gen = [0.000000] fr = [20.203283] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:23:55,378: Epoch 10 / 24, batch 400 / 1605, 0.1973 sec/batch\n                         loss = [20.085426] gen = [0.000000] fr = [20.085426] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:24:14,969: Epoch 10 / 24, batch 500 / 1605, 0.1970 sec/batch\n                         loss = [20.152676] gen = [0.000000] fr = [20.152676] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:24:34,617: Epoch 10 / 24, batch 600 / 1605, 0.1965 sec/batch\n                         loss = [21.210054] gen = [0.000000] fr = [21.210054] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:24:54,245: Epoch 10 / 24, batch 700 / 1605, 0.1964 sec/batch\n                         loss = [20.635653] gen = [0.000000] fr = [20.635653] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:25:13,881: Epoch 10 / 24, batch 800 / 1605, 0.1964 sec/batch\n                         loss = [19.915554] gen = [0.000000] fr = [19.915554] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:25:33,511: Epoch 10 / 24, batch 900 / 1605, 0.1964 sec/batch\n                         loss = [20.350502] gen = [0.000000] fr = [20.350502] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:25:53,136: Epoch 10 / 24, batch 1000 / 1605, 0.1963 sec/batch\n                         loss = [21.048124] gen = [0.000000] fr = [21.048124] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:26:12,688: Epoch 10 / 24, batch 1100 / 1605, 0.1955 sec/batch\n                         loss = [20.473330] gen = [0.000000] fr = [20.473330] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:26:32,232: Epoch 10 / 24, batch 1200 / 1605, 0.1955 sec/batch\n                         loss = [20.137217] gen = [0.000000] fr = [20.137217] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:26:51,802: Epoch 10 / 24, batch 1300 / 1605, 0.1956 sec/batch\n                         loss = [20.918816] gen = [0.000000] fr = [20.918816] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:27:11,351: Epoch 10 / 24, batch 1400 / 1605, 0.1955 sec/batch\n                         loss = [19.980129] gen = [0.000000] fr = [19.980129] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:27:30,913: Epoch 10 / 24, batch 1500 / 1605, 0.1956 sec/batch\n                         loss = [20.076195] gen = [0.000000] fr = [20.076195] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 19:27:50,459: Epoch 10 / 24, batch 1600 / 1605, 0.1955 sec/batch\n                         loss = [20.100670] gen = [0.000000] fr = [20.100670] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:27:52,159: Save checkpoint at epoch 10 ...\n2024-09-26 19:27:52,159: Current epoch 11, learning rate 0.001\n2024-09-26 19:27:52,733: Epoch 11 / 24, batch 1 / 1605, 0.5715 sec/batch\n                         loss = [20.530800] gen = [0.000000] fr = [20.530800] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:28:12,102: Epoch 11 / 24, batch 100 / 1605, 0.1994 sec/batch\n                         loss = [20.437008] gen = [0.000000] fr = [20.437008] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:28:31,663: Epoch 11 / 24, batch 200 / 1605, 0.1975 sec/batch\n                         loss = [20.053337] gen = [0.000000] fr = [20.053337] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:28:51,218: Epoch 11 / 24, batch 300 / 1605, 0.1969 sec/batch\n                         loss = [21.084190] gen = [0.000000] fr = [21.084190] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:29:10,764: Epoch 11 / 24, batch 400 / 1605, 0.1965 sec/batch\n                         loss = [20.164589] gen = [0.000000] fr = [20.164589] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:29:30,343: Epoch 11 / 24, batch 500 / 1605, 0.1964 sec/batch\n                         loss = [20.254955] gen = [0.000000] fr = [20.254955] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:29:49,899: Epoch 11 / 24, batch 600 / 1605, 0.1956 sec/batch\n                         loss = [20.586056] gen = [0.000000] fr = [20.586056] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:30:09,488: Epoch 11 / 24, batch 700 / 1605, 0.1957 sec/batch\n                         loss = [20.054028] gen = [0.000000] fr = [20.054028] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:30:29,080: Epoch 11 / 24, batch 800 / 1605, 0.1958 sec/batch\n                         loss = [20.929405] gen = [0.000000] fr = [20.929405] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:30:48,671: Epoch 11 / 24, batch 900 / 1605, 0.1958 sec/batch\n                         loss = [20.073936] gen = [0.000000] fr = [20.073936] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:31:08,260: Epoch 11 / 24, batch 1000 / 1605, 0.1958 sec/batch\n                         loss = [20.117805] gen = [0.000000] fr = [20.117805] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:31:27,848: Epoch 11 / 24, batch 1100 / 1605, 0.1959 sec/batch\n                         loss = [19.956085] gen = [0.000000] fr = [19.956085] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:31:47,428: Epoch 11 / 24, batch 1200 / 1605, 0.1958 sec/batch\n                         loss = [19.519188] gen = [0.000000] fr = [19.519188] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:32:07,003: Epoch 11 / 24, batch 1300 / 1605, 0.1958 sec/batch\n                         loss = [19.327530] gen = [0.000000] fr = [19.327530] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:32:26,604: Epoch 11 / 24, batch 1400 / 1605, 0.1959 sec/batch\n                         loss = [20.546724] gen = [0.000000] fr = [20.546724] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:32:46,224: Epoch 11 / 24, batch 1500 / 1605, 0.1959 sec/batch\n                         loss = [19.676483] gen = [0.000000] fr = [19.676483] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:33:05,833: Epoch 11 / 24, batch 1600 / 1605, 0.1961 sec/batch\n                         loss = [19.952099] gen = [0.000000] fr = [19.952099] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:33:07,553: Save checkpoint at epoch 11 ...\n2024-09-26 19:33:07,553: Current epoch 12, learning rate 0.001\n2024-09-26 19:33:08,068: Epoch 12 / 24, batch 1 / 1605, 0.5128 sec/batch\n                         loss = [20.151634] gen = [0.000000] fr = [20.151634] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:33:27,492: Epoch 12 / 24, batch 100 / 1605, 0.1994 sec/batch\n                         loss = [19.681778] gen = [0.000000] fr = [19.681778] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:33:47,137: Epoch 12 / 24, batch 200 / 1605, 0.1979 sec/batch\n                         loss = [19.743526] gen = [0.000000] fr = [19.743526] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:34:06,732: Epoch 12 / 24, batch 300 / 1605, 0.1973 sec/batch\n                         loss = [20.003294] gen = [0.000000] fr = [20.003294] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:34:26,332: Epoch 12 / 24, batch 400 / 1605, 0.1969 sec/batch\n                         loss = [20.006859] gen = [0.000000] fr = [20.006859] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:34:45,907: Epoch 12 / 24, batch 500 / 1605, 0.1967 sec/batch\n                         loss = [19.561890] gen = [0.000000] fr = [19.561890] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 19:35:05,490: Epoch 12 / 24, batch 600 / 1605, 0.1958 sec/batch\n                         loss = [19.650936] gen = [0.000000] fr = [19.650936] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:35:25,076: Epoch 12 / 24, batch 700 / 1605, 0.1958 sec/batch\n                         loss = [19.671318] gen = [0.000000] fr = [19.671318] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:35:44,662: Epoch 12 / 24, batch 800 / 1605, 0.1958 sec/batch\n                         loss = [19.897078] gen = [0.000000] fr = [19.897078] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:36:04,252: Epoch 12 / 24, batch 900 / 1605, 0.1959 sec/batch\n                         loss = [19.775650] gen = [0.000000] fr = [19.775650] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:36:23,823: Epoch 12 / 24, batch 1000 / 1605, 0.1958 sec/batch\n                         loss = [19.802099] gen = [0.000000] fr = [19.802099] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:36:43,395: Epoch 12 / 24, batch 1100 / 1605, 0.1957 sec/batch\n                         loss = [19.743326] gen = [0.000000] fr = [19.743326] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:37:03,006: Epoch 12 / 24, batch 1200 / 1605, 0.1959 sec/batch\n                         loss = [20.469675] gen = [0.000000] fr = [20.469675] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:37:22,592: Epoch 12 / 24, batch 1300 / 1605, 0.1959 sec/batch\n                         loss = [19.651863] gen = [0.000000] fr = [19.651863] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:37:42,159: Epoch 12 / 24, batch 1400 / 1605, 0.1958 sec/batch\n                         loss = [20.315966] gen = [0.000000] fr = [20.315966] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:38:01,724: Epoch 12 / 24, batch 1500 / 1605, 0.1958 sec/batch\n                         loss = [20.051201] gen = [0.000000] fr = [20.051201] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:38:21,297: Epoch 12 / 24, batch 1600 / 1605, 0.1957 sec/batch\n                         loss = [20.397720] gen = [0.000000] fr = [20.397720] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:38:23,035: Save checkpoint at epoch 12 ...\n2024-09-26 19:38:23,035: Current epoch 13, learning rate 0.001\n2024-09-26 19:38:23,597: Epoch 13 / 24, batch 1 / 1605, 0.5598 sec/batch\n                         loss = [20.015087] gen = [0.000000] fr = [20.015087] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:38:43,000: Epoch 13 / 24, batch 100 / 1605, 0.1996 sec/batch\n                         loss = [20.310001] gen = [0.000000] fr = [20.310001] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:39:02,588: Epoch 13 / 24, batch 200 / 1605, 0.1978 sec/batch\n                         loss = [20.072571] gen = [0.000000] fr = [20.072571] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:39:22,164: Epoch 13 / 24, batch 300 / 1605, 0.1971 sec/batch\n                         loss = [20.024452] gen = [0.000000] fr = [20.024452] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:39:41,750: Epoch 13 / 24, batch 400 / 1605, 0.1968 sec/batch\n                         loss = [20.031773] gen = [0.000000] fr = [20.031773] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:40:01,309: Epoch 13 / 24, batch 500 / 1605, 0.1965 sec/batch\n                         loss = [19.948515] gen = [0.000000] fr = [19.948515] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:40:20,871: Epoch 13 / 24, batch 600 / 1605, 0.1956 sec/batch\n                         loss = [19.849031] gen = [0.000000] fr = [19.849031] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:40:40,490: Epoch 13 / 24, batch 700 / 1605, 0.1959 sec/batch\n                         loss = [20.052193] gen = [0.000000] fr = [20.052193] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:41:00,059: Epoch 13 / 24, batch 800 / 1605, 0.1958 sec/batch\n                         loss = [19.991514] gen = [0.000000] fr = [19.991514] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:41:19,651: Epoch 13 / 24, batch 900 / 1605, 0.1959 sec/batch\n                         loss = [20.305843] gen = [0.000000] fr = [20.305843] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:41:39,255: Epoch 13 / 24, batch 1000 / 1605, 0.1959 sec/batch\n                         loss = [20.305099] gen = [0.000000] fr = [20.305099] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:41:58,823: Epoch 13 / 24, batch 1100 / 1605, 0.1957 sec/batch\n                         loss = [20.277758] gen = [0.000000] fr = [20.277758] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:42:18,420: Epoch 13 / 24, batch 1200 / 1605, 0.1958 sec/batch\n                         loss = [19.992397] gen = [0.000000] fr = [19.992397] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:42:37,996: Epoch 13 / 24, batch 1300 / 1605, 0.1958 sec/batch\n                         loss = [20.221014] gen = [0.000000] fr = [20.221014] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:42:57,557: Epoch 13 / 24, batch 1400 / 1605, 0.1958 sec/batch\n                         loss = [20.053410] gen = [0.000000] fr = [20.053410] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:43:17,108: Epoch 13 / 24, batch 1500 / 1605, 0.1957 sec/batch\n                         loss = [19.796402] gen = [0.000000] fr = [19.796402] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:43:36,624: Epoch 13 / 24, batch 1600 / 1605, 0.1952 sec/batch\n                         loss = [19.699429] gen = [0.000000] fr = [19.699429] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:43:38,305: Save checkpoint at epoch 13 ...\n2024-09-26 19:43:38,306: Current epoch 14, learning rate 0.001\n2024-09-26 19:43:38,870: Epoch 14 / 24, batch 1 / 1605, 0.5625 sec/batch\n                         loss = [20.155972] gen = [0.000000] fr = [20.155972] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:43:58,211: Epoch 14 / 24, batch 100 / 1605, 0.1990 sec/batch\n                         loss = [20.353485] gen = [0.000000] fr = [20.353485] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:44:17,739: Epoch 14 / 24, batch 200 / 1605, 0.1972 sec/batch\n                         loss = [20.080944] gen = [0.000000] fr = [20.080944] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:44:37,288: Epoch 14 / 24, batch 300 / 1605, 0.1966 sec/batch\n                         loss = [20.071213] gen = [0.000000] fr = [20.071213] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:44:56,837: Epoch 14 / 24, batch 400 / 1605, 0.1963 sec/batch\n                         loss = [21.268181] gen = [0.000000] fr = [21.268181] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:45:16,379: Epoch 14 / 24, batch 500 / 1605, 0.1961 sec/batch\n                         loss = [19.989910] gen = [0.000000] fr = [19.989910] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:45:35,907: Epoch 14 / 24, batch 600 / 1605, 0.1953 sec/batch\n                         loss = [20.319002] gen = [0.000000] fr = [20.319002] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:45:55,448: Epoch 14 / 24, batch 700 / 1605, 0.1953 sec/batch\n                         loss = [19.968994] gen = [0.000000] fr = [19.968994] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:46:14,991: Epoch 14 / 24, batch 800 / 1605, 0.1954 sec/batch\n                         loss = [20.052483] gen = [0.000000] fr = [20.052483] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:46:34,482: Epoch 14 / 24, batch 900 / 1605, 0.1953 sec/batch\n                         loss = [20.025028] gen = [0.000000] fr = [20.025028] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:46:53,979: Epoch 14 / 24, batch 1000 / 1605, 0.1952 sec/batch\n                         loss = [20.039391] gen = [0.000000] fr = [20.039391] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:47:13,471: Epoch 14 / 24, batch 1100 / 1605, 0.1949 sec/batch\n                         loss = [20.328873] gen = [0.000000] fr = [20.328873] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:47:33,028: Epoch 14 / 24, batch 1200 / 1605, 0.1952 sec/batch\n                         loss = [20.122274] gen = [0.000000] fr = [20.122274] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:47:52,572: Epoch 14 / 24, batch 1300 / 1605, 0.1953 sec/batch\n                         loss = [20.281990] gen = [0.000000] fr = [20.281990] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:48:12,104: Epoch 14 / 24, batch 1400 / 1605, 0.1953 sec/batch\n                         loss = [20.049574] gen = [0.000000] fr = [20.049574] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:48:31,645: Epoch 14 / 24, batch 1500 / 1605, 0.1953 sec/batch\n                         loss = [20.148136] gen = [0.000000] fr = [20.148136] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:48:51,132: Epoch 14 / 24, batch 1600 / 1605, 0.1949 sec/batch\n                         loss = [20.603960] gen = [0.000000] fr = [20.603960] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:48:52,835: Save checkpoint at epoch 14 ...\n2024-09-26 19:48:52,835: Current epoch 15, learning rate 0.001\n2024-09-26 19:48:53,351: Epoch 15 / 24, batch 1 / 1605, 0.5142 sec/batch\n                         loss = [20.040051] gen = [0.000000] fr = [20.040051] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:49:12,665: Epoch 15 / 24, batch 100 / 1605, 0.1983 sec/batch\n                         loss = [20.060163] gen = [0.000000] fr = [20.060163] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:49:32,197: Epoch 15 / 24, batch 200 / 1605, 0.1968 sec/batch\n                         loss = [21.247009] gen = [0.000000] fr = [21.247009] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:49:51,686: Epoch 15 / 24, batch 300 / 1605, 0.1962 sec/batch\n                         loss = [20.387899] gen = [0.000000] fr = [20.387899] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:50:11,203: Epoch 15 / 24, batch 400 / 1605, 0.1959 sec/batch\n                         loss = [20.354786] gen = [0.000000] fr = [20.354786] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:50:30,685: Epoch 15 / 24, batch 500 / 1605, 0.1957 sec/batch\n                         loss = [20.302860] gen = [0.000000] fr = [20.302860] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:50:50,195: Epoch 15 / 24, batch 600 / 1605, 0.1951 sec/batch\n                         loss = [20.163883] gen = [0.000000] fr = [20.163883] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:51:09,696: Epoch 15 / 24, batch 700 / 1605, 0.1951 sec/batch\n                         loss = [19.999336] gen = [0.000000] fr = [19.999336] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:51:29,157: Epoch 15 / 24, batch 800 / 1605, 0.1949 sec/batch\n                         loss = [20.281908] gen = [0.000000] fr = [20.281908] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:51:48,648: Epoch 15 / 24, batch 900 / 1605, 0.1949 sec/batch\n                         loss = [20.619879] gen = [0.000000] fr = [20.619879] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:52:08,105: Epoch 15 / 24, batch 1000 / 1605, 0.1948 sec/batch\n                         loss = [19.748854] gen = [0.000000] fr = [19.748854] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:52:27,594: Epoch 15 / 24, batch 1100 / 1605, 0.1949 sec/batch\n                         loss = [20.549564] gen = [0.000000] fr = [20.549564] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:52:47,090: Epoch 15 / 24, batch 1200 / 1605, 0.1949 sec/batch\n                         loss = [20.032028] gen = [0.000000] fr = [20.032028] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:53:06,566: Epoch 15 / 24, batch 1300 / 1605, 0.1949 sec/batch\n                         loss = [20.803202] gen = [0.000000] fr = [20.803202] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:53:26,043: Epoch 15 / 24, batch 1400 / 1605, 0.1948 sec/batch\n                         loss = [20.281775] gen = [0.000000] fr = [20.281775] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:53:45,539: Epoch 15 / 24, batch 1500 / 1605, 0.1949 sec/batch\n                         loss = [20.382832] gen = [0.000000] fr = [20.382832] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:54:04,985: Epoch 15 / 24, batch 1600 / 1605, 0.1945 sec/batch\n                         loss = [19.821640] gen = [0.000000] fr = [19.821640] spar = [0.000000] prec@1 = [0.000000] prec@5 = [18.750000] \n2024-09-26 19:54:06,628: Save checkpoint at epoch 15 ...\n2024-09-26 19:54:06,628: Current epoch 16, learning rate 0.001\n2024-09-26 19:54:07,177: Epoch 16 / 24, batch 1 / 1605, 0.5464 sec/batch\n                         loss = [19.808697] gen = [0.000000] fr = [19.808697] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:54:26,432: Epoch 16 / 24, batch 100 / 1605, 0.1980 sec/batch\n                         loss = [20.275187] gen = [0.000000] fr = [20.275187] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:54:45,909: Epoch 16 / 24, batch 200 / 1605, 0.1964 sec/batch\n                         loss = [20.280331] gen = [0.000000] fr = [20.280331] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:55:05,354: Epoch 16 / 24, batch 300 / 1605, 0.1957 sec/batch\n                         loss = [19.795677] gen = [0.000000] fr = [19.795677] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:55:24,757: Epoch 16 / 24, batch 400 / 1605, 0.1953 sec/batch\n                         loss = [20.042152] gen = [0.000000] fr = [20.042152] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:55:44,137: Epoch 16 / 24, batch 500 / 1605, 0.1950 sec/batch\n                         loss = [20.311878] gen = [0.000000] fr = [20.311878] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:56:03,553: Epoch 16 / 24, batch 600 / 1605, 0.1942 sec/batch\n                         loss = [20.950645] gen = [0.000000] fr = [20.950645] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:56:22,960: Epoch 16 / 24, batch 700 / 1605, 0.1941 sec/batch\n                         loss = [20.301054] gen = [0.000000] fr = [20.301054] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:56:42,411: Epoch 16 / 24, batch 800 / 1605, 0.1942 sec/batch\n                         loss = [20.282906] gen = [0.000000] fr = [20.282906] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:57:01,897: Epoch 16 / 24, batch 900 / 1605, 0.1944 sec/batch\n                         loss = [20.318262] gen = [0.000000] fr = [20.318262] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:57:21,384: Epoch 16 / 24, batch 1000 / 1605, 0.1945 sec/batch\n                         loss = [21.130680] gen = [0.000000] fr = [21.130680] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:57:40,870: Epoch 16 / 24, batch 1100 / 1605, 0.1949 sec/batch\n                         loss = [20.282112] gen = [0.000000] fr = [20.282112] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:58:00,353: Epoch 16 / 24, batch 1200 / 1605, 0.1948 sec/batch\n                         loss = [19.621986] gen = [0.000000] fr = [19.621986] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:58:19,779: Epoch 16 / 24, batch 1300 / 1605, 0.1947 sec/batch\n                         loss = [20.339724] gen = [0.000000] fr = [20.339724] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:58:39,188: Epoch 16 / 24, batch 1400 / 1605, 0.1945 sec/batch\n                         loss = [20.285547] gen = [0.000000] fr = [20.285547] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 19:58:58,568: Epoch 16 / 24, batch 1500 / 1605, 0.1944 sec/batch\n                         loss = [20.680662] gen = [0.000000] fr = [20.680662] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:59:17,928: Epoch 16 / 24, batch 1600 / 1605, 0.1936 sec/batch\n                         loss = [20.329016] gen = [0.000000] fr = [20.329016] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:59:19,540: Save checkpoint at epoch 16 ...\n2024-09-26 19:59:19,540: Current epoch 17, learning rate 0.001\n2024-09-26 19:59:20,094: Epoch 17 / 24, batch 1 / 1605, 0.5523 sec/batch\n                         loss = [19.879726] gen = [0.000000] fr = [19.879726] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 19:59:39,299: Epoch 17 / 24, batch 100 / 1605, 0.1976 sec/batch\n                         loss = [20.972691] gen = [0.000000] fr = [20.972691] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 19:59:58,651: Epoch 17 / 24, batch 200 / 1605, 0.1955 sec/batch\n                         loss = [20.014456] gen = [0.000000] fr = [20.014456] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:00:18,025: Epoch 17 / 24, batch 300 / 1605, 0.1949 sec/batch\n                         loss = [20.722422] gen = [0.000000] fr = [20.722422] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:00:37,370: Epoch 17 / 24, batch 400 / 1605, 0.1946 sec/batch\n                         loss = [20.319822] gen = [0.000000] fr = [20.319822] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:00:56,680: Epoch 17 / 24, batch 500 / 1605, 0.1943 sec/batch\n                         loss = [20.230648] gen = [0.000000] fr = [20.230648] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:01:16,014: Epoch 17 / 24, batch 600 / 1605, 0.1933 sec/batch\n                         loss = [20.293615] gen = [0.000000] fr = [20.293615] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:01:35,367: Epoch 17 / 24, batch 700 / 1605, 0.1934 sec/batch\n                         loss = [20.884811] gen = [0.000000] fr = [20.884811] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:01:54,756: Epoch 17 / 24, batch 800 / 1605, 0.1936 sec/batch\n                         loss = [20.057838] gen = [0.000000] fr = [20.057838] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:02:14,193: Epoch 17 / 24, batch 900 / 1605, 0.1938 sec/batch\n                         loss = [20.322926] gen = [0.000000] fr = [20.322926] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:02:33,579: Epoch 17 / 24, batch 1000 / 1605, 0.1938 sec/batch\n                         loss = [20.270376] gen = [0.000000] fr = [20.270376] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 20:02:53,016: Epoch 17 / 24, batch 1100 / 1605, 0.1944 sec/batch\n                         loss = [20.309059] gen = [0.000000] fr = [20.309059] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:03:12,440: Epoch 17 / 24, batch 1200 / 1605, 0.1943 sec/batch\n                         loss = [20.278988] gen = [0.000000] fr = [20.278988] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:03:31,870: Epoch 17 / 24, batch 1300 / 1605, 0.1943 sec/batch\n                         loss = [20.122581] gen = [0.000000] fr = [20.122581] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:03:51,282: Epoch 17 / 24, batch 1400 / 1605, 0.1943 sec/batch\n                         loss = [20.064674] gen = [0.000000] fr = [20.064674] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:04:10,719: Epoch 17 / 24, batch 1500 / 1605, 0.1943 sec/batch\n                         loss = [20.053387] gen = [0.000000] fr = [20.053387] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:04:30,177: Epoch 17 / 24, batch 1600 / 1605, 0.1946 sec/batch\n                         loss = [20.346954] gen = [0.000000] fr = [20.346954] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:04:31,862: Save checkpoint at epoch 17 ...\n2024-09-26 20:04:31,862: Current epoch 18, learning rate 0.001\n2024-09-26 20:04:32,352: Epoch 18 / 24, batch 1 / 1605, 0.4874 sec/batch\n                         loss = [20.157351] gen = [0.000000] fr = [20.157351] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:04:51,592: Epoch 18 / 24, batch 100 / 1605, 0.1973 sec/batch\n                         loss = [20.304825] gen = [0.000000] fr = [20.304825] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:05:11,031: Epoch 18 / 24, batch 200 / 1605, 0.1958 sec/batch\n                         loss = [20.299770] gen = [0.000000] fr = [20.299770] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:05:30,458: Epoch 18 / 24, batch 300 / 1605, 0.1953 sec/batch\n                         loss = [20.276409] gen = [0.000000] fr = [20.276409] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:05:49,875: Epoch 18 / 24, batch 400 / 1605, 0.1950 sec/batch\n                         loss = [19.989588] gen = [0.000000] fr = [19.989588] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:06:09,338: Epoch 18 / 24, batch 500 / 1605, 0.1949 sec/batch\n                         loss = [20.021456] gen = [0.000000] fr = [20.021456] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:06:28,777: Epoch 18 / 24, batch 600 / 1605, 0.1944 sec/batch\n                         loss = [20.273314] gen = [0.000000] fr = [20.273314] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:06:48,229: Epoch 18 / 24, batch 700 / 1605, 0.1945 sec/batch\n                         loss = [21.723167] gen = [0.000000] fr = [21.723167] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 20:07:07,646: Epoch 18 / 24, batch 800 / 1605, 0.1944 sec/batch\n                         loss = [20.308674] gen = [0.000000] fr = [20.308674] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:07:27,042: Epoch 18 / 24, batch 900 / 1605, 0.1943 sec/batch\n                         loss = [19.953220] gen = [0.000000] fr = [19.953220] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:07:46,471: Epoch 18 / 24, batch 1000 / 1605, 0.1943 sec/batch\n                         loss = [20.256645] gen = [0.000000] fr = [20.256645] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:08:05,901: Epoch 18 / 24, batch 1100 / 1605, 0.1943 sec/batch\n                         loss = [20.010704] gen = [0.000000] fr = [20.010704] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:08:25,349: Epoch 18 / 24, batch 1200 / 1605, 0.1944 sec/batch\n                         loss = [20.129768] gen = [0.000000] fr = [20.129768] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:08:44,812: Epoch 18 / 24, batch 1300 / 1605, 0.1945 sec/batch\n                         loss = [19.846434] gen = [0.000000] fr = [19.846434] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 20:09:04,270: Epoch 18 / 24, batch 1400 / 1605, 0.1945 sec/batch\n                         loss = [20.318611] gen = [0.000000] fr = [20.318611] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:09:23,742: Epoch 18 / 24, batch 1500 / 1605, 0.1945 sec/batch\n                         loss = [20.016954] gen = [0.000000] fr = [20.016954] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:09:43,204: Epoch 18 / 24, batch 1600 / 1605, 0.1946 sec/batch\n                         loss = [20.272598] gen = [0.000000] fr = [20.272598] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:09:44,869: Save checkpoint at epoch 18 ...\n2024-09-26 20:09:44,869: Current epoch 19, learning rate 0.0001\n2024-09-26 20:09:45,431: Epoch 19 / 24, batch 1 / 1605, 0.5604 sec/batch\n                         loss = [20.300617] gen = [0.000000] fr = [20.300617] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:10:04,694: Epoch 19 / 24, batch 100 / 1605, 0.1982 sec/batch\n                         loss = [20.018661] gen = [0.000000] fr = [20.018661] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:10:24,259: Epoch 19 / 24, batch 200 / 1605, 0.1969 sec/batch\n                         loss = [20.283585] gen = [0.000000] fr = [20.283585] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:10:43,959: Epoch 19 / 24, batch 300 / 1605, 0.1970 sec/batch\n                         loss = [19.882057] gen = [0.000000] fr = [19.882057] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:11:03,599: Epoch 19 / 24, batch 400 / 1605, 0.1968 sec/batch\n                         loss = [20.317585] gen = [0.000000] fr = [20.317585] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:11:23,263: Epoch 19 / 24, batch 500 / 1605, 0.1968 sec/batch\n                         loss = [20.412579] gen = [0.000000] fr = [20.412579] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:11:42,831: Epoch 19 / 24, batch 600 / 1605, 0.1957 sec/batch\n                         loss = [20.042400] gen = [0.000000] fr = [20.042400] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:12:02,285: Epoch 19 / 24, batch 700 / 1605, 0.1951 sec/batch\n                         loss = [20.403992] gen = [0.000000] fr = [20.403992] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:12:21,705: Epoch 19 / 24, batch 800 / 1605, 0.1948 sec/batch\n                         loss = [20.290939] gen = [0.000000] fr = [20.290939] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:12:41,099: Epoch 19 / 24, batch 900 / 1605, 0.1946 sec/batch\n                         loss = [20.297810] gen = [0.000000] fr = [20.297810] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:13:00,469: Epoch 19 / 24, batch 1000 / 1605, 0.1944 sec/batch\n                         loss = [19.830742] gen = [0.000000] fr = [19.830742] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:13:19,840: Epoch 19 / 24, batch 1100 / 1605, 0.1937 sec/batch\n                         loss = [19.836861] gen = [0.000000] fr = [19.836861] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:13:39,262: Epoch 19 / 24, batch 1200 / 1605, 0.1940 sec/batch\n                         loss = [20.284365] gen = [0.000000] fr = [20.284365] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:13:58,703: Epoch 19 / 24, batch 1300 / 1605, 0.1941 sec/batch\n                         loss = [20.011145] gen = [0.000000] fr = [20.011145] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:14:18,153: Epoch 19 / 24, batch 1400 / 1605, 0.1942 sec/batch\n                         loss = [20.306671] gen = [0.000000] fr = [20.306671] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:14:37,573: Epoch 19 / 24, batch 1500 / 1605, 0.1942 sec/batch\n                         loss = [20.276913] gen = [0.000000] fr = [20.276913] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:14:56,999: Epoch 19 / 24, batch 1600 / 1605, 0.1943 sec/batch\n                         loss = [20.277897] gen = [0.000000] fr = [20.277897] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:14:58,674: Save checkpoint at epoch 19 ...\n2024-09-26 20:14:58,674: Current epoch 20, learning rate 0.0001\n2024-09-26 20:14:59,254: Epoch 20 / 24, batch 1 / 1605, 0.5783 sec/batch\n                         loss = [20.297974] gen = [0.000000] fr = [20.297974] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:15:18,462: Epoch 20 / 24, batch 100 / 1605, 0.1979 sec/batch\n                         loss = [20.276665] gen = [0.000000] fr = [20.276665] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:15:37,864: Epoch 20 / 24, batch 200 / 1605, 0.1959 sec/batch\n                         loss = [20.040775] gen = [0.000000] fr = [20.040775] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:15:57,238: Epoch 20 / 24, batch 300 / 1605, 0.1952 sec/batch\n                         loss = [20.079523] gen = [0.000000] fr = [20.079523] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:16:16,659: Epoch 20 / 24, batch 400 / 1605, 0.1950 sec/batch\n                         loss = [20.284338] gen = [0.000000] fr = [20.284338] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:16:36,260: Epoch 20 / 24, batch 500 / 1605, 0.1952 sec/batch\n                         loss = [20.461060] gen = [0.000000] fr = [20.461060] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:16:55,842: Epoch 20 / 24, batch 600 / 1605, 0.1958 sec/batch\n                         loss = [20.308388] gen = [0.000000] fr = [20.308388] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:17:15,292: Epoch 20 / 24, batch 700 / 1605, 0.1952 sec/batch\n                         loss = [20.219585] gen = [0.000000] fr = [20.219585] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:17:34,820: Epoch 20 / 24, batch 800 / 1605, 0.1952 sec/batch\n                         loss = [20.294327] gen = [0.000000] fr = [20.294327] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:17:54,435: Epoch 20 / 24, batch 900 / 1605, 0.1954 sec/batch\n                         loss = [20.273033] gen = [0.000000] fr = [20.273033] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:18:14,053: Epoch 20 / 24, batch 1000 / 1605, 0.1956 sec/batch\n                         loss = [20.990261] gen = [0.000000] fr = [20.990261] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:18:33,667: Epoch 20 / 24, batch 1100 / 1605, 0.1961 sec/batch\n                         loss = [20.292542] gen = [0.000000] fr = [20.292542] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:18:53,235: Epoch 20 / 24, batch 1200 / 1605, 0.1959 sec/batch\n                         loss = [19.999134] gen = [0.000000] fr = [19.999134] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:19:12,567: Epoch 20 / 24, batch 1300 / 1605, 0.1950 sec/batch\n                         loss = [20.083788] gen = [0.000000] fr = [20.083788] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:19:31,865: Epoch 20 / 24, batch 1400 / 1605, 0.1945 sec/batch\n                         loss = [20.256323] gen = [0.000000] fr = [20.256323] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:19:51,426: Epoch 20 / 24, batch 1500 / 1605, 0.1947 sec/batch\n                         loss = [20.288712] gen = [0.000000] fr = [20.288712] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:20:11,005: Epoch 20 / 24, batch 1600 / 1605, 0.1958 sec/batch\n                         loss = [20.296766] gen = [0.000000] fr = [20.296766] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:20:12,689: Save checkpoint at epoch 20 ...\n2024-09-26 20:20:12,689: Current epoch 21, learning rate 0.0001\n2024-09-26 20:20:13,256: Epoch 21 / 24, batch 1 / 1605, 0.5644 sec/batch\n                         loss = [19.742319] gen = [0.000000] fr = [19.742319] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:20:32,681: Epoch 21 / 24, batch 100 / 1605, 0.1999 sec/batch\n                         loss = [20.018265] gen = [0.000000] fr = [20.018265] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:20:52,308: Epoch 21 / 24, batch 200 / 1605, 0.1981 sec/batch\n                         loss = [20.269932] gen = [0.000000] fr = [20.269932] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:21:11,906: Epoch 21 / 24, batch 300 / 1605, 0.1974 sec/batch\n                         loss = [20.290882] gen = [0.000000] fr = [20.290882] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:21:31,500: Epoch 21 / 24, batch 400 / 1605, 0.1970 sec/batch\n                         loss = [20.147327] gen = [0.000000] fr = [20.147327] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:21:51,050: Epoch 21 / 24, batch 500 / 1605, 0.1967 sec/batch\n                         loss = [20.271723] gen = [0.000000] fr = [20.271723] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:22:10,506: Epoch 21 / 24, batch 600 / 1605, 0.1946 sec/batch\n                         loss = [20.330215] gen = [0.000000] fr = [20.330215] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:22:29,881: Epoch 21 / 24, batch 700 / 1605, 0.1942 sec/batch\n                         loss = [20.273842] gen = [0.000000] fr = [20.273842] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:22:49,214: Epoch 21 / 24, batch 800 / 1605, 0.1939 sec/batch\n                         loss = [20.005186] gen = [0.000000] fr = [20.005186] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:23:08,577: Epoch 21 / 24, batch 900 / 1605, 0.1938 sec/batch\n                         loss = [20.280209] gen = [0.000000] fr = [20.280209] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:23:27,901: Epoch 21 / 24, batch 1000 / 1605, 0.1937 sec/batch\n                         loss = [20.911901] gen = [0.000000] fr = [20.911901] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:23:47,238: Epoch 21 / 24, batch 1100 / 1605, 0.1934 sec/batch\n                         loss = [20.278809] gen = [0.000000] fr = [20.278809] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:24:06,661: Epoch 21 / 24, batch 1200 / 1605, 0.1938 sec/batch\n                         loss = [20.048126] gen = [0.000000] fr = [20.048126] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:24:26,164: Epoch 21 / 24, batch 1300 / 1605, 0.1942 sec/batch\n                         loss = [20.612892] gen = [0.000000] fr = [20.612892] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:24:45,618: Epoch 21 / 24, batch 1400 / 1605, 0.1943 sec/batch\n                         loss = [20.025520] gen = [0.000000] fr = [20.025520] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:25:05,005: Epoch 21 / 24, batch 1500 / 1605, 0.1942 sec/batch\n                         loss = [20.278864] gen = [0.000000] fr = [20.278864] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:25:24,324: Epoch 21 / 24, batch 1600 / 1605, 0.1932 sec/batch\n                         loss = [20.057447] gen = [0.000000] fr = [20.057447] spar = [0.000000] prec@1 = [0.000000] prec@5 = [12.500000] \n2024-09-26 20:25:25,962: Save checkpoint at epoch 21 ...\n2024-09-26 20:25:25,962: Current epoch 22, learning rate 0.0001\n2024-09-26 20:25:26,452: Epoch 22 / 24, batch 1 / 1605, 0.4874 sec/batch\n                         loss = [20.307646] gen = [0.000000] fr = [20.307646] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:25:45,781: Epoch 22 / 24, batch 100 / 1605, 0.1982 sec/batch\n                         loss = [20.221840] gen = [0.000000] fr = [20.221840] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:26:05,222: Epoch 22 / 24, batch 200 / 1605, 0.1963 sec/batch\n                         loss = [20.553217] gen = [0.000000] fr = [20.553217] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:26:24,518: Epoch 22 / 24, batch 300 / 1605, 0.1952 sec/batch\n                         loss = [20.302931] gen = [0.000000] fr = [20.302931] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:26:43,784: Epoch 22 / 24, batch 400 / 1605, 0.1945 sec/batch\n                         loss = [20.101004] gen = [0.000000] fr = [20.101004] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:27:03,039: Epoch 22 / 24, batch 500 / 1605, 0.1942 sec/batch\n                         loss = [20.274714] gen = [0.000000] fr = [20.274714] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:27:22,266: Epoch 22 / 24, batch 600 / 1605, 0.1923 sec/batch\n                         loss = [20.323128] gen = [0.000000] fr = [20.323128] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:27:41,536: Epoch 22 / 24, batch 700 / 1605, 0.1925 sec/batch\n                         loss = [20.259293] gen = [0.000000] fr = [20.259293] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:28:00,800: Epoch 22 / 24, batch 800 / 1605, 0.1925 sec/batch\n                         loss = [20.703171] gen = [0.000000] fr = [20.703171] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:28:20,056: Epoch 22 / 24, batch 900 / 1605, 0.1925 sec/batch\n                         loss = [20.004356] gen = [0.000000] fr = [20.004356] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:28:39,354: Epoch 22 / 24, batch 1000 / 1605, 0.1926 sec/batch\n                         loss = [20.249088] gen = [0.000000] fr = [20.249088] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:28:58,635: Epoch 22 / 24, batch 1100 / 1605, 0.1928 sec/batch\n                         loss = [20.018108] gen = [0.000000] fr = [20.018108] spar = [0.000000] prec@1 = [6.250000] prec@5 = [12.500000] \n2024-09-26 20:29:17,899: Epoch 22 / 24, batch 1200 / 1605, 0.1927 sec/batch\n                         loss = [20.346767] gen = [0.000000] fr = [20.346767] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:29:37,144: Epoch 22 / 24, batch 1300 / 1605, 0.1926 sec/batch\n                         loss = [20.378834] gen = [0.000000] fr = [20.378834] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:29:56,443: Epoch 22 / 24, batch 1400 / 1605, 0.1927 sec/batch\n                         loss = [20.051384] gen = [0.000000] fr = [20.051384] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:30:15,689: Epoch 22 / 24, batch 1500 / 1605, 0.1927 sec/batch\n                         loss = [20.021687] gen = [0.000000] fr = [20.021687] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:30:34,919: Epoch 22 / 24, batch 1600 / 1605, 0.1923 sec/batch\n                         loss = [20.293245] gen = [0.000000] fr = [20.293245] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:30:36,517: Save checkpoint at epoch 22 ...\n2024-09-26 20:30:36,517: Current epoch 23, learning rate 1e-05\n2024-09-26 20:30:36,992: Epoch 23 / 24, batch 1 / 1605, 0.4737 sec/batch\n                         loss = [20.206909] gen = [0.000000] fr = [20.206909] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:30:56,041: Epoch 23 / 24, batch 100 / 1605, 0.1952 sec/batch\n                         loss = [20.272593] gen = [0.000000] fr = [20.272593] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:31:15,267: Epoch 23 / 24, batch 200 / 1605, 0.1937 sec/batch\n                         loss = [19.770382] gen = [0.000000] fr = [19.770382] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:31:34,544: Epoch 23 / 24, batch 300 / 1605, 0.1934 sec/batch\n                         loss = [20.163876] gen = [0.000000] fr = [20.163876] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:31:53,796: Epoch 23 / 24, batch 400 / 1605, 0.1932 sec/batch\n                         loss = [20.273758] gen = [0.000000] fr = [20.273758] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:32:13,043: Epoch 23 / 24, batch 500 / 1605, 0.1930 sec/batch\n                         loss = [20.295959] gen = [0.000000] fr = [20.295959] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:32:32,279: Epoch 23 / 24, batch 600 / 1605, 0.1924 sec/batch\n                         loss = [20.401596] gen = [0.000000] fr = [20.401596] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:32:51,499: Epoch 23 / 24, batch 700 / 1605, 0.1923 sec/batch\n                         loss = [19.744825] gen = [0.000000] fr = [19.744825] spar = [0.000000] prec@1 = [6.250000] prec@5 = [12.500000] \n2024-09-26 20:33:10,730: Epoch 23 / 24, batch 800 / 1605, 0.1923 sec/batch\n                         loss = [20.099039] gen = [0.000000] fr = [20.099039] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:33:29,956: Epoch 23 / 24, batch 900 / 1605, 0.1923 sec/batch\n                         loss = [20.284487] gen = [0.000000] fr = [20.284487] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:33:49,198: Epoch 23 / 24, batch 1000 / 1605, 0.1923 sec/batch\n                         loss = [20.291245] gen = [0.000000] fr = [20.291245] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:34:08,459: Epoch 23 / 24, batch 1100 / 1605, 0.1926 sec/batch\n                         loss = [20.251144] gen = [0.000000] fr = [20.251144] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:34:27,760: Epoch 23 / 24, batch 1200 / 1605, 0.1928 sec/batch\n                         loss = [20.006535] gen = [0.000000] fr = [20.006535] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:34:47,190: Epoch 23 / 24, batch 1300 / 1605, 0.1933 sec/batch\n                         loss = [20.099653] gen = [0.000000] fr = [20.099653] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:35:06,627: Epoch 23 / 24, batch 1400 / 1605, 0.1936 sec/batch\n                         loss = [20.012642] gen = [0.000000] fr = [20.012642] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:35:26,040: Epoch 23 / 24, batch 1500 / 1605, 0.1937 sec/batch\n                         loss = [20.041302] gen = [0.000000] fr = [20.041302] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:35:45,443: Epoch 23 / 24, batch 1600 / 1605, 0.1940 sec/batch\n                         loss = [21.447575] gen = [0.000000] fr = [21.447575] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:35:47,078: Save checkpoint at epoch 23 ...\n2024-09-26 20:35:47,078: Current epoch 24, learning rate 1e-05\n2024-09-26 20:35:47,563: Epoch 24 / 24, batch 1 / 1605, 0.4830 sec/batch\n                         loss = [19.663754] gen = [0.000000] fr = [19.663754] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:36:06,708: Epoch 24 / 24, batch 100 / 1605, 0.1963 sec/batch\n                         loss = [20.025272] gen = [0.000000] fr = [20.025272] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:36:26,037: Epoch 24 / 24, batch 200 / 1605, 0.1948 sec/batch\n                         loss = [20.289562] gen = [0.000000] fr = [20.289562] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:36:45,405: Epoch 24 / 24, batch 300 / 1605, 0.1944 sec/batch\n                         loss = [20.285503] gen = [0.000000] fr = [20.285503] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:37:04,753: Epoch 24 / 24, batch 400 / 1605, 0.1942 sec/batch\n                         loss = [20.132879] gen = [0.000000] fr = [20.132879] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:37:24,114: Epoch 24 / 24, batch 500 / 1605, 0.1941 sec/batch\n                         loss = [20.291885] gen = [0.000000] fr = [20.291885] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:37:43,497: Epoch 24 / 24, batch 600 / 1605, 0.1938 sec/batch\n                         loss = [19.996685] gen = [0.000000] fr = [19.996685] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:38:02,884: Epoch 24 / 24, batch 700 / 1605, 0.1938 sec/batch\n                         loss = [20.035217] gen = [0.000000] fr = [20.035217] spar = [0.000000] prec@1 = [6.250000] prec@5 = [6.250000] \n2024-09-26 20:38:22,229: Epoch 24 / 24, batch 800 / 1605, 0.1937 sec/batch\n                         loss = [20.024925] gen = [0.000000] fr = [20.024925] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:38:41,573: Epoch 24 / 24, batch 900 / 1605, 0.1936 sec/batch\n                         loss = [20.027935] gen = [0.000000] fr = [20.027935] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:39:00,970: Epoch 24 / 24, batch 1000 / 1605, 0.1937 sec/batch\n                         loss = [20.278833] gen = [0.000000] fr = [20.278833] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:39:20,333: Epoch 24 / 24, batch 1100 / 1605, 0.1936 sec/batch\n                         loss = [20.267530] gen = [0.000000] fr = [20.267530] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:39:39,758: Epoch 24 / 24, batch 1200 / 1605, 0.1939 sec/batch\n                         loss = [20.277840] gen = [0.000000] fr = [20.277840] spar = [0.000000] prec@1 = [6.250000] prec@5 = [12.500000] \n2024-09-26 20:39:59,165: Epoch 24 / 24, batch 1300 / 1605, 0.1940 sec/batch\n                         loss = [20.294895] gen = [0.000000] fr = [20.294895] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:40:18,579: Epoch 24 / 24, batch 1400 / 1605, 0.1940 sec/batch\n                         loss = [21.007187] gen = [0.000000] fr = [21.007187] spar = [0.000000] prec@1 = [0.000000] prec@5 = [0.000000] \n2024-09-26 20:40:37,980: Epoch 24 / 24, batch 1500 / 1605, 0.1940 sec/batch\n                         loss = [20.555508] gen = [0.000000] fr = [20.555508] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:40:57,376: Epoch 24 / 24, batch 1600 / 1605, 0.1940 sec/batch\n                         loss = [19.761837] gen = [0.000000] fr = [19.761837] spar = [0.000000] prec@1 = [0.000000] prec@5 = [6.250000] \n2024-09-26 20:40:59,021: Save checkpoint at epoch 24 ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Face Matching","metadata":{}},{"cell_type":"code","source":"!$PYTHON_BIN/pip install mtcnn\n!$PYTHON_BIN/pip install tensorflow\n!$PYTHON_BIN/pip install tensorflow-gpu","metadata":{"execution":{"iopub.status.busy":"2024-09-29T08:13:57.551063Z","iopub.execute_input":"2024-09-29T08:13:57.551906Z","iopub.status.idle":"2024-09-29T08:14:03.037277Z","shell.execute_reply.started":"2024-09-29T08:13:57.551863Z","shell.execute_reply":"2024-09-29T08:14:03.036118Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: mtcnn in /opt/conda/envs/minusface/lib/python3.8/site-packages (0.1.1)\nRequirement already satisfied: keras>=2.0.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from mtcnn) (2.13.1)\nRequirement already satisfied: opencv-python>=4.1.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from mtcnn) (4.10.0.84)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from opencv-python>=4.1.0->mtcnn) (1.24.3)\nRequirement already satisfied: tensorflow in /opt/conda/envs/minusface/lib/python3.8/site-packages (2.13.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (1.66.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (24.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.35.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\nRequirement already satisfied: zipp>=3.20 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.20.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/minusface/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nCollecting tensorflow-gpu\n  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[39 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/requirements.py\", line 36, in __init__\n  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/_parser.py\", line 62, in parse_requirement\n  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/_parser.py\", line 80, in _parse_requirement\n  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/_parser.py\", line 124, in _parse_requirement_details\n  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/_parser.py\", line 145, in _parse_requirement_marker\n  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/_tokenizer.py\", line 167, in raise_syntax_error\n  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n  \u001b[31m   \u001b[0m packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n  \u001b[31m   \u001b[0m                   ^\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-3oqrjy8f/tensorflow-gpu_fa6e313bb467424a9ac01724f94166a4/setup.py\", line 40, in <module>\n  \u001b[31m   \u001b[0m     setuptools.setup()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/setuptools/__init__.py\", line 116, in setup\n  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/setuptools/__init__.py\", line 87, in _install_setup_requires\n  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/setuptools/dist.py\", line 610, in parse_config_files\n  \u001b[31m   \u001b[0m     self._finalize_requires()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/setuptools/dist.py\", line 344, in _finalize_requires\n  \u001b[31m   \u001b[0m     self._normalize_requires()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/setuptools/dist.py\", line 359, in _normalize_requires\n  \u001b[31m   \u001b[0m     self.install_requires = list(map(str, _reqs.parse(install_requires)))\n  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/packaging/requirements.py\", line 38, in __init__\n  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n  \u001b[31m   \u001b[0m packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n  \u001b[31m   \u001b[0m                   ^\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir '/kaggle/working/FM'","metadata":{"execution":{"iopub.status.busy":"2024-09-28T19:00:08.143166Z","iopub.execute_input":"2024-09-28T19:00:08.143918Z","iopub.status.idle":"2024-09-28T19:00:09.207662Z","shell.execute_reply.started":"2024-09-28T19:00:08.143876Z","shell.execute_reply":"2024-09-28T19:00:09.206459Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory '/kaggle/working/FM': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd '/kaggle/working/FM'","metadata":{"execution":{"iopub.status.busy":"2024-09-29T08:25:37.839675Z","iopub.execute_input":"2024-09-29T08:25:37.840124Z","iopub.status.idle":"2024-09-29T08:25:37.847047Z","shell.execute_reply.started":"2024-09-29T08:25:37.840081Z","shell.execute_reply":"2024-09-29T08:25:37.846136Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working/FM\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile '/kaggle/working/FM/FM.py'\n\nimport os\nimport sys\nsys.path.append(os.path.abspath('/kaggle/working/recognition'))\nfrom tasks.partialface.train import TrainTask\nimport copy\n\nimport torch\nimport torch.nn as nn\nfrom torchkit.backbone import get_model\nfrom torchkit.loss import get_loss\nfrom tasks.minusface.utils import UNet\nfrom tasks.partialface.utils import dct_transform, idct_transform\n\nimport torch\nimport cv2\nfrom mtcnn import MTCNN\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n\n# Initialize face detector\ndetector = MTCNN()\n\n# Load MinusFace model\nBACKBONE_NAME = 'IR_18'\nTASK_BACKBONE = 'IR_18'\nPRETRAIN_CKPT = '/kaggle/working/model_root/Backbone_Epoch_24_checkpoint.pth'\n\nfrom tasks.minusface.minusface import MinusBackbone\ngenerator, recognizer = None, None\nrecognizer = get_model(TASK_BACKBONE)([112, 112])\n\npretrain_backbone = MinusBackbone(mode='stage1',\n    recognizer=get_model(TASK_BACKBONE)([112, 112]))\npretrain_backbone.load_state_dict(torch.load(PRETRAIN_CKPT))\npretrain_backbone.generator.mode = 'stage2'\ngenerator = copy.deepcopy(pretrain_backbone.generator)\nbackbone = MinusBackbone(mode='stage2', n_duplicate=1, generator=generator,\n    recognizer=recognizer)\nbackbone.cuda()\nprint(backbone.eval())\n\ndef preprocess_face(image_path, target_size=(112, 112)):\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    detections = detector.detect_faces(image_rgb)\n    \n    if len(detections) == 0:\n        raise ValueError(f\"No face detected in {image_path}.\")\n    \n    x, y, width, height = detections[0]['box']\n    face = image_rgb[y:y+height, x:x+width]\n    \n    # Optional: Align face\n    # face = align_face(face)\n    \n    face_pil = Image.fromarray(face)\n    face_resized = face_pil.resize(target_size)\n    face_array = np.array(face_resized).astype('float32') / 255.0\n    \n    # Normalize\n    mean = np.array([0.5, 0.5, 0.5])\n    std = np.array([0.5, 0.5, 0.5])\n    face_normalized = (face_array - mean) / std\n    \n    # Transpose and convert to tensor\n    face_transposed = np.transpose(face_normalized, (2, 0, 1))\n    face_tensor = torch.tensor(face_transposed).unsqueeze(0)  # [1, C, H, W]\n    return face_tensor\n\ndef get_embedding(model, face_tensor, device='cpu'):\n    model.to(device)\n    face_tensor = face_tensor.to(device)\n    with torch.no_grad():\n        embedding = model(face_tensor)\n    embedding = embedding / embedding.norm()\n    return embedding.cpu().numpy()\n\ndef compare_faces(embedding1, embedding2, method='cosine', threshold=None):\n    if method == 'cosine':\n        similarity = cosine_similarity(embedding1, embedding2)[0][0]\n        if threshold is None:\n            threshold = 0.5  # Example threshold\n        match = similarity >= threshold\n        return match, similarity\n    elif method == 'euclidean':\n        distance = euclidean_distances(embedding1, embedding2)[0][0]\n        if threshold is None:\n            threshold = 1.0  # Example threshold\n        match = distance <= threshold\n        return match, distance\n    else:\n        raise ValueError(\"Unsupported comparison method.\")\n\n# Example usage\nimage_path1 = '/kaggle/input/vn-celeb/VN-celeb/1002/0.png'\nimage_path2 = '/kaggle/input/vn-celeb/VN-celeb/1002/1.png'\n\n# Preprocess images\nface_tensor1 = preprocess_face(image_path1)\nface_tensor2 = preprocess_face(image_path2)\n\n# Get embeddings\nembedding1 = get_embedding(model, face_tensor1)\nembedding2 = get_embedding(model, face_tensor2)\n\n# Compare using cosine similarity\nmatch, similarity = compare_faces(embedding1, embedding2, method='cosine')\nprint(f\"Cosine Similarity: {similarity:.4f} - Match: {match}\")\n\n# Compare using Euclidean distance\nmatch, distance = compare_faces(embedding1, embedding2, method='euclidean')\nprint(f\"Euclidean Distance: {distance:.4f} - Match: {match}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T07:40:57.604535Z","iopub.execute_input":"2024-09-29T07:40:57.605130Z","iopub.status.idle":"2024-09-29T07:40:57.614136Z","shell.execute_reply.started":"2024-09-29T07:40:57.605092Z","shell.execute_reply":"2024-09-29T07:40:57.613177Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/FM/FM.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!export CUDA_VISIBLE_DEVICES='0'\n!$PYTHON_BIN/python3 -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 '/kaggle/working/FM/FM.py'","metadata":{"execution":{"iopub.status.busy":"2024-09-29T07:44:06.551994Z","iopub.execute_input":"2024-09-29T07:44:06.552556Z","iopub.status.idle":"2024-09-29T07:44:26.164879Z","shell.execute_reply.started":"2024-09-29T07:44:06.552513Z","shell.execute_reply":"2024-09-29T07:44:26.163731Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated\nand will be removed in future. Use torchrun.\nNote that --use-env is set by default in torchrun.\nIf your script expects `--local-rank` argument to be set, please\nchange it to read from `os.environ['LOCAL_RANK']` instead. See \nhttps://pytorch.org/docs/stable/distributed.html#launch-utility for \nfurther instructions\n\n  warnings.warn(\nMinusBackbone(\n  (generator): MinusGenerativeModel(\n    (backbone): UNet(\n      (left_conv_1): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (left_conv_2): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (left_conv_3): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (pool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (left_conv_4): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (pool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (left_conv_5): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (deconv_1): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (right_conv_1): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (deconv_2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (right_conv_2): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (deconv_3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (right_conv_3): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (deconv_4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (right_conv_4): ConvBlock(\n        (conv_ReLU): Sequential(\n          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU()\n          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (3): ReLU()\n        )\n      )\n      (right_conv_5): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (recognizer): Backbone(\n    (input_layer): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): PReLU(num_parameters=64)\n    )\n    (output_layer): Sequential(\n      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): Dropout(p=0.4, inplace=False)\n      (2): Flatten()\n      (3): Linear(in_features=25088, out_features=512, bias=True)\n      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n    )\n    (body): Sequential(\n      (0): BasicBlockIR(\n        (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n        (res_layer): Sequential(\n          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=64)\n          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlockIR(\n        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n        (res_layer): Sequential(\n          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=64)\n          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): BasicBlockIR(\n        (shortcut_layer): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (res_layer): Sequential(\n          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=128)\n          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): BasicBlockIR(\n        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n        (res_layer): Sequential(\n          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=128)\n          (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): BasicBlockIR(\n        (shortcut_layer): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (res_layer): Sequential(\n          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=256)\n          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): BasicBlockIR(\n        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n        (res_layer): Sequential(\n          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=256)\n          (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): BasicBlockIR(\n        (shortcut_layer): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (res_layer): Sequential(\n          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=512)\n          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): BasicBlockIR(\n        (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n        (res_layer): Sequential(\n          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (3): PReLU(num_parameters=512)\n          (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n)\n2024-09-29 07:44:20.884484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\nTraceback (most recent call last):\n  File \"/kaggle/working/FM/FM.py\", line 101, in <module>\n    face_tensor1 = preprocess_face(image_path1)\n  File \"/kaggle/working/FM/FM.py\", line 47, in preprocess_face\n    detections = detector.detect_faces(image_rgb)\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/mtcnn/mtcnn.py\", line 300, in detect_faces\n    result = stage(img, result[0], result[1])\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n    out = self._pnet.predict(img_y)\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/kaggle/working/FM/FM.py\", line 101, in <module>\n      face_tensor1 = preprocess_face(image_path1)\n    File \"/kaggle/working/FM/FM.py\", line 47, in preprocess_face\n      detections = detector.detect_faces(image_rgb)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/mtcnn/mtcnn.py\", line 300, in detect_faces\n      result = stage(img, result[0], result[1])\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n      out = self._pnet.predict(img_y)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node model/conv2d/Conv2D}}]] [Op:__inference_predict_function_917]\nERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 270) of binary: /opt/conda/envs/minusface/bin/python3\nTraceback (most recent call last):\n  File \"/opt/conda/envs/minusface/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/envs/minusface/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py\", line 196, in <module>\n    main()\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py\", line 192, in main\n    launch(args)\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launch.py\", line 177, in launch\n    run(args)\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/run.py\", line 785, in run\n    elastic_launch(\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n  File \"/opt/conda/envs/minusface/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\n/kaggle/working/FM/FM.py FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-09-29_07:44:25\n  host      : 7285292ac8ed\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 270)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}]}]}